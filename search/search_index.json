{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#what-is-this-place","title":"What is this place?","text":"<p>This is a place where I will be going over anything and everything that has to do with quant trading. That will be creating strategies, coding, tutorials, backtesting, deploying strategies to the cloud, basically anything to do with algo trading / quant trading I will be talking about it.</p>"},{"location":"#quantfreedom.base.base.backtest_df_only","title":"backtest_df_only","text":"<pre><code>backtest_df_only(\n    prices,\n    entries,\n    equity,\n    fee_pct,\n    mmr_pct,\n    lev_mode,\n    order_type,\n    size_type,\n    leverage=np.nan,\n    max_equity_risk_pct=np.nan,\n    max_equity_risk_value=np.nan,\n    max_order_size_pct=100.0,\n    min_order_size_pct=0.01,\n    max_order_size_value=np.inf,\n    min_order_size_value=1.0,\n    max_lev=100.0,\n    size_pct=np.nan,\n    size_value=np.nan,\n    sl_pcts=np.nan,\n    sl_to_be=False,\n    sl_to_be_based_on=np.nan,\n    sl_to_be_when_pct_from_avg_entry=np.nan,\n    sl_to_be_zero_or_entry=np.nan,\n    sl_to_be_then_trail=False,\n    sl_to_be_trail_by_when_pct_from_avg_entry=np.nan,\n    tsl_pcts_init=np.nan,\n    tsl_true_or_false=False,\n    tsl_based_on=np.nan,\n    tsl_trail_by_pct=np.nan,\n    tsl_when_pct_from_avg_entry=np.nan,\n    risk_rewards=np.nan,\n    tp_pcts=np.nan,\n    gains_pct_filter=-np.inf,\n    total_trade_filter=0,\n    divide_records_array_size_by=1.0,\n    upside_filter=-1.0,\n)\n</code></pre>"},{"location":"#quantfreedom.base.base.backtest_df_only--function-name","title":"Function Name","text":"<pre><code>backtest_df_only\n</code></pre>"},{"location":"#quantfreedom.base.base.backtest_df_only--quick-summary","title":"Quick Summary","text":"<pre><code>The main way to backtest your strategy.\nI highly highly highly suggest watching the explainer video\nI explain what everything does and means in great detail.\n</code></pre>"},{"location":"#quantfreedom.base.base.backtest_df_only--explainer-video","title":"Explainer Video","text":"<pre><code>https://youtu.be/yDNPhgO-450\n</code></pre> <p>Parameters:</p> <ul> <li> prices             (<code>pdFrame</code>)         \u2013 <p>Dataframe of prices</p> </li> <li> entries             (<code>pdFrame</code>)         \u2013 <p>Dataframe of entries</p> </li> <li> equity             (<code>float</code>)         \u2013 <p>Starting equity. I suggest only doing 100 or 1000 dollars</p> </li> <li> fee_pct             (<code>float</code>)         \u2013 <p>Fees percent</p> </li> <li> mmr_pct             (<code>float</code>)         \u2013 <p>maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this</p> </li> <li> lev_mode             (<code>int</code>)         \u2013 <p>Selecting your leverage mode. Look in the enums api section for LeverageMode</p> </li> <li> order_type             (<code>int</code>)         \u2013 <p>Selecting your order type. Please only use long short or both. Look in the enums api section for OrderType</p> </li> <li> size_type             (<code>int</code>)         \u2013 <p>Selecting your size type. Look in the enums api section for SizeType</p> </li> <li> leverage             (<code>PossibleArray, optional</code>)         \u2013 <p>If your leverage mode is isolated this is where you put in how much leverage you want to use., by default np.nan</p> </li> <li> max_equity_risk_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>What is the max equity percent you want to possibly risk, by default np.nan</p> </li> <li> max_equity_risk_value             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> max_order_size_pct             (<code>float, optional</code>)         \u2013 <p>description, by default 100.0</p> </li> <li> min_order_size_pct             (<code>float, optional</code>)         \u2013 <p>description, by default 0.01</p> </li> <li> max_order_size_value             (<code>float, optional</code>)         \u2013 <p>description, by default np.inf</p> </li> <li> min_order_size_value             (<code>float, optional</code>)         \u2013 <p>description, by default 1.0</p> </li> <li> max_lev             (<code>float, optional</code>)         \u2013 <p>description, by default 100.0</p> </li> <li> size_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> size_value             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_pcts             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> sl_to_be_based_on             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_zero_or_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_trail_by_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_pcts_init             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_true_or_false             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> tsl_based_on             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_trail_by_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> risk_rewards             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tp_pcts             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> gains_pct_filter             (<code>float, optional</code>)         \u2013 <p>description, by default -np.inf</p> </li> <li> total_trade_filter             (<code>int, optional</code>)         \u2013 <p>description, by default 0</p> </li> <li> divide_records_array_size_by             (<code>float, optional</code>)         \u2013 <p>If you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more.</p> <p>If you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1.</p> <p>This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million, by default 1.0</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[pdFrame, pdFrame]</code>         \u2013 <p>First return is a dataframe of strategy results. Second return is a dataframe of the indicator and order settings.</p> </li> </ul> Source code in <code>quantfreedom\\base\\base.py</code> <pre><code>def backtest_df_only(\n    # entry info\n    prices: pdFrame,\n    entries: pdFrame,\n    # required account info\n    equity: float,\n    fee_pct: float,\n    mmr_pct: float,\n    # required order\n    lev_mode: int,\n    order_type: int,\n    size_type: int,\n    # Order Params\n    leverage: PossibleArray = np.nan,\n    max_equity_risk_pct: PossibleArray = np.nan,\n    max_equity_risk_value: PossibleArray = np.nan,\n    max_order_size_pct: float = 100.0,\n    min_order_size_pct: float = 0.01,\n    max_order_size_value: float = np.inf,\n    min_order_size_value: float = 1.0,\n    max_lev: float = 100.0,\n    size_pct: PossibleArray = np.nan,\n    size_value: PossibleArray = np.nan,\n    # Stop Losses\n    sl_pcts: PossibleArray = np.nan,\n    sl_to_be: bool = False,\n    sl_to_be_based_on: PossibleArray = np.nan,\n    sl_to_be_when_pct_from_avg_entry: PossibleArray = np.nan,\n    sl_to_be_zero_or_entry: PossibleArray = np.nan,  # 0 for zero or 1 for entry\n    sl_to_be_then_trail: bool = False,\n    sl_to_be_trail_by_when_pct_from_avg_entry: PossibleArray = np.nan,\n    # Trailing Stop Loss Params\n    tsl_pcts_init: PossibleArray = np.nan,\n    tsl_true_or_false: bool = False,\n    tsl_based_on: PossibleArray = np.nan,\n    tsl_trail_by_pct: PossibleArray = np.nan,\n    tsl_when_pct_from_avg_entry: PossibleArray = np.nan,\n    # Take Profit Params\n    risk_rewards: PossibleArray = np.nan,\n    tp_pcts: PossibleArray = np.nan,\n    # Results Filters\n    gains_pct_filter: float = -np.inf,\n    total_trade_filter: int = 0,\n    divide_records_array_size_by: float = 1.0,  # between 1 and 1000\n    upside_filter: float = -1.0,  # between -1 and 1\n) -&gt; tuple[pdFrame, pdFrame]:\n\"\"\"\n     Function Name\n    -------------\n        backtest_df_only\n\n    Quick Summary\n    -------------\n        The main way to backtest your strategy.\n        I highly highly highly suggest watching the explainer video\n        I explain what everything does and means in great detail.\n\n\n    Explainer Video\n    ---------------\n        https://youtu.be/yDNPhgO-450\n\n    Parameters\n    ----------\n    prices : pdFrame\n        Dataframe of prices\n    entries : pdFrame\n        Dataframe of entries\n    equity : float\n        Starting equity. I suggest only doing 100 or 1000 dollars\n    fee_pct : float\n        Fees percent\n    mmr_pct : float\n        maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this\n    lev_mode : int\n        Selecting your leverage mode. Look in the enums api section for LeverageMode\n    order_type : int\n        Selecting your order type. Please only use long short or both. Look in the enums api section for OrderType\n    size_type : int\n        Selecting your size type. Look in the enums api section for SizeType\n    leverage : PossibleArray, optional\n        If your leverage mode is isolated this is where you put in how much leverage you want to use., by default np.nan\n    max_equity_risk_pct : PossibleArray, optional\n        What is the max equity percent you want to possibly risk, by default np.nan\n    max_equity_risk_value : PossibleArray, optional\n        _description_, by default np.nan\n    max_order_size_pct : float, optional\n        _description_, by default 100.0\n    min_order_size_pct : float, optional\n        _description_, by default 0.01\n    max_order_size_value : float, optional\n        _description_, by default np.inf\n    min_order_size_value : float, optional\n        _description_, by default 1.0\n    max_lev : float, optional\n        _description_, by default 100.0\n    size_pct : PossibleArray, optional\n        _description_, by default np.nan\n    size_value : PossibleArray, optional\n        _description_, by default np.nan\n    sl_pcts : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be : bool, optional\n        _description_, by default False\n    sl_to_be_based_on : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_zero_or_entry : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_trail_by_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_pcts_init : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_true_or_false : bool, optional\n        _description_, by default False\n    tsl_based_on : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_trail_by_pct : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    risk_rewards : PossibleArray, optional\n        _description_, by default np.nan\n    tp_pcts : PossibleArray, optional\n        _description_, by default np.nan\n    gains_pct_filter : float, optional\n        _description_, by default -np.inf\n    total_trade_filter : int, optional\n        _description_, by default 0\n    divide_records_array_size_by : float, optional\n        If you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more.\n\n        If you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1.\n\n        This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million, by default 1.0\n\n    Returns\n    -------\n    tuple[pdFrame, pdFrame]\n        First return is a dataframe of strategy results.\n        Second return is a dataframe of the indicator and order settings.\n    \"\"\"\n    print(\"Checking static variables for errors or conflicts.\")\n    # Static checks\n    static_variables_tuple = static_var_checker_nb(\n        divide_records_array_size_by=divide_records_array_size_by,\n        equity=equity,\n        fee_pct=fee_pct,\n        gains_pct_filter=gains_pct_filter,\n        lev_mode=lev_mode,\n        max_lev=max_lev,\n        max_order_size_pct=max_order_size_pct,\n        max_order_size_value=max_order_size_value,\n        min_order_size_pct=min_order_size_pct,\n        min_order_size_value=min_order_size_value,\n        mmr_pct=mmr_pct,\n        order_type=order_type,\n        size_type=size_type,\n        sl_to_be_then_trail=sl_to_be_then_trail,\n        sl_to_be=sl_to_be,\n        total_trade_filter=total_trade_filter,\n        tsl_true_or_false=tsl_true_or_false,\n        upside_filter=upside_filter,\n    )\n    print(\"Turning all variables into arrays.\")\n    # Create 1d Arrays\n    arrays_1d_tuple = create_1d_arrays_nb(\n        leverage=leverage,\n        max_equity_risk_pct=max_equity_risk_pct,\n        max_equity_risk_value=max_equity_risk_value,\n        risk_rewards=risk_rewards,\n        size_pct=size_pct,\n        size_value=size_value,\n        sl_pcts=sl_pcts,\n        sl_to_be_based_on=sl_to_be_based_on,\n        sl_to_be_trail_by_when_pct_from_avg_entry=sl_to_be_trail_by_when_pct_from_avg_entry,\n        sl_to_be_when_pct_from_avg_entry=sl_to_be_when_pct_from_avg_entry,\n        sl_to_be_zero_or_entry=sl_to_be_zero_or_entry,\n        tp_pcts=tp_pcts,\n        tsl_based_on=tsl_based_on,\n        tsl_pcts_init=tsl_pcts_init,\n        tsl_trail_by_pct=tsl_trail_by_pct,\n        tsl_when_pct_from_avg_entry=tsl_when_pct_from_avg_entry,\n    )\n    print(\n        \"Checking arrays for errors or conflicts ... the backtest will begin shortly, please hold.\"\n    )\n    # Checking all new arrays\n    check_1d_arrays_nb(\n        arrays_1d_tuple=arrays_1d_tuple,\n        static_variables_tuple=static_variables_tuple,\n    )\n\n    print(\n        \"Creating cartesian product ... after this the backtest will start, I promise :).\\n\"\n    )\n    cart_array_tuple = create_cart_product_nb(arrays_1d_tuple=arrays_1d_tuple)\n\n    num_of_symbols = len(prices.columns.levels[0])\n\n    # Creating Settings Vars\n    total_order_settings = cart_array_tuple.sl_pcts.shape[0]\n\n    total_indicator_settings = entries.shape[1]\n\n    total_bars = entries.shape[0]\n\n    # Printing out total numbers of things\n    print(\n        \"Starting the backtest now ... and also here are some stats for your backtest.\\n\"\n    )\n    print(f\"Total symbols: {num_of_symbols:,}\")\n    print(\n        f\"Total indicator settings per symbol: {int(total_indicator_settings / num_of_symbols):,}\"\n    )\n    print(f\"Total indicator settings to test: {total_indicator_settings:,}\")\n    print(f\"Total order settings per symbol: {total_order_settings:,}\")\n    print(f\"Total order settings to test: {total_order_settings * num_of_symbols:,}\")\n    print(f\"Total candles per symbol: {total_bars:,}\")\n    print(\n        f\"Total candles to test: {total_indicator_settings * total_order_settings * total_bars:,}\"\n    )\n    print(\n        f\"\\nTotal combinations to test: {total_indicator_settings * total_order_settings:,}\"\n    )\n\n    strat_array, settings_array = backtest_df_only_nb(\n        cart_array_tuple=cart_array_tuple,\n        entries=entries.values,\n        gains_pct_filter=gains_pct_filter,\n        num_of_symbols=num_of_symbols,\n        og_equity=equity,\n        prices=prices.values,\n        static_variables_tuple=static_variables_tuple,\n        total_bars=total_bars,\n        total_indicator_settings=total_indicator_settings,\n        total_order_settings=total_order_settings,\n        total_trade_filter=total_trade_filter,\n    )\n\n    strat_results_df = pd.DataFrame(strat_array).sort_values(\n        by=[\"to_the_upside\", \"gains_pct\"], ascending=False\n    )\n\n    symbols = list(prices.columns.levels[0])\n\n    for i in range(len(symbols)):\n        strat_results_df.replace({\"symbol\": {i: symbols[i]}}, inplace=True)\n\n    symbols = list(entries.columns.levels[0])\n    setting_results_df = pd.DataFrame(settings_array).dropna(axis=\"columns\", thresh=1)\n\n    for i in range(len(SL_BE_or_Trail_BasedOn._fields)):\n        setting_results_df.replace(\n            {\"tsl_based_on\": {i: SL_BE_or_Trail_BasedOn._fields[i]}}, inplace=True\n        )\n        setting_results_df.replace(\n            {\"sl_to_be_based_on\": {i: SL_BE_or_Trail_BasedOn._fields[i]}}, inplace=True\n        )\n    for i in range(len(symbols)):\n        setting_results_df.replace({\"symbol\": {i: symbols[i]}}, inplace=True)\n\n    setting_results_df = setting_results_df.T\n\n    return strat_results_df, setting_results_df\n</code></pre>"},{"location":"features/","title":"Features","text":""},{"location":"features/#version-002","title":"Version 0.0.2 ()","text":"<ul> <li>delete cache </li> </ul>"},{"location":"releasenotes/","title":"Release Notes","text":""},{"location":"releasenotes/#version-002","title":"Version 0.0.2 ()","text":"<ul> <li>Added the ability to delete cache</li> <li>Return cart array</li> <li>made a df array only function and simulate less than 6 function to save memory</li> <li>got selling and longing to work</li> <li>added the charting option in base</li> <li>removed user input price for now</li> </ul>"},{"location":"releasenotes/#version-001-march-12-2023","title":"Version 0.0.1 (March 12 2023)","text":"<ul> <li>Initial commit where only longing works and the whole thing barely even works lol</li> </ul>"},{"location":"roadmap/","title":"Roadmap","text":"<p>get this version done work on making a dashboard with grpahs and stuff build the divergence indicator and run it live work on making courses for peole to follow</p>"},{"location":"api/","title":"Index","text":""},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>quantfreedom<ul> <li>base<ul> <li>base</li> </ul> </li> <li>data<ul> <li>ccxtdata</li> </ul> </li> <li>enums<ul> <li>enums</li> </ul> </li> <li>evaluators<ul> <li>evaluators</li> </ul> </li> <li>indicators<ul> <li>talib_ind</li> </ul> </li> <li>nb<ul> <li>buy_funcs</li> <li>execute_funcs</li> <li>helper_funcs</li> <li>sell_funcs</li> <li>simulate</li> <li>temp</li> </ul> </li> <li>plotting<ul> <li>plot_helper_functions</li> <li>plotting_main</li> <li>replay</li> <li>temp</li> </ul> </li> <li>testing</li> <li>utils<ul> <li>helpers</li> </ul> </li> </ul> </li> </ul>"},{"location":"api/testing/","title":"Testing","text":""},{"location":"api/testing/#quantfreedom.testing--function-name","title":"Function Name","text":"<pre><code>backtest_df_only\n</code></pre>"},{"location":"api/testing/#quantfreedom.testing--quick-summary","title":"Quick Summary","text":"<pre><code>The main way to backtest your strategy. \nI highly highly highly suggest watching the explainer video\nI explain what everything does and means in great detail.\n</code></pre>"},{"location":"api/testing/#quantfreedom.testing--explainer-video","title":"Explainer Video","text":"<pre><code>https://youtu.be/yDNPhgO-450\n</code></pre> <p>mmr_pct: float     maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this lev_mode: int order_type: int size_type: int</p>"},{"location":"api/testing/#quantfreedom.testing--optional-parameters","title":"Optional Parameters","text":"<p>Variable Name: Variable Type = Default Value</p> <p>leverage: PossibleArray = np.nan max_equity_risk_pct: PossibleArray = np.nan max_equity_risk_value: PossibleArray = np.nan     What is the max usd amount of your equity do you want to possibly risk max_order_size_pct: float = 100.0     max order size percent possible min_order_size_pct: float = 0.01     min order size percent possible max_order_size_value: float = np.inf     max order size usd value possible min_order_size_value: float = 1.0     min order size usd value possible max_lev: float = 100.0     setting your max leverage size_pct: PossibleArray = np.nan     When you have selected a size type that is based on percent you put your size percent here. size_value: PossibleArray = np.nan     when you selected a size type that is based on value you put your size value here. sl_pcts: PossibleArray = np.nan     stop loss based on percent sl_to_be: bool = False     if you want to move your stop loss to break even sl_to_be_based_on: PossibleArray = np.nan     Selecting what part of the candle you want your stop loss to break even to based on. Please look in enums api to find out more info on SL_BE_or_Trail_BasedOn sl_to_be_when_pct_from_avg_entry: PossibleArray = np.nan     how far in percent does the price have to be from your average entry to move your stop loss to break even sl_to_be_zero_or_entry: PossibleArray = np.nan     do you want to have your break even be zero dollars lost or moving your stop loss to your average entry. Use 0 for zero and use 1 for average entry sl_to_be_trail_by_when_pct_from_avg_entry: PossibleArray = np.nan     how much, in percent, do you want to trail the price by, set that here tsl_pcts_init: PossibleArray = np.nan     your initial stop loss tsl_true_or_false: bool = False     if you want to have a trailing stop loss this must be set to true tsl_based_on: PossibleArray = np.nan     Selecting what part of the candle you want your trailing stop loss to be based on. Please look in enums api to find out more info on SL_BE_or_Trail_BasedOn tsl_trail_by_pct: PossibleArray = np.nan     how much percent from the price do you want to trail your stop loss tsl_when_pct_from_avg_entry: PossibleArray = np.nan     at what percent from the price should the trailing stop loss strat trailing risk_rewards: PossibleArray = np.nan     risk to reward, don't set a tp percent if you are going to use risk to reward tp_pcts: PossibleArray = np.nan     take profit percent, don't set this if you are going to use risk to reward gains_pct_filter: float = -np.inf     don't return any strategies that have gains less than the percent set here total_trade_filter: int = 0     don't return any strategies that have a total trade amount that is less than this filter divide_records_array_size_by: float = 1.0     if you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more, if you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1. This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million upside_filter: float = -1.0     How you want to filter strategies that don't meet the to the upside numbers you want. Please watch the video to understand what to the upside is but it is basically the r2 value of the cumilative sum of the strategies pnl.</p> <p>Returns:</p> <ul> <li> <code>tuple[pdFrame, pdFrame]</code>         \u2013 <p>First return is a dataframe of strategy results Second return is a dataframe of the indicator and order settings</p> </li> </ul>"},{"location":"api/base/","title":"Index","text":""},{"location":"api/base/base/","title":"Base","text":""},{"location":"api/base/base/#quantfreedom.base.base.backtest_df_only","title":"backtest_df_only","text":"<pre><code>backtest_df_only(\n    prices,\n    entries,\n    equity,\n    fee_pct,\n    mmr_pct,\n    lev_mode,\n    order_type,\n    size_type,\n    leverage=np.nan,\n    max_equity_risk_pct=np.nan,\n    max_equity_risk_value=np.nan,\n    max_order_size_pct=100.0,\n    min_order_size_pct=0.01,\n    max_order_size_value=np.inf,\n    min_order_size_value=1.0,\n    max_lev=100.0,\n    size_pct=np.nan,\n    size_value=np.nan,\n    sl_pcts=np.nan,\n    sl_to_be=False,\n    sl_to_be_based_on=np.nan,\n    sl_to_be_when_pct_from_avg_entry=np.nan,\n    sl_to_be_zero_or_entry=np.nan,\n    sl_to_be_then_trail=False,\n    sl_to_be_trail_by_when_pct_from_avg_entry=np.nan,\n    tsl_pcts_init=np.nan,\n    tsl_true_or_false=False,\n    tsl_based_on=np.nan,\n    tsl_trail_by_pct=np.nan,\n    tsl_when_pct_from_avg_entry=np.nan,\n    risk_rewards=np.nan,\n    tp_pcts=np.nan,\n    gains_pct_filter=-np.inf,\n    total_trade_filter=0,\n    divide_records_array_size_by=1.0,\n    upside_filter=-1.0,\n)\n</code></pre>"},{"location":"api/base/base/#quantfreedom.base.base.backtest_df_only--function-name","title":"Function Name","text":"<pre><code>backtest_df_only\n</code></pre>"},{"location":"api/base/base/#quantfreedom.base.base.backtest_df_only--quick-summary","title":"Quick Summary","text":"<pre><code>The main way to backtest your strategy.\nI highly highly highly suggest watching the explainer video\nI explain what everything does and means in great detail.\n</code></pre>"},{"location":"api/base/base/#quantfreedom.base.base.backtest_df_only--explainer-video","title":"Explainer Video","text":"<pre><code>https://youtu.be/yDNPhgO-450\n</code></pre> <p>Parameters:</p> <ul> <li> prices             (<code>pdFrame</code>)         \u2013 <p>Dataframe of prices</p> </li> <li> entries             (<code>pdFrame</code>)         \u2013 <p>Dataframe of entries</p> </li> <li> equity             (<code>float</code>)         \u2013 <p>Starting equity. I suggest only doing 100 or 1000 dollars</p> </li> <li> fee_pct             (<code>float</code>)         \u2013 <p>Fees percent</p> </li> <li> mmr_pct             (<code>float</code>)         \u2013 <p>maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this</p> </li> <li> lev_mode             (<code>int</code>)         \u2013 <p>Selecting your leverage mode. Look in the enums api section for LeverageMode</p> </li> <li> order_type             (<code>int</code>)         \u2013 <p>Selecting your order type. Please only use long short or both. Look in the enums api section for OrderType</p> </li> <li> size_type             (<code>int</code>)         \u2013 <p>Selecting your size type. Look in the enums api section for SizeType</p> </li> <li> leverage             (<code>PossibleArray, optional</code>)         \u2013 <p>If your leverage mode is isolated this is where you put in how much leverage you want to use., by default np.nan</p> </li> <li> max_equity_risk_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>What is the max equity percent you want to possibly risk, by default np.nan</p> </li> <li> max_equity_risk_value             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> max_order_size_pct             (<code>float, optional</code>)         \u2013 <p>description, by default 100.0</p> </li> <li> min_order_size_pct             (<code>float, optional</code>)         \u2013 <p>description, by default 0.01</p> </li> <li> max_order_size_value             (<code>float, optional</code>)         \u2013 <p>description, by default np.inf</p> </li> <li> min_order_size_value             (<code>float, optional</code>)         \u2013 <p>description, by default 1.0</p> </li> <li> max_lev             (<code>float, optional</code>)         \u2013 <p>description, by default 100.0</p> </li> <li> size_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> size_value             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_pcts             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> sl_to_be_based_on             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_zero_or_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_trail_by_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_pcts_init             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_true_or_false             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> tsl_based_on             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_trail_by_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> risk_rewards             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tp_pcts             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> gains_pct_filter             (<code>float, optional</code>)         \u2013 <p>description, by default -np.inf</p> </li> <li> total_trade_filter             (<code>int, optional</code>)         \u2013 <p>description, by default 0</p> </li> <li> divide_records_array_size_by             (<code>float, optional</code>)         \u2013 <p>If you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more.</p> <p>If you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1.</p> <p>This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million, by default 1.0</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[pdFrame, pdFrame]</code>         \u2013 <p>First return is a dataframe of strategy results. Second return is a dataframe of the indicator and order settings.</p> </li> </ul> Source code in <code>quantfreedom\\base\\base.py</code> <pre><code>def backtest_df_only(\n    # entry info\n    prices: pdFrame,\n    entries: pdFrame,\n    # required account info\n    equity: float,\n    fee_pct: float,\n    mmr_pct: float,\n    # required order\n    lev_mode: int,\n    order_type: int,\n    size_type: int,\n    # Order Params\n    leverage: PossibleArray = np.nan,\n    max_equity_risk_pct: PossibleArray = np.nan,\n    max_equity_risk_value: PossibleArray = np.nan,\n    max_order_size_pct: float = 100.0,\n    min_order_size_pct: float = 0.01,\n    max_order_size_value: float = np.inf,\n    min_order_size_value: float = 1.0,\n    max_lev: float = 100.0,\n    size_pct: PossibleArray = np.nan,\n    size_value: PossibleArray = np.nan,\n    # Stop Losses\n    sl_pcts: PossibleArray = np.nan,\n    sl_to_be: bool = False,\n    sl_to_be_based_on: PossibleArray = np.nan,\n    sl_to_be_when_pct_from_avg_entry: PossibleArray = np.nan,\n    sl_to_be_zero_or_entry: PossibleArray = np.nan,  # 0 for zero or 1 for entry\n    sl_to_be_then_trail: bool = False,\n    sl_to_be_trail_by_when_pct_from_avg_entry: PossibleArray = np.nan,\n    # Trailing Stop Loss Params\n    tsl_pcts_init: PossibleArray = np.nan,\n    tsl_true_or_false: bool = False,\n    tsl_based_on: PossibleArray = np.nan,\n    tsl_trail_by_pct: PossibleArray = np.nan,\n    tsl_when_pct_from_avg_entry: PossibleArray = np.nan,\n    # Take Profit Params\n    risk_rewards: PossibleArray = np.nan,\n    tp_pcts: PossibleArray = np.nan,\n    # Results Filters\n    gains_pct_filter: float = -np.inf,\n    total_trade_filter: int = 0,\n    divide_records_array_size_by: float = 1.0,  # between 1 and 1000\n    upside_filter: float = -1.0,  # between -1 and 1\n) -&gt; tuple[pdFrame, pdFrame]:\n\"\"\"\n     Function Name\n    -------------\n        backtest_df_only\n\n    Quick Summary\n    -------------\n        The main way to backtest your strategy.\n        I highly highly highly suggest watching the explainer video\n        I explain what everything does and means in great detail.\n\n\n    Explainer Video\n    ---------------\n        https://youtu.be/yDNPhgO-450\n\n    Parameters\n    ----------\n    prices : pdFrame\n        Dataframe of prices\n    entries : pdFrame\n        Dataframe of entries\n    equity : float\n        Starting equity. I suggest only doing 100 or 1000 dollars\n    fee_pct : float\n        Fees percent\n    mmr_pct : float\n        maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this\n    lev_mode : int\n        Selecting your leverage mode. Look in the enums api section for LeverageMode\n    order_type : int\n        Selecting your order type. Please only use long short or both. Look in the enums api section for OrderType\n    size_type : int\n        Selecting your size type. Look in the enums api section for SizeType\n    leverage : PossibleArray, optional\n        If your leverage mode is isolated this is where you put in how much leverage you want to use., by default np.nan\n    max_equity_risk_pct : PossibleArray, optional\n        What is the max equity percent you want to possibly risk, by default np.nan\n    max_equity_risk_value : PossibleArray, optional\n        _description_, by default np.nan\n    max_order_size_pct : float, optional\n        _description_, by default 100.0\n    min_order_size_pct : float, optional\n        _description_, by default 0.01\n    max_order_size_value : float, optional\n        _description_, by default np.inf\n    min_order_size_value : float, optional\n        _description_, by default 1.0\n    max_lev : float, optional\n        _description_, by default 100.0\n    size_pct : PossibleArray, optional\n        _description_, by default np.nan\n    size_value : PossibleArray, optional\n        _description_, by default np.nan\n    sl_pcts : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be : bool, optional\n        _description_, by default False\n    sl_to_be_based_on : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_zero_or_entry : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_trail_by_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_pcts_init : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_true_or_false : bool, optional\n        _description_, by default False\n    tsl_based_on : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_trail_by_pct : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    risk_rewards : PossibleArray, optional\n        _description_, by default np.nan\n    tp_pcts : PossibleArray, optional\n        _description_, by default np.nan\n    gains_pct_filter : float, optional\n        _description_, by default -np.inf\n    total_trade_filter : int, optional\n        _description_, by default 0\n    divide_records_array_size_by : float, optional\n        If you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more.\n\n        If you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1.\n\n        This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million, by default 1.0\n\n    Returns\n    -------\n    tuple[pdFrame, pdFrame]\n        First return is a dataframe of strategy results.\n        Second return is a dataframe of the indicator and order settings.\n    \"\"\"\n    print(\"Checking static variables for errors or conflicts.\")\n    # Static checks\n    static_variables_tuple = static_var_checker_nb(\n        divide_records_array_size_by=divide_records_array_size_by,\n        equity=equity,\n        fee_pct=fee_pct,\n        gains_pct_filter=gains_pct_filter,\n        lev_mode=lev_mode,\n        max_lev=max_lev,\n        max_order_size_pct=max_order_size_pct,\n        max_order_size_value=max_order_size_value,\n        min_order_size_pct=min_order_size_pct,\n        min_order_size_value=min_order_size_value,\n        mmr_pct=mmr_pct,\n        order_type=order_type,\n        size_type=size_type,\n        sl_to_be_then_trail=sl_to_be_then_trail,\n        sl_to_be=sl_to_be,\n        total_trade_filter=total_trade_filter,\n        tsl_true_or_false=tsl_true_or_false,\n        upside_filter=upside_filter,\n    )\n    print(\"Turning all variables into arrays.\")\n    # Create 1d Arrays\n    arrays_1d_tuple = create_1d_arrays_nb(\n        leverage=leverage,\n        max_equity_risk_pct=max_equity_risk_pct,\n        max_equity_risk_value=max_equity_risk_value,\n        risk_rewards=risk_rewards,\n        size_pct=size_pct,\n        size_value=size_value,\n        sl_pcts=sl_pcts,\n        sl_to_be_based_on=sl_to_be_based_on,\n        sl_to_be_trail_by_when_pct_from_avg_entry=sl_to_be_trail_by_when_pct_from_avg_entry,\n        sl_to_be_when_pct_from_avg_entry=sl_to_be_when_pct_from_avg_entry,\n        sl_to_be_zero_or_entry=sl_to_be_zero_or_entry,\n        tp_pcts=tp_pcts,\n        tsl_based_on=tsl_based_on,\n        tsl_pcts_init=tsl_pcts_init,\n        tsl_trail_by_pct=tsl_trail_by_pct,\n        tsl_when_pct_from_avg_entry=tsl_when_pct_from_avg_entry,\n    )\n    print(\n        \"Checking arrays for errors or conflicts ... the backtest will begin shortly, please hold.\"\n    )\n    # Checking all new arrays\n    check_1d_arrays_nb(\n        arrays_1d_tuple=arrays_1d_tuple,\n        static_variables_tuple=static_variables_tuple,\n    )\n\n    print(\n        \"Creating cartesian product ... after this the backtest will start, I promise :).\\n\"\n    )\n    cart_array_tuple = create_cart_product_nb(arrays_1d_tuple=arrays_1d_tuple)\n\n    num_of_symbols = len(prices.columns.levels[0])\n\n    # Creating Settings Vars\n    total_order_settings = cart_array_tuple.sl_pcts.shape[0]\n\n    total_indicator_settings = entries.shape[1]\n\n    total_bars = entries.shape[0]\n\n    # Printing out total numbers of things\n    print(\n        \"Starting the backtest now ... and also here are some stats for your backtest.\\n\"\n    )\n    print(f\"Total symbols: {num_of_symbols:,}\")\n    print(\n        f\"Total indicator settings per symbol: {int(total_indicator_settings / num_of_symbols):,}\"\n    )\n    print(f\"Total indicator settings to test: {total_indicator_settings:,}\")\n    print(f\"Total order settings per symbol: {total_order_settings:,}\")\n    print(f\"Total order settings to test: {total_order_settings * num_of_symbols:,}\")\n    print(f\"Total candles per symbol: {total_bars:,}\")\n    print(\n        f\"Total candles to test: {total_indicator_settings * total_order_settings * total_bars:,}\"\n    )\n    print(\n        f\"\\nTotal combinations to test: {total_indicator_settings * total_order_settings:,}\"\n    )\n\n    strat_array, settings_array = backtest_df_only_nb(\n        cart_array_tuple=cart_array_tuple,\n        entries=entries.values,\n        gains_pct_filter=gains_pct_filter,\n        num_of_symbols=num_of_symbols,\n        og_equity=equity,\n        prices=prices.values,\n        static_variables_tuple=static_variables_tuple,\n        total_bars=total_bars,\n        total_indicator_settings=total_indicator_settings,\n        total_order_settings=total_order_settings,\n        total_trade_filter=total_trade_filter,\n    )\n\n    strat_results_df = pd.DataFrame(strat_array).sort_values(\n        by=[\"to_the_upside\", \"gains_pct\"], ascending=False\n    )\n\n    symbols = list(prices.columns.levels[0])\n\n    for i in range(len(symbols)):\n        strat_results_df.replace({\"symbol\": {i: symbols[i]}}, inplace=True)\n\n    symbols = list(entries.columns.levels[0])\n    setting_results_df = pd.DataFrame(settings_array).dropna(axis=\"columns\", thresh=1)\n\n    for i in range(len(SL_BE_or_Trail_BasedOn._fields)):\n        setting_results_df.replace(\n            {\"tsl_based_on\": {i: SL_BE_or_Trail_BasedOn._fields[i]}}, inplace=True\n        )\n        setting_results_df.replace(\n            {\"sl_to_be_based_on\": {i: SL_BE_or_Trail_BasedOn._fields[i]}}, inplace=True\n        )\n    for i in range(len(symbols)):\n        setting_results_df.replace({\"symbol\": {i: symbols[i]}}, inplace=True)\n\n    setting_results_df = setting_results_df.T\n\n    return strat_results_df, setting_results_df\n</code></pre>"},{"location":"api/data/","title":"Index","text":""},{"location":"api/data/#quantfreedom.data.CCXTData","title":"CCXTData","text":"Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>class CCXTData:\n    @classmethod\n    def data_download(\n        cls,\n        exchange: str,\n        start: str,\n        end: str,\n        symbols: Union[str, list],\n        timeframe: str,\n        drop_volume: bool = True,\n        remove_rate_limit: bool = False,\n        bars_per_loop: int = 200,\n    ):\n\"\"\"\n        Function name:\n            data_download \n\n        Quick Summary:\n            Download Data using CCXT\n\n        Explainer Video\n        ---------------\n            Coming_Soon\n\n        Parameters\n        ----------\n        cls: self\n            passing all the information from the created class\n\n        exchange : str\n            'bybit' or 'binance' or whatever exchange works with ccxt\n            http://docs.ccxt.com/#/README?id=exchanges\n\n        start : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        end : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        symbol : list or str\n            This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n            You can send this as a list of symbols or just one symbol.\n            Here is an example of how to get the symbols list from bybit.\n            ```python\n            import ccxt\n            exh = ccxt.bybit()\n            exh.load_markets()\n            exh.symbols\n            ```\n\n        timeframe : str\n            '1m', '5m', '1h' '4h' '1d' '1w'\n\n        drop_volume: bool = True\n            Set this to False if you want to keep volume data.\n\n        remove_rate_limit: bool = False\n            This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n        bars_per_loop: int = 200\n            How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n        Returns\n        -------\n            Pandas dataframe of prices\n        \"\"\"\n        if remove_rate_limit:\n            exchange = getattr(ccxt, exchange)()\n        else:\n            exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n        print(\"Loading exchange data\")\n        exchange.load_markets()\n        # exchange.verbose = True  # uncomment for debugging purposes if necessary\n        start = exchange.parse8601(start)\n        end = exchange.parse8601(end)\n        timeframe = timeframe.lower()\n        if not isinstance(symbols, list):\n            symbols = [symbols]\n        if not all(isinstance(x, str) for x in symbols):\n            raise ValueError(\"your symbols must be strings\")\n\n        symbols = sorted(symbols)\n        timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n        timeframe_str = sub(r\"\\d\", \"\", timeframe)\n        len_symbols = len(symbols)\n        if timeframe_str == \"m\":\n            time_in = 1000 * 60\n        elif timeframe_str == \"h\":\n            time_in = 1000 * 60 * 60\n        elif timeframe_str == \"d\":\n            time_in = 1000 * 60 * 60 * 24\n        elif timeframe_str == \"w\":\n            time_in = 1000 * 60 * 60 * 24 * 7\n        elif timeframe_str == \"m\":\n            time_in = 1000 * 60 * 60 * 24 * 7 * 12\n        else:\n            raise ValueError(\"something wrong with your timeframe\")\n\n        x = start\n        timelist = [x]\n        while x &lt; end:\n            x += time_in * timeframe_int\n            timelist.append(x)\n\n        final_df = pd.DataFrame(\n            columns=pd.MultiIndex.from_tuples(\n                tuples=[],\n                name=[\"symbol\", \"candle_info\"],\n            ),\n            index=pd.Index(\n                data=pd.to_datetime(timelist, unit=\"ms\"),\n                name=\"open_time\",\n            ),\n        )\n        # Example if you selected your timeframe as 30 minute candles\n\n        # Get the distance between the end date and start date in miliseconds\n        # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n        # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n        # Then divide by limit because that is the amount of rows of data you can return\n        # Then add one because that is the amount of loops we will have to do\n        # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n        # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n        num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n        total_tqdm = (\n            (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n        ) + len_symbols\n        print(\n            f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n            f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n            f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n        )\n        with tqdm(total=total_tqdm) as pbar:\n            # with tqdm(total=96*2) as pbar:\n            for symbol in symbols:\n                all_ohlcvs = []\n                temp_end = end\n                pbar.set_description(f\"Downloading {symbol}\")\n                while True:\n                    try:\n                        ohlcvs = exchange.fetch_ohlcv(\n                            symbol=symbol,\n                            timeframe=timeframe,\n                            since=start,\n                            limit=bars_per_loop,\n                            params={\"end\": temp_end},\n                        )\n                        all_ohlcvs += ohlcvs\n                        if len(ohlcvs):\n                            temp_end = ohlcvs[0][0] - 1\n                            pbar.update(1)\n                        else:\n                            break\n\n                    except Exception as e:\n                        print(type(e).__name__, str(e))\n\n                if all_ohlcvs:\n                    all_ohlcvs = np.array(all_ohlcvs)\n                    data_columns = pd.MultiIndex.from_tuples(\n                        [\n                            (symbol, \"open\"),\n                            (symbol, \"high\"),\n                            (symbol, \"low\"),\n                            (symbol, \"close\"),\n                            (symbol, \"volume\"),\n                        ],\n                        name=[\"symbol\", \"candle_info\"],\n                    )\n                    data_index = pd.Index(\n                        data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                        name=\"open_time\",\n                    )\n                    data = pd.DataFrame(\n                        all_ohlcvs[:, 1:],\n                        columns=data_columns,\n                        index=data_index,\n                    )\n                    if drop_volume:\n                        data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                    final_df = final_df.join(data)\n                pbar.update(1)\n        final_df.sort_index(ascending=True, inplace=True)\n        final_df.sort_index(axis=1, level=0, sort_remaining=False)\n        final_df.dropna(how='all', inplace=True)\n        final_df.drop(final_df.tail(1).index, inplace=True)\n        return final_df\n</code></pre>"},{"location":"api/data/#quantfreedom.data.ccxtdata.CCXTData.data_download","title":"data_download  <code>classmethod</code>","text":"<pre><code>data_download(\n    exchange,\n    start,\n    end,\n    symbols,\n    timeframe,\n    drop_volume=True,\n    remove_rate_limit=False,\n    bars_per_loop=200,\n)\n</code></pre> <p>Function name:     data_download </p> <p>Quick Summary:     Download Data using CCXT</p>"},{"location":"api/data/#quantfreedom.data.ccxtdata.CCXTData.data_download--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre> <p>Parameters:</p> <ul> <li> cls         \u2013 <p>passing all the information from the created class</p> </li> <li> exchange             (<code>str</code>)         \u2013 <p>'bybit' or 'binance' or whatever exchange works with ccxt http://docs.ccxt.com/#/README?id=exchanges</p> </li> </ul> <p>start : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>end : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>symbol : list or str     This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.     You can send this as a list of symbols or just one symbol.     Here is an example of how to get the symbols list from bybit.     <pre><code>import ccxt\nexh = ccxt.bybit()\nexh.load_markets()\nexh.symbols\n</code></pre></p> <p>timeframe : str     '1m', '5m', '1h' '4h' '1d' '1w'</p> <p>drop_volume: bool = True     Set this to False if you want to keep volume data.</p> <p>remove_rate_limit: bool = False     This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.</p> <p>bars_per_loop: int = 200     How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.</p> <p>Returns:</p> <ul> <li> <code>    Pandas dataframe of prices</code>         \u2013        </li> </ul> Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>@classmethod\ndef data_download(\n    cls,\n    exchange: str,\n    start: str,\n    end: str,\n    symbols: Union[str, list],\n    timeframe: str,\n    drop_volume: bool = True,\n    remove_rate_limit: bool = False,\n    bars_per_loop: int = 200,\n):\n\"\"\"\n    Function name:\n        data_download \n\n    Quick Summary:\n        Download Data using CCXT\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Parameters\n    ----------\n    cls: self\n        passing all the information from the created class\n\n    exchange : str\n        'bybit' or 'binance' or whatever exchange works with ccxt\n        http://docs.ccxt.com/#/README?id=exchanges\n\n    start : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    end : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    symbol : list or str\n        This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n        You can send this as a list of symbols or just one symbol.\n        Here is an example of how to get the symbols list from bybit.\n        ```python\n        import ccxt\n        exh = ccxt.bybit()\n        exh.load_markets()\n        exh.symbols\n        ```\n\n    timeframe : str\n        '1m', '5m', '1h' '4h' '1d' '1w'\n\n    drop_volume: bool = True\n        Set this to False if you want to keep volume data.\n\n    remove_rate_limit: bool = False\n        This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n    bars_per_loop: int = 200\n        How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n    Returns\n    -------\n        Pandas dataframe of prices\n    \"\"\"\n    if remove_rate_limit:\n        exchange = getattr(ccxt, exchange)()\n    else:\n        exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n    print(\"Loading exchange data\")\n    exchange.load_markets()\n    # exchange.verbose = True  # uncomment for debugging purposes if necessary\n    start = exchange.parse8601(start)\n    end = exchange.parse8601(end)\n    timeframe = timeframe.lower()\n    if not isinstance(symbols, list):\n        symbols = [symbols]\n    if not all(isinstance(x, str) for x in symbols):\n        raise ValueError(\"your symbols must be strings\")\n\n    symbols = sorted(symbols)\n    timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n    timeframe_str = sub(r\"\\d\", \"\", timeframe)\n    len_symbols = len(symbols)\n    if timeframe_str == \"m\":\n        time_in = 1000 * 60\n    elif timeframe_str == \"h\":\n        time_in = 1000 * 60 * 60\n    elif timeframe_str == \"d\":\n        time_in = 1000 * 60 * 60 * 24\n    elif timeframe_str == \"w\":\n        time_in = 1000 * 60 * 60 * 24 * 7\n    elif timeframe_str == \"m\":\n        time_in = 1000 * 60 * 60 * 24 * 7 * 12\n    else:\n        raise ValueError(\"something wrong with your timeframe\")\n\n    x = start\n    timelist = [x]\n    while x &lt; end:\n        x += time_in * timeframe_int\n        timelist.append(x)\n\n    final_df = pd.DataFrame(\n        columns=pd.MultiIndex.from_tuples(\n            tuples=[],\n            name=[\"symbol\", \"candle_info\"],\n        ),\n        index=pd.Index(\n            data=pd.to_datetime(timelist, unit=\"ms\"),\n            name=\"open_time\",\n        ),\n    )\n    # Example if you selected your timeframe as 30 minute candles\n\n    # Get the distance between the end date and start date in miliseconds\n    # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n    # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n    # Then divide by limit because that is the amount of rows of data you can return\n    # Then add one because that is the amount of loops we will have to do\n    # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n    # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n    num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n    total_tqdm = (\n        (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n    ) + len_symbols\n    print(\n        f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n        f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n        f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n    )\n    with tqdm(total=total_tqdm) as pbar:\n        # with tqdm(total=96*2) as pbar:\n        for symbol in symbols:\n            all_ohlcvs = []\n            temp_end = end\n            pbar.set_description(f\"Downloading {symbol}\")\n            while True:\n                try:\n                    ohlcvs = exchange.fetch_ohlcv(\n                        symbol=symbol,\n                        timeframe=timeframe,\n                        since=start,\n                        limit=bars_per_loop,\n                        params={\"end\": temp_end},\n                    )\n                    all_ohlcvs += ohlcvs\n                    if len(ohlcvs):\n                        temp_end = ohlcvs[0][0] - 1\n                        pbar.update(1)\n                    else:\n                        break\n\n                except Exception as e:\n                    print(type(e).__name__, str(e))\n\n            if all_ohlcvs:\n                all_ohlcvs = np.array(all_ohlcvs)\n                data_columns = pd.MultiIndex.from_tuples(\n                    [\n                        (symbol, \"open\"),\n                        (symbol, \"high\"),\n                        (symbol, \"low\"),\n                        (symbol, \"close\"),\n                        (symbol, \"volume\"),\n                    ],\n                    name=[\"symbol\", \"candle_info\"],\n                )\n                data_index = pd.Index(\n                    data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                    name=\"open_time\",\n                )\n                data = pd.DataFrame(\n                    all_ohlcvs[:, 1:],\n                    columns=data_columns,\n                    index=data_index,\n                )\n                if drop_volume:\n                    data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                final_df = final_df.join(data)\n            pbar.update(1)\n    final_df.sort_index(ascending=True, inplace=True)\n    final_df.sort_index(axis=1, level=0, sort_remaining=False)\n    final_df.dropna(how='all', inplace=True)\n    final_df.drop(final_df.tail(1).index, inplace=True)\n    return final_df\n</code></pre>"},{"location":"api/data/ccxtdata/","title":"Ccxtdata","text":""},{"location":"api/data/ccxtdata/#quantfreedom.data.ccxtdata.CCXTData","title":"CCXTData","text":"Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>class CCXTData:\n    @classmethod\n    def data_download(\n        cls,\n        exchange: str,\n        start: str,\n        end: str,\n        symbols: Union[str, list],\n        timeframe: str,\n        drop_volume: bool = True,\n        remove_rate_limit: bool = False,\n        bars_per_loop: int = 200,\n    ):\n\"\"\"\n        Function name:\n            data_download \n\n        Quick Summary:\n            Download Data using CCXT\n\n        Explainer Video\n        ---------------\n            Coming_Soon\n\n        Parameters\n        ----------\n        cls: self\n            passing all the information from the created class\n\n        exchange : str\n            'bybit' or 'binance' or whatever exchange works with ccxt\n            http://docs.ccxt.com/#/README?id=exchanges\n\n        start : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        end : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        symbol : list or str\n            This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n            You can send this as a list of symbols or just one symbol.\n            Here is an example of how to get the symbols list from bybit.\n            ```python\n            import ccxt\n            exh = ccxt.bybit()\n            exh.load_markets()\n            exh.symbols\n            ```\n\n        timeframe : str\n            '1m', '5m', '1h' '4h' '1d' '1w'\n\n        drop_volume: bool = True\n            Set this to False if you want to keep volume data.\n\n        remove_rate_limit: bool = False\n            This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n        bars_per_loop: int = 200\n            How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n        Returns\n        -------\n            Pandas dataframe of prices\n        \"\"\"\n        if remove_rate_limit:\n            exchange = getattr(ccxt, exchange)()\n        else:\n            exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n        print(\"Loading exchange data\")\n        exchange.load_markets()\n        # exchange.verbose = True  # uncomment for debugging purposes if necessary\n        start = exchange.parse8601(start)\n        end = exchange.parse8601(end)\n        timeframe = timeframe.lower()\n        if not isinstance(symbols, list):\n            symbols = [symbols]\n        if not all(isinstance(x, str) for x in symbols):\n            raise ValueError(\"your symbols must be strings\")\n\n        symbols = sorted(symbols)\n        timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n        timeframe_str = sub(r\"\\d\", \"\", timeframe)\n        len_symbols = len(symbols)\n        if timeframe_str == \"m\":\n            time_in = 1000 * 60\n        elif timeframe_str == \"h\":\n            time_in = 1000 * 60 * 60\n        elif timeframe_str == \"d\":\n            time_in = 1000 * 60 * 60 * 24\n        elif timeframe_str == \"w\":\n            time_in = 1000 * 60 * 60 * 24 * 7\n        elif timeframe_str == \"m\":\n            time_in = 1000 * 60 * 60 * 24 * 7 * 12\n        else:\n            raise ValueError(\"something wrong with your timeframe\")\n\n        x = start\n        timelist = [x]\n        while x &lt; end:\n            x += time_in * timeframe_int\n            timelist.append(x)\n\n        final_df = pd.DataFrame(\n            columns=pd.MultiIndex.from_tuples(\n                tuples=[],\n                name=[\"symbol\", \"candle_info\"],\n            ),\n            index=pd.Index(\n                data=pd.to_datetime(timelist, unit=\"ms\"),\n                name=\"open_time\",\n            ),\n        )\n        # Example if you selected your timeframe as 30 minute candles\n\n        # Get the distance between the end date and start date in miliseconds\n        # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n        # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n        # Then divide by limit because that is the amount of rows of data you can return\n        # Then add one because that is the amount of loops we will have to do\n        # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n        # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n        num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n        total_tqdm = (\n            (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n        ) + len_symbols\n        print(\n            f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n            f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n            f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n        )\n        with tqdm(total=total_tqdm) as pbar:\n            # with tqdm(total=96*2) as pbar:\n            for symbol in symbols:\n                all_ohlcvs = []\n                temp_end = end\n                pbar.set_description(f\"Downloading {symbol}\")\n                while True:\n                    try:\n                        ohlcvs = exchange.fetch_ohlcv(\n                            symbol=symbol,\n                            timeframe=timeframe,\n                            since=start,\n                            limit=bars_per_loop,\n                            params={\"end\": temp_end},\n                        )\n                        all_ohlcvs += ohlcvs\n                        if len(ohlcvs):\n                            temp_end = ohlcvs[0][0] - 1\n                            pbar.update(1)\n                        else:\n                            break\n\n                    except Exception as e:\n                        print(type(e).__name__, str(e))\n\n                if all_ohlcvs:\n                    all_ohlcvs = np.array(all_ohlcvs)\n                    data_columns = pd.MultiIndex.from_tuples(\n                        [\n                            (symbol, \"open\"),\n                            (symbol, \"high\"),\n                            (symbol, \"low\"),\n                            (symbol, \"close\"),\n                            (symbol, \"volume\"),\n                        ],\n                        name=[\"symbol\", \"candle_info\"],\n                    )\n                    data_index = pd.Index(\n                        data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                        name=\"open_time\",\n                    )\n                    data = pd.DataFrame(\n                        all_ohlcvs[:, 1:],\n                        columns=data_columns,\n                        index=data_index,\n                    )\n                    if drop_volume:\n                        data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                    final_df = final_df.join(data)\n                pbar.update(1)\n        final_df.sort_index(ascending=True, inplace=True)\n        final_df.sort_index(axis=1, level=0, sort_remaining=False)\n        final_df.dropna(how='all', inplace=True)\n        final_df.drop(final_df.tail(1).index, inplace=True)\n        return final_df\n</code></pre>"},{"location":"api/data/ccxtdata/#quantfreedom.data.ccxtdata.CCXTData.data_download","title":"data_download  <code>classmethod</code>","text":"<pre><code>data_download(\n    exchange,\n    start,\n    end,\n    symbols,\n    timeframe,\n    drop_volume=True,\n    remove_rate_limit=False,\n    bars_per_loop=200,\n)\n</code></pre> <p>Function name:     data_download </p> <p>Quick Summary:     Download Data using CCXT</p>"},{"location":"api/data/ccxtdata/#quantfreedom.data.ccxtdata.CCXTData.data_download--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre> <p>Parameters:</p> <ul> <li> cls         \u2013 <p>passing all the information from the created class</p> </li> <li> exchange             (<code>str</code>)         \u2013 <p>'bybit' or 'binance' or whatever exchange works with ccxt http://docs.ccxt.com/#/README?id=exchanges</p> </li> </ul> <p>start : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>end : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>symbol : list or str     This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.     You can send this as a list of symbols or just one symbol.     Here is an example of how to get the symbols list from bybit.     <pre><code>import ccxt\nexh = ccxt.bybit()\nexh.load_markets()\nexh.symbols\n</code></pre></p> <p>timeframe : str     '1m', '5m', '1h' '4h' '1d' '1w'</p> <p>drop_volume: bool = True     Set this to False if you want to keep volume data.</p> <p>remove_rate_limit: bool = False     This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.</p> <p>bars_per_loop: int = 200     How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.</p> <p>Returns:</p> <ul> <li> <code>    Pandas dataframe of prices</code>         \u2013        </li> </ul> Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>@classmethod\ndef data_download(\n    cls,\n    exchange: str,\n    start: str,\n    end: str,\n    symbols: Union[str, list],\n    timeframe: str,\n    drop_volume: bool = True,\n    remove_rate_limit: bool = False,\n    bars_per_loop: int = 200,\n):\n\"\"\"\n    Function name:\n        data_download \n\n    Quick Summary:\n        Download Data using CCXT\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Parameters\n    ----------\n    cls: self\n        passing all the information from the created class\n\n    exchange : str\n        'bybit' or 'binance' or whatever exchange works with ccxt\n        http://docs.ccxt.com/#/README?id=exchanges\n\n    start : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    end : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    symbol : list or str\n        This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n        You can send this as a list of symbols or just one symbol.\n        Here is an example of how to get the symbols list from bybit.\n        ```python\n        import ccxt\n        exh = ccxt.bybit()\n        exh.load_markets()\n        exh.symbols\n        ```\n\n    timeframe : str\n        '1m', '5m', '1h' '4h' '1d' '1w'\n\n    drop_volume: bool = True\n        Set this to False if you want to keep volume data.\n\n    remove_rate_limit: bool = False\n        This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n    bars_per_loop: int = 200\n        How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n    Returns\n    -------\n        Pandas dataframe of prices\n    \"\"\"\n    if remove_rate_limit:\n        exchange = getattr(ccxt, exchange)()\n    else:\n        exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n    print(\"Loading exchange data\")\n    exchange.load_markets()\n    # exchange.verbose = True  # uncomment for debugging purposes if necessary\n    start = exchange.parse8601(start)\n    end = exchange.parse8601(end)\n    timeframe = timeframe.lower()\n    if not isinstance(symbols, list):\n        symbols = [symbols]\n    if not all(isinstance(x, str) for x in symbols):\n        raise ValueError(\"your symbols must be strings\")\n\n    symbols = sorted(symbols)\n    timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n    timeframe_str = sub(r\"\\d\", \"\", timeframe)\n    len_symbols = len(symbols)\n    if timeframe_str == \"m\":\n        time_in = 1000 * 60\n    elif timeframe_str == \"h\":\n        time_in = 1000 * 60 * 60\n    elif timeframe_str == \"d\":\n        time_in = 1000 * 60 * 60 * 24\n    elif timeframe_str == \"w\":\n        time_in = 1000 * 60 * 60 * 24 * 7\n    elif timeframe_str == \"m\":\n        time_in = 1000 * 60 * 60 * 24 * 7 * 12\n    else:\n        raise ValueError(\"something wrong with your timeframe\")\n\n    x = start\n    timelist = [x]\n    while x &lt; end:\n        x += time_in * timeframe_int\n        timelist.append(x)\n\n    final_df = pd.DataFrame(\n        columns=pd.MultiIndex.from_tuples(\n            tuples=[],\n            name=[\"symbol\", \"candle_info\"],\n        ),\n        index=pd.Index(\n            data=pd.to_datetime(timelist, unit=\"ms\"),\n            name=\"open_time\",\n        ),\n    )\n    # Example if you selected your timeframe as 30 minute candles\n\n    # Get the distance between the end date and start date in miliseconds\n    # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n    # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n    # Then divide by limit because that is the amount of rows of data you can return\n    # Then add one because that is the amount of loops we will have to do\n    # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n    # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n    num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n    total_tqdm = (\n        (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n    ) + len_symbols\n    print(\n        f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n        f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n        f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n    )\n    with tqdm(total=total_tqdm) as pbar:\n        # with tqdm(total=96*2) as pbar:\n        for symbol in symbols:\n            all_ohlcvs = []\n            temp_end = end\n            pbar.set_description(f\"Downloading {symbol}\")\n            while True:\n                try:\n                    ohlcvs = exchange.fetch_ohlcv(\n                        symbol=symbol,\n                        timeframe=timeframe,\n                        since=start,\n                        limit=bars_per_loop,\n                        params={\"end\": temp_end},\n                    )\n                    all_ohlcvs += ohlcvs\n                    if len(ohlcvs):\n                        temp_end = ohlcvs[0][0] - 1\n                        pbar.update(1)\n                    else:\n                        break\n\n                except Exception as e:\n                    print(type(e).__name__, str(e))\n\n            if all_ohlcvs:\n                all_ohlcvs = np.array(all_ohlcvs)\n                data_columns = pd.MultiIndex.from_tuples(\n                    [\n                        (symbol, \"open\"),\n                        (symbol, \"high\"),\n                        (symbol, \"low\"),\n                        (symbol, \"close\"),\n                        (symbol, \"volume\"),\n                    ],\n                    name=[\"symbol\", \"candle_info\"],\n                )\n                data_index = pd.Index(\n                    data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                    name=\"open_time\",\n                )\n                data = pd.DataFrame(\n                    all_ohlcvs[:, 1:],\n                    columns=data_columns,\n                    index=data_index,\n                )\n                if drop_volume:\n                    data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                final_df = final_df.join(data)\n            pbar.update(1)\n    final_df.sort_index(ascending=True, inplace=True)\n    final_df.sort_index(axis=1, level=0, sort_remaining=False)\n    final_df.dropna(how='all', inplace=True)\n    final_df.drop(final_df.tail(1).index, inplace=True)\n    return final_df\n</code></pre>"},{"location":"api/enums/","title":"Index","text":""},{"location":"api/enums/enums/","title":"Enums","text":"<p>Enums</p> <p>Warning</p> <p>\u2620\ufe0fTHIS IS A MASSIVE MASSIVE WARNING.\u2620\ufe0f</p> <p>Make sure you follow what the variable types are. If it says float you have to make sure you put a         decimal like 1. or 3., or if it says int that you make sure there are no decimals.</p> <p>If you do not follow exactly what the type says for you to do then numba will start crying and wont run your code.</p> <p>Then you will be sitting there for hours trying to debug what is wrong and then you will find out it is because you put a number as an int instead of a float</p> <p>Danger</p> <p>All inputs requiring you to tell it what percent you want something to be should be put in like 1. for 1% or 50. for 50%.</p> <p>If you put .01 for 1% the math will calculate it as .0001.</p>"},{"location":"api/enums/enums/#quantfreedom.enums.enums.RejectedOrderError","title":"RejectedOrderError","text":"<p>         Bases: <code>Exception</code></p> <p>Rejected order error.</p> Source code in <code>quantfreedom\\enums\\enums.py</code> <pre><code>class RejectedOrderError(Exception):\n\"\"\"Rejected order error.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/evaluators/","title":"Index","text":""},{"location":"api/evaluators/evaluators/","title":"Evaluators","text":""},{"location":"api/evaluators/evaluators/#quantfreedom.evaluators.evaluators.combine_evals","title":"combine_evals","text":"<pre><code>combine_evals(\n    first_eval_data,\n    second_eval_data,\n    plot_results=False,\n    first_eval_data_needs_prices=False,\n    second_eval_data_needs_prices=False,\n    prices=None,\n    first_ind_data=None,\n    second_ind_data=None,\n)\n</code></pre> <p>summary</p> <p>Parameters:</p> <ul> <li> first_eval_data             (<code>pdFrame</code>)         \u2013 <p>description</p> </li> <li> second_eval_data             (<code>pdFrame</code>)         \u2013 <p>description</p> </li> <li> plot_results             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> first_eval_data_needs_prices             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> second_eval_data_needs_prices             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> prices             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> first_ind_data             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> second_ind_data             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pdFrame</code>         \u2013 <p>description</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> </ul> Source code in <code>quantfreedom\\evaluators\\evaluators.py</code> <pre><code>def combine_evals(\n    first_eval_data: pdFrame,\n    second_eval_data: pdFrame,\n    plot_results: bool = False,\n    first_eval_data_needs_prices: bool = False,\n    second_eval_data_needs_prices: bool = False,\n    prices: pdFrame = None,\n    first_ind_data: pdFrame = None,\n    second_ind_data: pdFrame = None,\n) -&gt; pdFrame:\n\"\"\"\n    _summary_\n\n    Parameters\n    ----------\n    first_eval_data : pdFrame\n        _description_\n    second_eval_data : pdFrame\n        _description_\n    plot_results : bool, optional\n        _description_, by default False\n    first_eval_data_needs_prices : bool, optional\n        _description_, by default False\n    second_eval_data_needs_prices : bool, optional\n        _description_, by default False\n    prices : pdFrame, optional\n        _description_, by default None\n    first_ind_data : pdFrame, optional\n        _description_, by default None\n    second_ind_data : pdFrame, optional\n        _description_, by default None\n\n    Returns\n    -------\n    pdFrame\n        _description_\n\n    Raises\n    ------\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    \"\"\"\n\n    if plot_results and (first_ind_data is None or second_ind_data is None):\n        raise ValueError(\n            \"Make sure you are sending first and second indicator data if you want to plot\")\n    elif plot_results:\n        if first_eval_data_needs_prices and prices is None:\n            raise ValueError(\"You need to provide prices to plot the candles\")\n        elif not first_eval_data_needs_prices and prices is not None:\n            raise ValueError(\n                \"Make sure you set first_eval_data_needs_prices to true if you want to send price data\")\n    elif not plot_results and (\n        first_eval_data_needs_prices or\n        prices is not None or\n        first_ind_data is not None or\n        second_ind_data is not None\n    ):\n        raise ValueError(\n            \"Make sure you set plot_results to true if you want to send any plotting data.\")\n\n    if len(first_eval_data.columns.levels) &lt; len(second_eval_data.columns.levels):\n        temp = len(first_eval_data.columns.levels)\n    else:\n        temp = len(second_eval_data.columns.levels)\n\n    list_for_product = []\n    pd_col_names = []\n    for x in range(temp):\n        if list(first_eval_data.columns.levels[x]) == list(second_eval_data.columns.levels[x]):\n            list_for_product.append(list(first_eval_data.columns.levels[x]))\n            pd_col_names.append(first_eval_data.columns.names[x])\n    levels = list(product(*list_for_product))\n\n    pd_col_names = pd_col_names + list(first_eval_data.droplevel(pd_col_names, axis=1).columns.names) + \\\n        list(second_eval_data.droplevel(pd_col_names, axis=1).columns.names)\n\n    combine_array = np.empty(\n        (first_eval_data.shape[0], first_eval_data[levels[0]].shape[1] * second_eval_data[levels[0]].shape[1] * len(levels)), dtype=np.bool_\n    )\n\n    try:\n        second_eval_data[levels[0]].columns[0][0]\n        temp_smaller_def_columns = list(second_eval_data[levels[0]].columns)\n    except:\n        temp_smaller_def_columns = []\n        for value in list(second_eval_data[levels[0]].columns):\n            temp_smaller_def_columns.append((value,))\n\n    try:\n        first_eval_data[levels[0]].columns[0][0]\n        temp_big_def_columns = list(first_eval_data[levels[0]].columns)\n    except:\n        temp_big_def_columns = []\n        for value in list(first_eval_data[levels[0]].columns):\n            temp_big_def_columns.append((value,))\n\n    comb_counter = 0\n    pd_multind_tuples = ()\n    for level in levels:\n        temp_big_df = first_eval_data[level]\n        temp_small_df = second_eval_data[level]\n        for big_count, big_values in enumerate(temp_big_df.values.T):\n\n            for small_count, small_values in enumerate(temp_small_df.values.T):\n\n                combine_array[:, comb_counter] = np.logical_and(\n                    big_values == True, small_values == True\n                )\n\n                pd_multind_tuples = pd_multind_tuples + (\n                    level + temp_big_def_columns[big_count] +\n                    temp_smaller_def_columns[small_count],\n                )\n\n                comb_counter += 1\n\n    if plot_results:\n        plot_index = second_eval_data.index\n\n        temp_first_ind_data = first_ind_data.iloc[:, -1]\n        temp_second_ind_data = second_ind_data.iloc[:, -1]\n\n        temp_combine_array = combine_array[:, -1]\n\n        # candle data with subplot\n        if first_eval_data_needs_prices and not second_eval_data_needs_prices:\n            temp_prices = prices[list(prices.columns)[-1][0]]\n            fig = make_subplots(\n                rows=2,\n                cols=1,\n                shared_xaxes=True,\n            )\n            fig.add_traces(\n                data=[\n                    go.Candlestick(\n                        x=plot_index,\n                        open=temp_prices.open,\n                        high=temp_prices.high,\n                        low=temp_prices.low,\n                        close=temp_prices.close,\n                        name=\"Candles\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_first_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='#60BFE1'),\n                        name=\"First Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_first_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n                rows=1,\n                cols=1,\n            )\n            fig.add_traces(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_second_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=2, color='#60BFE1'),\n                        name=\"Second Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_second_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n                rows=2,\n                cols=1,\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=700, title=\"Last Column of the Results\")\n            fig.show()\n\n        elif first_eval_data_needs_prices and second_eval_data_needs_prices:\n            temp_prices = prices[list(prices.columns)[-1][0]]\n            fig = go.Figure(\n                data=[\n                    go.Candlestick(\n                        x=plot_index,\n                        open=temp_prices.open,\n                        high=temp_prices.high,\n                        low=temp_prices.low,\n                        close=temp_prices.close,\n                        name=\"Candles\",\n                    ),\n\n                    # First Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_first_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='#60BFE1'),\n                        name=\"First Ind\",\n                    ),\n\n                    # Second Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_second_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='#84E5AC'),\n                        name=\"Second Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_second_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n        elif not first_eval_data_needs_prices and not second_eval_data_needs_prices:\n            fig = go.Figure(\n                data=[\n                    # First Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_first_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=2, color='green'),\n                        name=\"First Ind\",\n                    ),\n\n                    # Second Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_second_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='red'),\n                        name=\"Second Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_second_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n    return pd.DataFrame(\n        combine_array,\n        index=second_eval_data.index,\n        columns=pd.MultiIndex.from_tuples(\n            tuples=list(pd_multind_tuples),\n            names=pd_col_names,\n        ),\n    )\n</code></pre>"},{"location":"api/evaluators/evaluators/#quantfreedom.evaluators.evaluators.eval_is_below","title":"eval_is_below","text":"<pre><code>eval_is_below(\n    want_to_evaluate,\n    user_args=None,\n    indicator_data=None,\n    prices=None,\n    cand_ohlc=None,\n    plot_results=False,\n)\n</code></pre> <p>summary</p> <p>Parameters:</p> <ul> <li> want_to_evaluate             (<code>pdFrame</code>)         \u2013 <p>description</p> </li> <li> user_args             (<code>Union[list[int, float], int, float, Array1d], optional</code>)         \u2013 <p>description, by default None</p> </li> <li> indicator_data             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> prices             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> cand_ohlc             (<code>str, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> plot_results             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pdFrame</code>         \u2013 <p>description</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> </ul> Source code in <code>quantfreedom\\evaluators\\evaluators.py</code> <pre><code>def eval_is_below(\n    want_to_evaluate: pdFrame,\n    user_args: Union[list[int, float], int, float, Array1d] = None,\n    indicator_data: pdFrame = None,\n    prices: pdFrame = None,\n    cand_ohlc: str = None,\n    plot_results: bool = False,\n) -&gt; pdFrame:\n\"\"\"\n    _summary_\n\n    Parameters\n    ----------\n    want_to_evaluate : pdFrame\n        _description_\n    user_args : Union[list[int, float], int, float, Array1d], optional\n        _description_, by default None\n    indicator_data : pdFrame, optional\n        _description_, by default None\n    prices : pdFrame, optional\n        _description_, by default None\n    cand_ohlc : str, optional\n        _description_, by default None\n    plot_results : bool, optional\n        _description_, by default False\n\n    Returns\n    -------\n    pdFrame\n        _description_\n\n    Raises\n    ------\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    \"\"\"\n    if not isinstance(want_to_evaluate, pdFrame):\n        raise ValueError(\"Data must be a dataframe with multindex\")\n\n    want_to_evaluate_values = want_to_evaluate.values\n    want_to_evaluate_name = want_to_evaluate.columns.names[1].split(\"_\")[0]\n    pd_col_names = list(want_to_evaluate.columns.names) + [\n        want_to_evaluate_name + \"_is_below\"\n    ]\n    pd_multind_tuples = ()\n\n    if isinstance(user_args, (list, Array1d)):\n        if not all(isinstance(x, (int, float, np.int_, np.float_)) for x in user_args):\n            raise ValueError(\"user_args must be a list of ints or floats\")\n        user_args = np.asarray(user_args)\n\n        eval_array = np.empty(\n            (want_to_evaluate.shape[0], want_to_evaluate.shape[1] * user_args.size), dtype=np.bool_\n        )\n\n        eval_array_counter = 0\n        temp_eval_values = want_to_evaluate.values.T\n        for count, value in enumerate(want_to_evaluate.values.T):\n            for eval_col in range(user_args.size):\n                eval_array[:, eval_array_counter] = np.where(\n                    value &lt; user_args[eval_col], True, False\n                )\n                eval_array_counter += 1\n\n                pd_multind_tuples = pd_multind_tuples + (\n                    want_to_evaluate.columns[count] + (user_args[eval_col],),\n                )\n\n        if plot_results:\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=4),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n    elif isinstance(prices, pdFrame):\n        if cand_ohlc == None or cand_ohlc.lower() not in (\n            \"open\",\n            \"high\",\n            \"low\",\n            \"close\",\n        ):\n            raise ValueError(\n                \"cand_ohlc must be open, high, low or close when sending price data\"\n            )\n\n        eval_array = np.empty_like(want_to_evaluate, dtype=np.bool_)\n        symbols = list(prices.columns.levels[0])\n        eval_array_counter = 0\n\n        for symbol in symbols:\n            temp_prices_values = prices[symbol][cand_ohlc].values\n            if not all(isinstance(x, (np.int_, np.float_)) for x in temp_prices_values):\n                raise ValueError(\"price data must be ints or floats\")\n\n            temp_eval_values = want_to_evaluate[symbol].values.T\n\n            for values in temp_eval_values:\n                eval_array[:, eval_array_counter] = np.where(\n                    values &lt; temp_prices_values, True, False\n                )\n\n                pd_multind_tuples = pd_multind_tuples + (\n                    want_to_evaluate.columns[eval_array_counter] +\n                    (cand_ohlc,),\n                )\n                eval_array_counter += 1\n\n        if plot_results:\n            temp_prices = prices[prices.columns.levels[0][-1]]\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Candlestick(\n                        x=plot_index,\n                        open=temp_prices.open,\n                        high=temp_prices.high,\n                        low=temp_prices.low,\n                        close=temp_prices.close,\n                        name=\"Candles\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=4, color='lightblue'),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n        return pd.DataFrame(\n            eval_array,\n            index=want_to_evaluate.index,\n            columns=pd.MultiIndex.from_tuples(\n                tuples=list(pd_multind_tuples),\n                names=pd_col_names,\n            ),\n        ).swaplevel(1, -1, axis=1)\n\n    elif isinstance(indicator_data, pdFrame):\n        want_to_evaluate_name = want_to_evaluate.columns.names[-1].split(\"_\")[\n            1]\n        indicator_data_name = indicator_data.columns.names[-1].split(\"_\")[0]\n\n        pd_col_names = list(want_to_evaluate.columns.names) + [\n            want_to_evaluate_name + \"_is_below\"\n        ]\n\n        want_to_evaluate_settings_tuple_list = want_to_evaluate.columns.to_list()\n\n        eval_array = np.empty_like(want_to_evaluate,  dtype=np.bool_,)\n        pd_multind_tuples = ()\n\n        indicator_data_levels = list(indicator_data.columns)\n        eval_array_counter = 0\n\n        for level in indicator_data_levels:\n            temp_indicator_values = indicator_data[level].values\n            temp_evaluate_values = want_to_evaluate[level].values.T\n\n            for values in temp_evaluate_values:\n                eval_array[:, eval_array_counter] = np.where(\n                    values &lt; temp_indicator_values,\n                    True,\n                    False,\n                )\n                pd_multind_tuples = pd_multind_tuples + \\\n                    (want_to_evaluate_settings_tuple_list[eval_array_counter] + (\n                        indicator_data_name,),)\n                eval_array_counter += 1\n\n        if plot_results:\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            temp_ind_values = indicator_data.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_ind_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=4),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n    elif isinstance(user_args, (int, float)):\n        eval_array = np.where(want_to_evaluate_values &lt; user_args, True, False)\n\n        for col in range(want_to_evaluate.shape[1]):\n            pd_multind_tuples = pd_multind_tuples + (\n                want_to_evaluate.columns[col] + (user_args,),\n            )\n\n        if plot_results:\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=4),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n    else:\n        raise ValueError(\n            \"something is wrong with what you sent please make sure the type of variable you are sending matches with the type required\"\n        )\n    return pd.DataFrame(\n        eval_array,\n        index=want_to_evaluate.index,\n        columns=pd.MultiIndex.from_tuples(\n            tuples=list(pd_multind_tuples),\n            names=pd_col_names,\n        ),\n    )\n</code></pre>"},{"location":"api/indicators/","title":"Index","text":""},{"location":"api/indicators/talib_ind/","title":"Talib ind","text":""},{"location":"api/nb/","title":"Index","text":""},{"location":"api/nb/buy_funcs/","title":"Buy funcs","text":""},{"location":"api/nb/buy_funcs/#quantfreedom.nb.buy_funcs.long_decrease_nb","title":"long_decrease_nb","text":"<pre><code>long_decrease_nb(\n    fee_pct,\n    order_result,\n    account_state,\n)\n</code></pre> <p>This is where the long position gets decreased or closed out.</p> Source code in <code>quantfreedom\\nb\\buy_funcs.py</code> <pre><code>@njit(cache=True)\ndef long_decrease_nb(\n    fee_pct: float,\n    order_result: OrderResult,\n    account_state: AccountState,\n):\n\"\"\"\n    This is where the long position gets decreased or closed out.\n    \"\"\"\n\n    if order_result.size_value &gt;= order_result.position:\n        size_value = order_result.position\n    else:\n        size_value = order_result.size_value\n\n    pct_chg_trade = (\n        order_result.price - order_result.average_entry\n    ) / order_result.average_entry  # math checked\n\n    # Set new order_result.position size_value and cash borrowed and cash used\n    position_new = order_result.position - size_value\n    position_pct_chg = (\n        order_result.position - position_new\n    ) / order_result.position  # math checked\n\n    # profit and loss calulation\n    coin_size = size_value / order_result.average_entry  # math checked\n    pnl = coin_size * (order_result.price - order_result.average_entry)  # math checked\n    fee_open = coin_size * order_result.average_entry * fee_pct  # math checked\n    fee_close = coin_size * order_result.price * fee_pct  # math checked\n    fees_paid = fee_open + fee_close  # math checked\n    realized_pnl = pnl - fees_paid  # math checked\n\n    # Setting new account_state.equity\n    equity_new = account_state.equity + realized_pnl\n\n    cash_borrowed_new = account_state.cash_borrowed - (\n        account_state.cash_borrowed * position_pct_chg\n    )\n\n    cash_used_new = account_state.cash_used - (\n        account_state.cash_used * position_pct_chg\n    )\n\n    available_balance_new = (\n        realized_pnl\n        + account_state.available_balance\n        + (account_state.cash_used * position_pct_chg)\n    )\n\n    return AccountState(\n        available_balance=available_balance_new,\n        cash_borrowed=cash_borrowed_new,\n        cash_used=cash_used_new,\n        equity=equity_new,\n    ), OrderResult(\n        average_entry=order_result.average_entry,\n        fees_paid=fees_paid,\n        leverage=order_result.leverage,\n        liq_price=order_result.liq_price,\n        moved_sl_to_be=order_result.moved_sl_to_be,\n        order_status=OrderStatus.Filled,\n        order_status_info=OrderStatusInfo.HopefullyNoProblems,\n        order_type=order_result.order_type,\n        pct_chg_trade=pct_chg_trade,\n        position=position_new,\n        price=order_result.price,\n        realized_pnl=realized_pnl,\n        size_value=size_value,\n        sl_pcts=order_result.sl_pcts,\n        sl_prices=order_result.sl_prices,\n        tp_pcts=order_result.tp_pcts,\n        tp_prices=order_result.tp_prices,\n        tsl_pcts_init=order_result.tsl_pcts_init,\n        tsl_prices=order_result.tsl_prices,\n    )\n</code></pre>"},{"location":"api/nb/execute_funcs/","title":"Execute funcs","text":"<p>Testing the tester</p>"},{"location":"api/nb/helper_funcs/","title":"Helper funcs","text":""},{"location":"api/nb/helper_funcs/#quantfreedom.nb.helper_funcs.to_1d_array_nb","title":"to_1d_array_nb","text":"<pre><code>to_1d_array_nb(\n    var,\n)\n</code></pre> <p>Resize array to one dimension.</p> Source code in <code>quantfreedom\\nb\\helper_funcs.py</code> <pre><code>@njit(cache=True)\ndef to_1d_array_nb(var: PossibleArray) -&gt; Array1d:\n\"\"\"Resize array to one dimension.\"\"\"\n    if var.ndim == 0:\n        return np.expand_dims(var, axis=0)\n    if var.ndim == 1:\n        return var\n    if var.ndim == 2 and var.shape[1] == 1:\n        return var[:, 0]\n    raise ValueError(\"to 1d array problem\")\n</code></pre>"},{"location":"api/nb/sell_funcs/","title":"Sell funcs","text":""},{"location":"api/nb/sell_funcs/#quantfreedom.nb.sell_funcs.short_decrease_nb","title":"short_decrease_nb","text":"<pre><code>short_decrease_nb(\n    fee_pct,\n    order_result,\n    account_state,\n)\n</code></pre> <p>This is where the long position gets decreased or closed out.</p> Source code in <code>quantfreedom\\nb\\sell_funcs.py</code> <pre><code>@njit(cache=True)\ndef short_decrease_nb(\n    fee_pct: float,\n    order_result: OrderResult,\n    account_state: AccountState,\n):\n\"\"\"\n    This is where the long position gets decreased or closed out.\n    \"\"\"\n\n    if order_result.size_value &gt;= order_result.position:\n        size_value = order_result.position\n    else:\n        size_value = order_result.size_value\n\n    pct_chg_trade = (\n        order_result.average_entry - order_result.price\n    ) / order_result.average_entry  # math checked\n\n    # Set new order_result.position size_value and cash borrowed and cash used\n    position_new = order_result.position - size_value\n    position_pct_chg = (\n        order_result.position - position_new\n    ) / order_result.position  # math checked\n\n    # profit and loss calulation\n    coin_size = size_value / order_result.average_entry  # math checked\n    pnl = coin_size * (order_result.average_entry - order_result.price)  # math checked\n    fee_open = coin_size * order_result.average_entry * fee_pct  # math checked\n    fee_close = coin_size * order_result.price * fee_pct  # math checked\n    fees_paid = fee_open + fee_close  # math checked\n    realized_pnl = pnl - fees_paid  # math checked\n\n    # Setting new account_state.equity\n    equity_new = account_state.equity + realized_pnl\n\n    cash_borrowed_new = account_state.cash_borrowed - (\n        account_state.cash_borrowed * position_pct_chg\n    )\n\n    cash_used_new = account_state.cash_used - (\n        account_state.cash_used * position_pct_chg\n    )\n\n    available_balance_new = (\n        realized_pnl\n        + account_state.available_balance\n        + (account_state.cash_used * position_pct_chg)\n    )\n\n    return AccountState(\n        available_balance=available_balance_new,\n        cash_borrowed=cash_borrowed_new,\n        cash_used=cash_used_new,\n        equity=equity_new,\n    ), OrderResult(\n        average_entry=order_result.average_entry,\n        fees_paid=fees_paid,\n        leverage=order_result.leverage,\n        liq_price=order_result.liq_price,\n        moved_sl_to_be=order_result.moved_sl_to_be,\n        order_status=OrderStatus.Filled,\n        order_status_info=OrderStatusInfo.HopefullyNoProblems,\n        order_type=order_result.order_type,\n        pct_chg_trade=pct_chg_trade,\n        position=position_new,\n        price=order_result.price,\n        realized_pnl=realized_pnl,\n        size_value=size_value,\n        sl_pcts=order_result.sl_pcts,\n        sl_prices=order_result.sl_prices,\n        tp_pcts=order_result.tp_pcts,\n        tp_prices=order_result.tp_prices,\n        tsl_pcts_init=order_result.tsl_pcts_init,\n        tsl_prices=order_result.tsl_prices,\n    )\n</code></pre>"},{"location":"api/nb/simulate/","title":"Simulate","text":""},{"location":"api/nb/temp/","title":"Temp","text":""},{"location":"api/plotting/","title":"Index","text":""},{"location":"api/plotting/plot_helper_functions/","title":"Plot helper functions","text":""},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list","title":"append_to_trace_data_list","text":"<pre><code>append_to_trace_data_list(\n    trace_data_list,\n    dict_key,\n    dict_value,\n    index_prices,\n    temp_ind_vals,\n)\n</code></pre>"},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list--function-name","title":"Function Name","text":"<pre><code>append_to_trace_data_list\n</code></pre>"},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list--quick-summary","title":"Quick Summary","text":"<pre><code>appending value or entry scatter plots to the trace data list\n</code></pre>"},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list--required-parameters","title":"Required Parameters","text":"<p>Variable Name: Variable Type</p> <p>trace_data_list: list     trace data list dict_key: str     either values or entries dict_value: pdFrame     dataframe of either an indicator or entries index_prices: pdIndex     index temp_ind_vals: pdFrame     needed so we can use this if the dict key is entries so we can generate temp_ind_entries</p> Source code in <code>quantfreedom\\plotting\\plot_helper_functions.py</code> <pre><code>def append_to_trace_data_list(\n    trace_data_list: list,\n    dict_key: str,\n    dict_value: pdFrame,\n    index_prices: pdIndex,\n    temp_ind_vals: pdFrame,\n):\n\"\"\"\n    Function Name\n    -------------\n        append_to_trace_data_list\n\n    Quick Summary\n    -------------\n        appending value or entry scatter plots to the trace data list\n\n    Required Parameters\n    -------------------\n    Variable Name: Variable Type\n\n    trace_data_list: list\n        trace data list\n    dict_key: str\n        either values or entries\n    dict_value: pdFrame\n        dataframe of either an indicator or entries\n    index_prices: pdIndex\n        index\n    temp_ind_vals: pdFrame\n        needed so we can use this if the dict key is entries so we can generate temp_ind_entries\n    \"\"\"\n    if \"values\" in dict_key:\n        temp_ind_vals[0] = dict_value.values.flatten()\n        ind_name = list(dict_value.columns.names)[1].split(\"_\")[0]\n        ind_value = str(list(dict_value.columns)[0][0])\n        trace_data_list.append(\n            go.Scatter(\n                x=index_prices,\n                y=temp_ind_vals[0],\n                mode=\"lines\",\n                name=ind_name + \" \" + ind_value,\n            )\n        )\n    elif \"entries\" in dict_key:\n        temp_ind_entries = np.where(\n            dict_value.values.flatten(), temp_ind_vals[0], np.nan\n        ).flatten()\n        trace_data_list.append(\n            go.Scatter(\n                x=index_prices,\n                y=temp_ind_entries,\n                mode=\"markers\",\n                name=\"Signals\",\n            )\n        )\n</code></pre>"},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data","title":"get_candle_trace_data","text":"<pre><code>get_candle_trace_data(\n    index_prices,\n    prices,\n    order_records,\n    indicator_dict,\n)\n</code></pre>"},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data--function-name","title":"Function Name","text":"<pre><code>get_candle_trace_data\n</code></pre>"},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data--quick-summary","title":"Quick Summary","text":"<pre><code>Here we take all the info needed to create a candlestick chart and also place indicators on top of the candle stick chart\n</code></pre>"},{"location":"api/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data--required-parameters","title":"Required Parameters","text":"<p>Variable Name: Variable Type</p> <p>index_prices: pdIndex     index prices: pdFrame     price dataframe order_records: RecordArray     order records indicator_dict: dict     dictionary of candle stick and indicator data</p> <p>Returns:</p> <ul> <li> <code>list</code>         \u2013 <p>list of Candle stick chart and indicators data for plotly</p> </li> </ul> Source code in <code>quantfreedom\\plotting\\plot_helper_functions.py</code> <pre><code>def get_candle_trace_data(\n    index_prices: pdIndex,\n    prices: pdFrame,\n    order_records: RecordArray,\n    indicator_dict: dict,\n)-&gt; list:\n\"\"\"\n    Function Name\n    -------------\n        get_candle_trace_data\n\n    Quick Summary\n    -------------\n        Here we take all the info needed to create a candlestick chart and also place indicators on top of the candle stick chart\n\n    Required Parameters\n    -------------------\n    Variable Name: Variable Type\n\n    index_prices: pdIndex\n        index\n    prices: pdFrame\n        price dataframe\n    order_records: RecordArray\n        order records\n    indicator_dict: dict\n        dictionary of candle stick and indicator data\n\n    Returns\n    -------\n    list\n        list of Candle stick chart and indicators data for plotly\n    \"\"\"\n    array_size = prices.shape[0]\n\n    order_price_array = np.full(array_size, np.nan)\n    avg_entry_array = np.full(array_size, np.nan)\n    stop_loss_array = np.full(array_size, np.nan)\n    trailing_sl_array = np.full(array_size, np.nan)\n    take_profit_array = np.full(array_size, np.nan)\n\n    or_counter = 0\n    array_counter = 0\n\n    avg_entry_current = np.array([0.0])\n    stop_loss_current = np.array([0.0])\n    trailing_sl_current = np.array([0.0])\n    take_profit_current = np.array([0.0])\n\n    for i in range(array_size):\n        if or_counter &lt; order_records.size and order_records[\"bar\"][or_counter] == i:\n            fill_candle_trace_trades(\n                order_records=order_records[or_counter],\n                order_price_array=order_price_array,\n                avg_entry_array=avg_entry_array,\n                stop_loss_array=stop_loss_array,\n                trailing_sl_array=trailing_sl_array,\n                take_profit_array=take_profit_array,\n                avg_entry_current=avg_entry_current,\n                stop_loss_current=stop_loss_current,\n                trailing_sl_current=trailing_sl_current,\n                take_profit_current=take_profit_current,\n                array_counter=array_counter,\n            )\n            or_counter += 1\n\n            if (\n                or_counter &lt; order_records.size\n                and order_records[\"bar\"][or_counter] == i\n            ):\n                fill_candle_trace_trades(\n                    order_records=order_records[or_counter],\n                    order_price_array=order_price_array,\n                    avg_entry_array=avg_entry_array,\n                    stop_loss_array=stop_loss_array,\n                    trailing_sl_array=trailing_sl_array,\n                    take_profit_array=take_profit_array,\n                    avg_entry_current=avg_entry_current,\n                    stop_loss_current=stop_loss_current,\n                    trailing_sl_current=trailing_sl_current,\n                    take_profit_current=take_profit_current,\n                    array_counter=array_counter,\n                )\n            or_counter += 1\n        array_counter += 1\n    trace_data_list = cerate_candle_trace_trades_list(\n        index_prices=index_prices,\n        prices=prices,\n        order_price_array=order_price_array,\n        avg_entry=avg_entry_array,\n        stop_loss=stop_loss_array,\n        trailing_sl=trailing_sl_array,\n        take_profit=take_profit_array,\n    )\n    if list(indicator_dict.keys())[0] == \"candle_chart\":\n        temp_ind_vals = np.array([0], dtype=object)\n        for candle_ind_key, candle_ind_value in indicator_dict[\"candle_chart\"].items():\n            append_to_trace_data_list(\n                trace_data_list,\n                index_prices=index_prices,\n                dict_key=candle_ind_key,\n                dict_value=candle_ind_value,\n                temp_ind_vals=temp_ind_vals,\n            )\n    return trace_data_list\n</code></pre>"},{"location":"api/plotting/plotting_main/","title":"Plotting main","text":""},{"location":"api/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard","title":"strat_dashboard","text":"<pre><code>strat_dashboard(\n    indicator_dict,\n    prices,\n    order_records,\n)\n</code></pre>"},{"location":"api/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--function-name","title":"Function Name","text":"<pre><code>strat_dashboard\n</code></pre>"},{"location":"api/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--quick-summary","title":"Quick Summary","text":"<pre><code>Creates a dashboard with your trades, indicators, cumliative PnL and the order records of all the trades.\n</code></pre>"},{"location":"api/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre>"},{"location":"api/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--required-parameters","title":"Required Parameters","text":"<p>Variable Name: Variable Type</p> <p>indicator_dict: dict     You need to create a dictionary of all your indicators.</p> <pre><code>If you have any indicators that need to go on the candle stick chart then make a key named candle_chart and inside of that you put your indicator values with keys called value with a number after it like in the example, then you provide the entries\n\nIf you have indicators that need their own chart then create a key called indicator with a number after it and then provide the indicator values and the entries in new keys.\n\nExample:\n    indicator_dict = {\n            \"candle_chart\": {\n                \"values1\": ema_300_ind[[('BTCUSDT', 300)]],\n                \"values2\": ema_600_ind[[('BTCUSDT', 600)]],\n                \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                },\n            \"indicator1\": {\n                \"values1\": rsi_ind[[('BTCUSDT', 30)]],\n                \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                },\n            \"indicator2\": {\n                \"values1\": atr_ind[[('BTCUSDT', 50)]],\n                \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                },\n            }\n</code></pre> <p>prices: pdFrame     Your prices info as one symbol like prices['BTCUSDT']</p> <p>order_records: RecordArray     Order Records</p> <p>Returns:</p> <ul> <li> <code>JupyterDash</code>         \u2013 <p>Returns a jupyter dashboard that will open up in a new window when you click on the local host url</p> </li> </ul> Source code in <code>quantfreedom\\plotting\\plotting_main.py</code> <pre><code>def strat_dashboard(\n    indicator_dict: dict,\n    prices: pdFrame,\n    order_records: RecordArray,\n) -&gt; JupyterDash:\n\"\"\"\n    Function Name\n    -------------\n        strat_dashboard\n\n    Quick Summary\n    -------------\n        Creates a dashboard with your trades, indicators, cumliative PnL and the order records of all the trades.\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Required Parameters\n    -------------------\n    Variable Name: Variable Type\n\n    indicator_dict: dict\n        You need to create a dictionary of all your indicators.\n\n        If you have any indicators that need to go on the candle stick chart then make a key named candle_chart and inside of that you put your indicator values with keys called value with a number after it like in the example, then you provide the entries\n\n        If you have indicators that need their own chart then create a key called indicator with a number after it and then provide the indicator values and the entries in new keys.\n\n        Example:\n            indicator_dict = {\n                    \"candle_chart\": {\n                        \"values1\": ema_300_ind[[('BTCUSDT', 300)]],\n                        \"values2\": ema_600_ind[[('BTCUSDT', 600)]],\n                        \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                        },\n                    \"indicator1\": {\n                        \"values1\": rsi_ind[[('BTCUSDT', 30)]],\n                        \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                        },\n                    \"indicator2\": {\n                        \"values1\": atr_ind[[('BTCUSDT', 50)]],\n                        \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                        },\n                    }\n    prices: pdFrame\n        Your prices info as one symbol like prices['BTCUSDT']\n\n    order_records: RecordArray\n        Order Records\n\n    Returns\n    -------\n    JupyterDash\n        Returns a jupyter dashboard that will open up in a new window when you click on the local host url\n    \"\"\"\n\n    amount_of_subplots = 0\n\n    for keys in indicator_dict.keys():\n        if \"indicator\" in keys:\n            amount_of_subplots += 1\n\n    layout_height = 500 + (250 * amount_of_subplots)\n    candle_chart_height_pct = [500 / layout_height]\n\n    if amount_of_subplots &gt; 0:\n        subchart_heights_pct = np.array(\n            [((layout_height - 500) / layout_height) / amount_of_subplots]\n            * amount_of_subplots\n        ).tolist()\n        row_heights = candle_chart_height_pct + subchart_heights_pct\n        fig = make_subplots(\n            rows=amount_of_subplots + 1,\n            cols=1,\n            shared_xaxes=True,\n            vertical_spacing=0.02,\n            row_heights=row_heights,\n        )\n    else:\n        fig = make_subplots()\n\n    index_prices = prices.index.to_list()\n\n    # candle chart trace\n    fig.add_traces(\n        data=get_candle_trace_data(\n            index_prices=index_prices,\n            prices=prices,\n            order_records=order_records,\n            indicator_dict=indicator_dict,\n        ),\n        rows=1,\n        cols=1,\n    )\n    try:\n        del indicator_dict[\"candle_chart\"]\n    except:\n        pass\n\n    row_count = 2\n    for indicator_dict_value in indicator_dict.values():\n        trace_data_list = []\n        temp_ind_vals = np.array([0], dtype=object)\n        for ind_key, ind_value in indicator_dict_value.items():\n            append_to_trace_data_list(\n                trace_data_list=trace_data_list,\n                index_prices=index_prices,\n                dict_key=ind_key,\n                dict_value=ind_value,\n                temp_ind_vals=temp_ind_vals,\n            )\n        fig.add_traces(\n            data=trace_data_list,\n            rows=row_count,\n            cols=1,\n        )\n        row_count += 1\n    fig.update_xaxes(row=1, col=1, rangeslider_visible=False)\n    fig.update_yaxes(row=1, col=1, tickprefix=\"$\")\n    fig.update_layout(\n        height=layout_height,\n        paper_bgcolor=bg_color,\n        plot_bgcolor=bg_color,\n    )\n    candle_trades_and_ind = (\n        html.H1(\n            \"All Trades For This Strategy\",\n            style={\n                \"textAlign\": \"center\",\n                \"font-weight\": \"bold\",\n                \"font-size\": \"5em\",\n                \"padding-top\": \"20px\",\n            },\n        ),\n        dcc.Graph(\n            id=\"candles-trades\",\n            figure=fig,\n        ),\n    )\n\n    y_pnl = np.append(\n        0,\n        order_records[\"real_pnl\"][~np.isnan(order_records[\"real_pnl\"])].cumsum(),\n    )\n\n    pnl_graph = go.Figure(\n        data=[\n            go.Scatter(\n                x=np.arange(0, y_pnl.size),\n                y=y_pnl,\n                mode=\"lines+markers\",\n                marker=dict(size=6),\n                line=dict(color=\"#247eb2\"),\n            ),\n        ]\n    ).update_layout(\n        paper_bgcolor=bg_color,\n        plot_bgcolor=bg_color,\n    )\n    pnl_graph.update_yaxes(tickprefix=\"$\"),\n\n    pnl_graph = (\n        html.H1(\n            \"Cumulative PnL Over Time\",\n            style={\n                \"textAlign\": \"center\",\n                \"font-weight\": \"bold\",\n            },\n        ),\n        dcc.Graph(\n            id=\"pnl-graph\",\n            figure=pnl_graph,\n        ),\n    )\n\n    d_table = pd.DataFrame(order_records)\n    for i in range(len(OrderType._fields)):\n        d_table.replace({\"order_type\": {i: OrderType._fields[i]}}, inplace=True)\n\n    for col in d_table:\n        if d_table[col].dtype == \"float64\":\n            d_table[col] = d_table[col].map(\"{:,.2f}\".format)\n    d_table = d_table.to_dict(\"records\")\n\n    d_table = (\n        html.H1(\n            \"Table of All Orders\",\n            style={\n                \"textAlign\": \"center\",\n                \"font-weight\": \"bold\",\n            },\n        ),\n        dash_table.DataTable(\n            data=d_table,\n            id=\"d-table\",\n            page_size=50,\n            # page_action='none',\n            style_table={\"height\": \"400px\", \"overflowY\": \"auto\"},\n            fixed_rows={\"headers\": True},\n            style_header={\"backgroundColor\": \"rgb(30, 30, 30)\", \"color\": \"white\"},\n            style_data={\"backgroundColor\": \"rgb(50, 50, 50)\", \"color\": \"white\"},\n            style_cell_conditional=[\n                {\"if\": {\"column_id\": \"settings_id\"}, \"width\": \"110px\"},\n                {\"if\": {\"column_id\": \"order_id\"}, \"width\": \"90px\"},\n            ],\n        ),\n    )\n\n    app.layout = html.Div(\n        [\n            html.Div(\n                candle_trades_and_ind,\n            ),\n            html.Div(\n                pnl_graph,\n            ),\n            html.Div(\n                d_table,\n            ),\n        ]\n    )\n\n    return app.run_server(debug=True, port=3003)\n</code></pre>"},{"location":"api/plotting/replay/","title":"Replay","text":""},{"location":"api/plotting/temp/","title":"Temp","text":""},{"location":"api/utils/","title":"Index","text":""},{"location":"api/utils/#quantfreedom.utils.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache()\n</code></pre> <p>clears the python cache and numba cache</p> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def clear_cache():\n\"\"\"\n    clears the python cache and numba cache\n    \"\"\"\n    for p in Path(dir_path).parent.parent.rglob(\"numba_cache\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"__pycache__\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"*.py[co]\"):\n        p.unlink()\n</code></pre>"},{"location":"api/utils/#quantfreedom.utils.pretty","title":"pretty","text":"<pre><code>pretty(\n    object,\n)\n</code></pre> <p>Prints named tuples in a pretty way like StopOrder(     var1=54,     var2=1000,     var3=2.45, )</p> <p>Parameters:</p> <ul> <li> object             (<code>namedtuple</code>)         \u2013 <p>must only be a named tuple</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def pretty(\n    object: tuple,\n):\n\"\"\"\n    Prints named tuples in a pretty way like\n    StopOrder(\n        var1=54,\n        var2=1000,\n        var3=2.45,\n    )\n\n    Parameters\n    ----------\n    object : namedtuple\n        must only be a named tuple\n    \"\"\"\n    try:\n        object._fields[0]\n        items = []\n        indent = str(\"    \")\n        for x in range(len(object)):\n            items.append(indent + object._fields[x] + \" = \" + str(object[x]) + \",\\n\")\n        print(type(object).__name__ + \"(\" + \"\\n\" + \"\".join(items) + \")\")\n    except:\n        print(object)\n</code></pre>"},{"location":"api/utils/helpers/","title":"Helpers","text":""},{"location":"api/utils/helpers/#quantfreedom.utils.helpers.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache()\n</code></pre> <p>clears the python cache and numba cache</p> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def clear_cache():\n\"\"\"\n    clears the python cache and numba cache\n    \"\"\"\n    for p in Path(dir_path).parent.parent.rglob(\"numba_cache\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"__pycache__\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"*.py[co]\"):\n        p.unlink()\n</code></pre>"},{"location":"api/utils/helpers/#quantfreedom.utils.helpers.delete_dir","title":"delete_dir","text":"<pre><code>delete_dir(\n    p,\n)\n</code></pre> <p>Delete info in directory</p> <p>Parameters:</p> <ul> <li> p             (<code>path</code>)         \u2013 <p>path to directory</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def delete_dir(\n    p,\n):\n\"\"\"\n    Delete info in directory\n\n    Parameters\n    ----------\n    p : path\n        path to directory\n    \"\"\"\n    for sub in p.iterdir():\n        if sub.is_dir():\n            delete_dir(sub)\n        else:\n            sub.unlink()\n    p.rmdir()\n</code></pre>"},{"location":"api/utils/helpers/#quantfreedom.utils.helpers.generate_candles","title":"generate_candles","text":"<pre><code>generate_candles(\n    number_of_candles=100,\n    seed=None,\n)\n</code></pre> <p>Generate a dataframe filled with random candles</p>"},{"location":"api/utils/helpers/#quantfreedom.utils.helpers.generate_candles--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre> <p>Parameters:</p> <ul> <li> number_of_candles             (<code>int</code>)         \u2013 <p>number of candles you want to create</p> </li> <li> seed             (<code>int</code>)         \u2013 <p>random seed number</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pdFrame</code>         \u2013 <p>Dataframe of open high low close</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def generate_candles(\n    number_of_candles: int = 100,\n    seed: int = None,\n) -&gt; pdFrame:\n\"\"\"\n    Generate a dataframe filled with random candles\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Parameters\n    ----------\n    number_of_candles: int = 100\n        number of candles you want to create\n    seed: int = None\n        random seed number\n\n    Returns\n    -------\n    pdFrame\n        Dataframe of open high low close\n    \"\"\"\n    np.random.seed(seed)\n\n    periods = number_of_candles * 48\n\n    prices = np.around(5000 + np.random.normal(scale=1.5, size=periods).cumsum(), 2)\n\n    data = pd.DataFrame(\n        prices,\n        index=pd.Index(\n            pd.date_range(\"01/01/2000\", periods=periods, freq=\"30min\"),\n            name=\"open_time\",\n        ),\n        columns=[\"price\"],\n    )\n    data = data.price.resample(\"D\").ohlc()\n\n    data.columns = pd.MultiIndex.from_tuples(\n        tuples=[\n            (\"QuantFreedom\", \"open\"),\n            (\"QuantFreedom\", \"high\"),\n            (\"QuantFreedom\", \"low\"),\n            (\"QuantFreedom\", \"close\"),\n        ],\n        name=[\"symbol\", \"candle_info\"],\n    )\n    fig = go.Figure(\n        data=go.Candlestick(\n            x=data.index,\n            open=data.iloc[:, 0],\n            high=data.iloc[:, 1],\n            low=data.iloc[:, 2],\n            close=data.iloc[:, 3],\n        )\n    )\n    fig.update_layout(xaxis_rangeslider_visible=False)\n    fig.show()\n\n    return data\n</code></pre>"},{"location":"api/utils/helpers/#quantfreedom.utils.helpers.pretty","title":"pretty","text":"<pre><code>pretty(\n    object,\n)\n</code></pre> <p>Prints named tuples in a pretty way like StopOrder(     var1=54,     var2=1000,     var3=2.45, )</p> <p>Parameters:</p> <ul> <li> object             (<code>namedtuple</code>)         \u2013 <p>must only be a named tuple</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def pretty(\n    object: tuple,\n):\n\"\"\"\n    Prints named tuples in a pretty way like\n    StopOrder(\n        var1=54,\n        var2=1000,\n        var3=2.45,\n    )\n\n    Parameters\n    ----------\n    object : namedtuple\n        must only be a named tuple\n    \"\"\"\n    try:\n        object._fields[0]\n        items = []\n        indent = str(\"    \")\n        for x in range(len(object)):\n            items.append(indent + object._fields[x] + \" = \" + str(object[x]) + \",\\n\")\n        print(type(object).__name__ + \"(\" + \"\\n\" + \"\".join(items) + \")\")\n    except:\n        print(object)\n</code></pre>"},{"location":"getting-started/install/","title":"Index Page","text":""},{"location":"getting-started/install/#how-to-install-via-cmd-line-using-vs-code","title":"How to install via cmd line using vs code","text":"<p>If you have any problems along the way make sure you message me and let me know what you are having a problem with ... i want these installation instructions to be perfect so anyone can install </p> <p>I am using vscode because it is so easy to use and you can use jupyter notebooks in it for free</p> <p>Before we start:</p> <p>To avoid all types of issues i would suggestion uninstalling anaconda and all of your python installations, unless you know for sure that you need those previous versions for other projects and everything ... or if you are familiar with python already and you know what you are doing you can keep them ... but there have been many pathing issues with having different versions and anaconda installed.</p> <p>So if you do not need to do any of this then you can move to the next section ... but if you do need to uninstall then go and uninstall all of your python versions and anaconda versions ... then go to the python website and download python 3.10.10 and then make sure you select add to path when installing and also install for all users. https://www.python.org/downloads/</p> <p>Then make sure you have git installed ... if you don't go to the git website and download git and install. To the best of my knowledge all you need to do is just hit next for everything but i also suggest at least reading some of the options. https://git-scm.com/downloads</p> <p>you may run into problems later on with git saying you need to fonfigure your user name and user email ... to check this in the cmd terminal type in git config --global --list ... then you should see your user email and user name ... for github ... if you don't then type git config --global user.name \"your_username\" git config --global user.email \"your_email_address@example.com\"</p> <p>once you have git and python installed we need to check to make sure you were able to add everything to the path properly so press your windows key and type edit the system environment variables then click on environment variables then double click on path and make sure your python 310 scripts and python 310 are at the top then you want your vs code bin below it ... so your order should look something like mine but i think the most important is that the python version you want to use is first  </p> <p>Now download vs code https://code.visualstudio.com/download and then go to the extensions tab and install python, jupyter and gitlens and also python environment manager</p> <p>once you have vscode installed launch it and then press ctrl shift p and then type in terminal select default profile .. then make sure you select cmd prompt as the default</p> <p>now you want to go to a location on your computer and create a folder called coding because this is where you will store your virtual environment and possibly the cloned repo</p> <p>if you want to help develop the backtester then go to the github link and star and fork the project https://github.com/QuantFreedom1022/QuantFreedom ... if not skip to the next step</p> <p>once you have forked it then grab the code of your forked project from the code button and copy the link</p> <p>once you have the link copied then go back to vs code and press ctrl shift p and type git clone and then past the link of the code or if you are signed into your github you can select the new fork from the drop down list</p> <p>i would then suggest cloning to the coding folder that you made</p> <p>ok this part is for everyone</p> <p>before we create the virtual env you have to make sure you are using the cmd prompt so go to terminal in the menu and select new terminal and then once the terminal pops up make sure you are in the cmd prompt. if you aren't and have changed your default to the cmd prompt then close out your vs code and open it again and it should work this time. It is super important that we are in the cmd prompt or this installation wont work</p> <p>if you are in the cmd prompt then make sure the folder location for the cmd prompt is the coding folder ... if it isn't use cd and type in the location of the coding folder like cd \"C:\\users\\my stuff\\coding\" ... make sure you use quotes because if you have spaces in some of your folder names you have to have quotes</p> <p>now that you are in the right folder we want to type  <pre><code>python -m venv qfFree\n</code></pre> this will create a virtual env named qfFree</p> <p>next we want to type  <code>qfFree\\Scripts\\activate</code>  to activate the virtual env ... this will make sure anything we install is in the virtual env and not on our global python which is super extra important</p> <p>if you are using  now we need to create a jupyter notebook kernel by typing this ipython kernel install --user --name=qfFree</p> <p>if you want to install the dev env then you have to type pip install -e then the location of your cloned repo like \"C:\\user\\mystuff\\coding\\QuantFreedom\" this will then install the backtester</p> <p>if you are just installing to use the backtester then type pip install -U git+https://github.com/QuantFreedom1022/quantfreedom</p> <p>once we have our venv created and everything is pip installed then we want to do control shift p and type select Interpreter to start jupyter server and then select the venv we just created that way it selects that venv every time we use jupyter</p> <p>also make sure you have auto save on by going to file preferences setting then type auto save and then select after delay ... for people working in dev env this is for making sure you see the auto updates in the source control for pushing new data and for people who are just working you always want your data saved ... unless you don't you can choose another auto save or turn it off</p> <p>make sure you are on the dev branch and then fetch the upstream then right click on the dev upstream and merge into current branch ... then sync your changes to update your origin branch</p> <p>You now should have created a virtual environment</p> <p>if you are using the dev env if you want to get the latest updates from my repo to keep your forked repo up to date then in the source control section of vs code which is usually under the magnified glass the weird looking 3 circle thing ... if you installed git lens you should see remotes and branches</p> <p>click on remotes and you should see upstream ... what you need to do is make sure you right click on upstream and do fetch all ... if you see there are updates then which ever branch you are on locally which you can tell in the lower left corner of the vscode window it should say dev or main or some branch name then you right click on the same name for upstream and select merge branch into current branch ... this will get all the changes from my repo and put them on your local hard drive ... then you need to sync those changes to your forked branch by just clicking sync changes</p> <p>this is why i highly highly highly suggest you work from your own folder and don't edit any original code because if you work on the same file as me and there are updates from both of us then there will be merge problems</p> <p>i would suggest making your own tests folder and also your own folder inside quantfreedom folder ... if you make your own folder in quantfreedom then make sure you add it to the init.py file inside the quant freedom or it wont work ... then you have to add init.py files to all the folders you make inside of your folder ... you want to do this to avoid merging problems</p> <p>This should be it ... i highly suggest watching the video about installation as i know i am probably missed some things ... but if i do please let me know so i cam make these instructions better ... also don't forget to install talib</p> <p>Installation Problems</p> <p>Installation Problems</p> <p>If you have any trouble or run into installation errors then what i have found is if i shutdown vscode then open it back up and then reactivate my virtual environment then pip install again it is able to make the full install</p>"},{"location":"getting-started/install/#install-ta-lib","title":"Install TA-Lib","text":"<p>To install ta lib you need to do the following</p> <ul> <li>Go to this website https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib </li> <li>Download the one that has your python version. You can check your python version ( i run python 3.10.10 on a 64bit windows machine so i am going to choose cp310 ) ... if you don't know your python version in the terminal type python --version. </li> <li>Once you downloaded the file you need to change your folder path in the terminal by doing cd (download location of folder)</li> <li>Once there type in pip install ( full file name of the talib wheel you downloaded)</li> </ul>"},{"location":"getting-started/install/#isntalling-pytables","title":"isntalling pytables","text":"<p>to install pytables you have to do the same thing as talib</p> <p>go to this website and download the version of python that you have https://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables for me i have version 3.10.10 right now so i download tables\u20113.7.0\u2011cp310\u2011cp310\u2011win_amd64.whl then put it in your folder and change your directiroy in the terminal to the directory you put it in then do pip install tables\u20113.7.0\u2011cp310\u2011cp310\u2011win_amd64.whl</p>"},{"location":"getting-started/releasenotes/","title":"Release Notes","text":""},{"location":"getting-started/releasenotes/#version-002","title":"Version 0.0.2 ()","text":"<ul> <li>Added the ability to delete cache </li> </ul>"},{"location":"getting-started/releasenotes/#version-001-march-12-2023","title":"Version 0.0.1 (March 12 2023)","text":"<ul> <li>Initial commit where only longing works and the whole thing barely even works lol</li> </ul>"},{"location":"api/../quantfreedom/","title":"Index","text":""},{"location":"api/../quantfreedom/testing/","title":"Testing","text":""},{"location":"api/../quantfreedom/testing/#quantfreedom.testing--function-name","title":"Function Name","text":"<pre><code>backtest_df_only\n</code></pre>"},{"location":"api/../quantfreedom/testing/#quantfreedom.testing--quick-summary","title":"Quick Summary","text":"<pre><code>The main way to backtest your strategy. \nI highly highly highly suggest watching the explainer video\nI explain what everything does and means in great detail.\n</code></pre>"},{"location":"api/../quantfreedom/testing/#quantfreedom.testing--explainer-video","title":"Explainer Video","text":"<pre><code>https://youtu.be/yDNPhgO-450\n</code></pre> <p>mmr_pct: float     maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this lev_mode: int order_type: int size_type: int</p>"},{"location":"api/../quantfreedom/testing/#quantfreedom.testing--optional-parameters","title":"Optional Parameters","text":"<p>Variable Name: Variable Type = Default Value</p> <p>leverage: PossibleArray = np.nan max_equity_risk_pct: PossibleArray = np.nan max_equity_risk_value: PossibleArray = np.nan     What is the max usd amount of your equity do you want to possibly risk max_order_size_pct: float = 100.0     max order size percent possible min_order_size_pct: float = 0.01     min order size percent possible max_order_size_value: float = np.inf     max order size usd value possible min_order_size_value: float = 1.0     min order size usd value possible max_lev: float = 100.0     setting your max leverage size_pct: PossibleArray = np.nan     When you have selected a size type that is based on percent you put your size percent here. size_value: PossibleArray = np.nan     when you selected a size type that is based on value you put your size value here. sl_pcts: PossibleArray = np.nan     stop loss based on percent sl_to_be: bool = False     if you want to move your stop loss to break even sl_to_be_based_on: PossibleArray = np.nan     Selecting what part of the candle you want your stop loss to break even to based on. Please look in enums api to find out more info on SL_BE_or_Trail_BasedOn sl_to_be_when_pct_from_avg_entry: PossibleArray = np.nan     how far in percent does the price have to be from your average entry to move your stop loss to break even sl_to_be_zero_or_entry: PossibleArray = np.nan     do you want to have your break even be zero dollars lost or moving your stop loss to your average entry. Use 0 for zero and use 1 for average entry sl_to_be_trail_by_when_pct_from_avg_entry: PossibleArray = np.nan     how much, in percent, do you want to trail the price by, set that here tsl_pcts_init: PossibleArray = np.nan     your initial stop loss tsl_true_or_false: bool = False     if you want to have a trailing stop loss this must be set to true tsl_based_on: PossibleArray = np.nan     Selecting what part of the candle you want your trailing stop loss to be based on. Please look in enums api to find out more info on SL_BE_or_Trail_BasedOn tsl_trail_by_pct: PossibleArray = np.nan     how much percent from the price do you want to trail your stop loss tsl_when_pct_from_avg_entry: PossibleArray = np.nan     at what percent from the price should the trailing stop loss strat trailing risk_rewards: PossibleArray = np.nan     risk to reward, don't set a tp percent if you are going to use risk to reward tp_pcts: PossibleArray = np.nan     take profit percent, don't set this if you are going to use risk to reward gains_pct_filter: float = -np.inf     don't return any strategies that have gains less than the percent set here total_trade_filter: int = 0     don't return any strategies that have a total trade amount that is less than this filter divide_records_array_size_by: float = 1.0     if you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more, if you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1. This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million upside_filter: float = -1.0     How you want to filter strategies that don't meet the to the upside numbers you want. Please watch the video to understand what to the upside is but it is basically the r2 value of the cumilative sum of the strategies pnl.</p> <p>Returns:</p> <ul> <li> <code>tuple[pdFrame, pdFrame]</code>         \u2013 <p>First return is a dataframe of strategy results Second return is a dataframe of the indicator and order settings</p> </li> </ul>"},{"location":"api/../quantfreedom/base/","title":"Index","text":""},{"location":"api/../quantfreedom/base/base/","title":"Base","text":""},{"location":"api/../quantfreedom/base/base/#quantfreedom.base.base.backtest_df_only","title":"backtest_df_only","text":"<pre><code>backtest_df_only(\n    prices,\n    entries,\n    equity,\n    fee_pct,\n    mmr_pct,\n    lev_mode,\n    order_type,\n    size_type,\n    leverage=np.nan,\n    max_equity_risk_pct=np.nan,\n    max_equity_risk_value=np.nan,\n    max_order_size_pct=100.0,\n    min_order_size_pct=0.01,\n    max_order_size_value=np.inf,\n    min_order_size_value=1.0,\n    max_lev=100.0,\n    size_pct=np.nan,\n    size_value=np.nan,\n    sl_pcts=np.nan,\n    sl_to_be=False,\n    sl_to_be_based_on=np.nan,\n    sl_to_be_when_pct_from_avg_entry=np.nan,\n    sl_to_be_zero_or_entry=np.nan,\n    sl_to_be_then_trail=False,\n    sl_to_be_trail_by_when_pct_from_avg_entry=np.nan,\n    tsl_pcts_init=np.nan,\n    tsl_true_or_false=False,\n    tsl_based_on=np.nan,\n    tsl_trail_by_pct=np.nan,\n    tsl_when_pct_from_avg_entry=np.nan,\n    risk_rewards=np.nan,\n    tp_pcts=np.nan,\n    gains_pct_filter=-np.inf,\n    total_trade_filter=0,\n    divide_records_array_size_by=1.0,\n    upside_filter=-1.0,\n)\n</code></pre>"},{"location":"api/../quantfreedom/base/base/#quantfreedom.base.base.backtest_df_only--function-name","title":"Function Name","text":"<pre><code>backtest_df_only\n</code></pre>"},{"location":"api/../quantfreedom/base/base/#quantfreedom.base.base.backtest_df_only--quick-summary","title":"Quick Summary","text":"<pre><code>The main way to backtest your strategy.\nI highly highly highly suggest watching the explainer video\nI explain what everything does and means in great detail.\n</code></pre>"},{"location":"api/../quantfreedom/base/base/#quantfreedom.base.base.backtest_df_only--explainer-video","title":"Explainer Video","text":"<pre><code>https://youtu.be/yDNPhgO-450\n</code></pre> <p>Parameters:</p> <ul> <li> prices             (<code>pdFrame</code>)         \u2013 <p>Dataframe of prices</p> </li> <li> entries             (<code>pdFrame</code>)         \u2013 <p>Dataframe of entries</p> </li> <li> equity             (<code>float</code>)         \u2013 <p>Starting equity. I suggest only doing 100 or 1000 dollars</p> </li> <li> fee_pct             (<code>float</code>)         \u2013 <p>Fees percent</p> </li> <li> mmr_pct             (<code>float</code>)         \u2013 <p>maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this</p> </li> <li> lev_mode             (<code>int</code>)         \u2013 <p>Selecting your leverage mode. Look in the enums api section for LeverageMode</p> </li> <li> order_type             (<code>int</code>)         \u2013 <p>Selecting your order type. Please only use long short or both. Look in the enums api section for OrderType</p> </li> <li> size_type             (<code>int</code>)         \u2013 <p>Selecting your size type. Look in the enums api section for SizeType</p> </li> <li> leverage             (<code>PossibleArray, optional</code>)         \u2013 <p>If your leverage mode is isolated this is where you put in how much leverage you want to use., by default np.nan</p> </li> <li> max_equity_risk_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>What is the max equity percent you want to possibly risk, by default np.nan</p> </li> <li> max_equity_risk_value             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> max_order_size_pct             (<code>float, optional</code>)         \u2013 <p>description, by default 100.0</p> </li> <li> min_order_size_pct             (<code>float, optional</code>)         \u2013 <p>description, by default 0.01</p> </li> <li> max_order_size_value             (<code>float, optional</code>)         \u2013 <p>description, by default np.inf</p> </li> <li> min_order_size_value             (<code>float, optional</code>)         \u2013 <p>description, by default 1.0</p> </li> <li> max_lev             (<code>float, optional</code>)         \u2013 <p>description, by default 100.0</p> </li> <li> size_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> size_value             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_pcts             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> sl_to_be_based_on             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_zero_or_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> sl_to_be_trail_by_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_pcts_init             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_true_or_false             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> tsl_based_on             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_trail_by_pct             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tsl_when_pct_from_avg_entry             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> risk_rewards             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> tp_pcts             (<code>PossibleArray, optional</code>)         \u2013 <p>description, by default np.nan</p> </li> <li> gains_pct_filter             (<code>float, optional</code>)         \u2013 <p>description, by default -np.inf</p> </li> <li> total_trade_filter             (<code>int, optional</code>)         \u2013 <p>description, by default 0</p> </li> <li> divide_records_array_size_by             (<code>float, optional</code>)         \u2013 <p>If you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more.</p> <p>If you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1.</p> <p>This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million, by default 1.0</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[pdFrame, pdFrame]</code>         \u2013 <p>First return is a dataframe of strategy results. Second return is a dataframe of the indicator and order settings.</p> </li> </ul> Source code in <code>quantfreedom\\base\\base.py</code> <pre><code>def backtest_df_only(\n    # entry info\n    prices: pdFrame,\n    entries: pdFrame,\n    # required account info\n    equity: float,\n    fee_pct: float,\n    mmr_pct: float,\n    # required order\n    lev_mode: int,\n    order_type: int,\n    size_type: int,\n    # Order Params\n    leverage: PossibleArray = np.nan,\n    max_equity_risk_pct: PossibleArray = np.nan,\n    max_equity_risk_value: PossibleArray = np.nan,\n    max_order_size_pct: float = 100.0,\n    min_order_size_pct: float = 0.01,\n    max_order_size_value: float = np.inf,\n    min_order_size_value: float = 1.0,\n    max_lev: float = 100.0,\n    size_pct: PossibleArray = np.nan,\n    size_value: PossibleArray = np.nan,\n    # Stop Losses\n    sl_pcts: PossibleArray = np.nan,\n    sl_to_be: bool = False,\n    sl_to_be_based_on: PossibleArray = np.nan,\n    sl_to_be_when_pct_from_avg_entry: PossibleArray = np.nan,\n    sl_to_be_zero_or_entry: PossibleArray = np.nan,  # 0 for zero or 1 for entry\n    sl_to_be_then_trail: bool = False,\n    sl_to_be_trail_by_when_pct_from_avg_entry: PossibleArray = np.nan,\n    # Trailing Stop Loss Params\n    tsl_pcts_init: PossibleArray = np.nan,\n    tsl_true_or_false: bool = False,\n    tsl_based_on: PossibleArray = np.nan,\n    tsl_trail_by_pct: PossibleArray = np.nan,\n    tsl_when_pct_from_avg_entry: PossibleArray = np.nan,\n    # Take Profit Params\n    risk_rewards: PossibleArray = np.nan,\n    tp_pcts: PossibleArray = np.nan,\n    # Results Filters\n    gains_pct_filter: float = -np.inf,\n    total_trade_filter: int = 0,\n    divide_records_array_size_by: float = 1.0,  # between 1 and 1000\n    upside_filter: float = -1.0,  # between -1 and 1\n) -&gt; tuple[pdFrame, pdFrame]:\n\"\"\"\n     Function Name\n    -------------\n        backtest_df_only\n\n    Quick Summary\n    -------------\n        The main way to backtest your strategy.\n        I highly highly highly suggest watching the explainer video\n        I explain what everything does and means in great detail.\n\n\n    Explainer Video\n    ---------------\n        https://youtu.be/yDNPhgO-450\n\n    Parameters\n    ----------\n    prices : pdFrame\n        Dataframe of prices\n    entries : pdFrame\n        Dataframe of entries\n    equity : float\n        Starting equity. I suggest only doing 100 or 1000 dollars\n    fee_pct : float\n        Fees percent\n    mmr_pct : float\n        maintenance margin rate this is for bybit but i am not sure what other exchange also have this but please check your exchange and this\n    lev_mode : int\n        Selecting your leverage mode. Look in the enums api section for LeverageMode\n    order_type : int\n        Selecting your order type. Please only use long short or both. Look in the enums api section for OrderType\n    size_type : int\n        Selecting your size type. Look in the enums api section for SizeType\n    leverage : PossibleArray, optional\n        If your leverage mode is isolated this is where you put in how much leverage you want to use., by default np.nan\n    max_equity_risk_pct : PossibleArray, optional\n        What is the max equity percent you want to possibly risk, by default np.nan\n    max_equity_risk_value : PossibleArray, optional\n        _description_, by default np.nan\n    max_order_size_pct : float, optional\n        _description_, by default 100.0\n    min_order_size_pct : float, optional\n        _description_, by default 0.01\n    max_order_size_value : float, optional\n        _description_, by default np.inf\n    min_order_size_value : float, optional\n        _description_, by default 1.0\n    max_lev : float, optional\n        _description_, by default 100.0\n    size_pct : PossibleArray, optional\n        _description_, by default np.nan\n    size_value : PossibleArray, optional\n        _description_, by default np.nan\n    sl_pcts : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be : bool, optional\n        _description_, by default False\n    sl_to_be_based_on : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_zero_or_entry : PossibleArray, optional\n        _description_, by default np.nan\n    sl_to_be_trail_by_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_pcts_init : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_true_or_false : bool, optional\n        _description_, by default False\n    tsl_based_on : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_trail_by_pct : PossibleArray, optional\n        _description_, by default np.nan\n    tsl_when_pct_from_avg_entry : PossibleArray, optional\n        _description_, by default np.nan\n    risk_rewards : PossibleArray, optional\n        _description_, by default np.nan\n    tp_pcts : PossibleArray, optional\n        _description_, by default np.nan\n    gains_pct_filter : float, optional\n        _description_, by default -np.inf\n    total_trade_filter : int, optional\n        _description_, by default 0\n    divide_records_array_size_by : float, optional\n        If you have a ton of combinations you are testing with very strict filters then put this number higher like 100 or more.\n\n        If you have very low filters then set it to 10 or 5 or something and if you have absolutely no filters then leave this at 1.\n\n        This basically saves you memory so if you have 5 mil combinations but strict filters then you could reduce the amount of rows by like 100 which would be 5000000 / 100 which would create 50,000 rows for the array instead of 5 million, by default 1.0\n\n    Returns\n    -------\n    tuple[pdFrame, pdFrame]\n        First return is a dataframe of strategy results.\n        Second return is a dataframe of the indicator and order settings.\n    \"\"\"\n    print(\"Checking static variables for errors or conflicts.\")\n    # Static checks\n    static_variables_tuple = static_var_checker_nb(\n        divide_records_array_size_by=divide_records_array_size_by,\n        equity=equity,\n        fee_pct=fee_pct,\n        gains_pct_filter=gains_pct_filter,\n        lev_mode=lev_mode,\n        max_lev=max_lev,\n        max_order_size_pct=max_order_size_pct,\n        max_order_size_value=max_order_size_value,\n        min_order_size_pct=min_order_size_pct,\n        min_order_size_value=min_order_size_value,\n        mmr_pct=mmr_pct,\n        order_type=order_type,\n        size_type=size_type,\n        sl_to_be_then_trail=sl_to_be_then_trail,\n        sl_to_be=sl_to_be,\n        total_trade_filter=total_trade_filter,\n        tsl_true_or_false=tsl_true_or_false,\n        upside_filter=upside_filter,\n    )\n    print(\"Turning all variables into arrays.\")\n    # Create 1d Arrays\n    arrays_1d_tuple = create_1d_arrays_nb(\n        leverage=leverage,\n        max_equity_risk_pct=max_equity_risk_pct,\n        max_equity_risk_value=max_equity_risk_value,\n        risk_rewards=risk_rewards,\n        size_pct=size_pct,\n        size_value=size_value,\n        sl_pcts=sl_pcts,\n        sl_to_be_based_on=sl_to_be_based_on,\n        sl_to_be_trail_by_when_pct_from_avg_entry=sl_to_be_trail_by_when_pct_from_avg_entry,\n        sl_to_be_when_pct_from_avg_entry=sl_to_be_when_pct_from_avg_entry,\n        sl_to_be_zero_or_entry=sl_to_be_zero_or_entry,\n        tp_pcts=tp_pcts,\n        tsl_based_on=tsl_based_on,\n        tsl_pcts_init=tsl_pcts_init,\n        tsl_trail_by_pct=tsl_trail_by_pct,\n        tsl_when_pct_from_avg_entry=tsl_when_pct_from_avg_entry,\n    )\n    print(\n        \"Checking arrays for errors or conflicts ... the backtest will begin shortly, please hold.\"\n    )\n    # Checking all new arrays\n    check_1d_arrays_nb(\n        arrays_1d_tuple=arrays_1d_tuple,\n        static_variables_tuple=static_variables_tuple,\n    )\n\n    print(\n        \"Creating cartesian product ... after this the backtest will start, I promise :).\\n\"\n    )\n    cart_array_tuple = create_cart_product_nb(arrays_1d_tuple=arrays_1d_tuple)\n\n    num_of_symbols = len(prices.columns.levels[0])\n\n    # Creating Settings Vars\n    total_order_settings = cart_array_tuple.sl_pcts.shape[0]\n\n    total_indicator_settings = entries.shape[1]\n\n    total_bars = entries.shape[0]\n\n    # Printing out total numbers of things\n    print(\n        \"Starting the backtest now ... and also here are some stats for your backtest.\\n\"\n    )\n    print(f\"Total symbols: {num_of_symbols:,}\")\n    print(\n        f\"Total indicator settings per symbol: {int(total_indicator_settings / num_of_symbols):,}\"\n    )\n    print(f\"Total indicator settings to test: {total_indicator_settings:,}\")\n    print(f\"Total order settings per symbol: {total_order_settings:,}\")\n    print(f\"Total order settings to test: {total_order_settings * num_of_symbols:,}\")\n    print(f\"Total candles per symbol: {total_bars:,}\")\n    print(\n        f\"Total candles to test: {total_indicator_settings * total_order_settings * total_bars:,}\"\n    )\n    print(\n        f\"\\nTotal combinations to test: {total_indicator_settings * total_order_settings:,}\"\n    )\n\n    strat_array, settings_array = backtest_df_only_nb(\n        cart_array_tuple=cart_array_tuple,\n        entries=entries.values,\n        gains_pct_filter=gains_pct_filter,\n        num_of_symbols=num_of_symbols,\n        og_equity=equity,\n        prices=prices.values,\n        static_variables_tuple=static_variables_tuple,\n        total_bars=total_bars,\n        total_indicator_settings=total_indicator_settings,\n        total_order_settings=total_order_settings,\n        total_trade_filter=total_trade_filter,\n    )\n\n    strat_results_df = pd.DataFrame(strat_array).sort_values(\n        by=[\"to_the_upside\", \"gains_pct\"], ascending=False\n    )\n\n    symbols = list(prices.columns.levels[0])\n\n    for i in range(len(symbols)):\n        strat_results_df.replace({\"symbol\": {i: symbols[i]}}, inplace=True)\n\n    symbols = list(entries.columns.levels[0])\n    setting_results_df = pd.DataFrame(settings_array).dropna(axis=\"columns\", thresh=1)\n\n    for i in range(len(SL_BE_or_Trail_BasedOn._fields)):\n        setting_results_df.replace(\n            {\"tsl_based_on\": {i: SL_BE_or_Trail_BasedOn._fields[i]}}, inplace=True\n        )\n        setting_results_df.replace(\n            {\"sl_to_be_based_on\": {i: SL_BE_or_Trail_BasedOn._fields[i]}}, inplace=True\n        )\n    for i in range(len(symbols)):\n        setting_results_df.replace({\"symbol\": {i: symbols[i]}}, inplace=True)\n\n    setting_results_df = setting_results_df.T\n\n    return strat_results_df, setting_results_df\n</code></pre>"},{"location":"api/../quantfreedom/data/","title":"Index","text":""},{"location":"api/../quantfreedom/data/#quantfreedom.data.CCXTData","title":"CCXTData","text":"Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>class CCXTData:\n    @classmethod\n    def data_download(\n        cls,\n        exchange: str,\n        start: str,\n        end: str,\n        symbols: Union[str, list],\n        timeframe: str,\n        drop_volume: bool = True,\n        remove_rate_limit: bool = False,\n        bars_per_loop: int = 200,\n    ):\n\"\"\"\n        Function name:\n            data_download \n\n        Quick Summary:\n            Download Data using CCXT\n\n        Explainer Video\n        ---------------\n            Coming_Soon\n\n        Parameters\n        ----------\n        cls: self\n            passing all the information from the created class\n\n        exchange : str\n            'bybit' or 'binance' or whatever exchange works with ccxt\n            http://docs.ccxt.com/#/README?id=exchanges\n\n        start : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        end : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        symbol : list or str\n            This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n            You can send this as a list of symbols or just one symbol.\n            Here is an example of how to get the symbols list from bybit.\n            ```python\n            import ccxt\n            exh = ccxt.bybit()\n            exh.load_markets()\n            exh.symbols\n            ```\n\n        timeframe : str\n            '1m', '5m', '1h' '4h' '1d' '1w'\n\n        drop_volume: bool = True\n            Set this to False if you want to keep volume data.\n\n        remove_rate_limit: bool = False\n            This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n        bars_per_loop: int = 200\n            How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n        Returns\n        -------\n            Pandas dataframe of prices\n        \"\"\"\n        if remove_rate_limit:\n            exchange = getattr(ccxt, exchange)()\n        else:\n            exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n        print(\"Loading exchange data\")\n        exchange.load_markets()\n        # exchange.verbose = True  # uncomment for debugging purposes if necessary\n        start = exchange.parse8601(start)\n        end = exchange.parse8601(end)\n        timeframe = timeframe.lower()\n        if not isinstance(symbols, list):\n            symbols = [symbols]\n        if not all(isinstance(x, str) for x in symbols):\n            raise ValueError(\"your symbols must be strings\")\n\n        symbols = sorted(symbols)\n        timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n        timeframe_str = sub(r\"\\d\", \"\", timeframe)\n        len_symbols = len(symbols)\n        if timeframe_str == \"m\":\n            time_in = 1000 * 60\n        elif timeframe_str == \"h\":\n            time_in = 1000 * 60 * 60\n        elif timeframe_str == \"d\":\n            time_in = 1000 * 60 * 60 * 24\n        elif timeframe_str == \"w\":\n            time_in = 1000 * 60 * 60 * 24 * 7\n        elif timeframe_str == \"m\":\n            time_in = 1000 * 60 * 60 * 24 * 7 * 12\n        else:\n            raise ValueError(\"something wrong with your timeframe\")\n\n        x = start\n        timelist = [x]\n        while x &lt; end:\n            x += time_in * timeframe_int\n            timelist.append(x)\n\n        final_df = pd.DataFrame(\n            columns=pd.MultiIndex.from_tuples(\n                tuples=[],\n                name=[\"symbol\", \"candle_info\"],\n            ),\n            index=pd.Index(\n                data=pd.to_datetime(timelist, unit=\"ms\"),\n                name=\"open_time\",\n            ),\n        )\n        # Example if you selected your timeframe as 30 minute candles\n\n        # Get the distance between the end date and start date in miliseconds\n        # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n        # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n        # Then divide by limit because that is the amount of rows of data you can return\n        # Then add one because that is the amount of loops we will have to do\n        # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n        # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n        num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n        total_tqdm = (\n            (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n        ) + len_symbols\n        print(\n            f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n            f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n            f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n        )\n        with tqdm(total=total_tqdm) as pbar:\n            # with tqdm(total=96*2) as pbar:\n            for symbol in symbols:\n                all_ohlcvs = []\n                temp_end = end\n                pbar.set_description(f\"Downloading {symbol}\")\n                while True:\n                    try:\n                        ohlcvs = exchange.fetch_ohlcv(\n                            symbol=symbol,\n                            timeframe=timeframe,\n                            since=start,\n                            limit=bars_per_loop,\n                            params={\"end\": temp_end},\n                        )\n                        all_ohlcvs += ohlcvs\n                        if len(ohlcvs):\n                            temp_end = ohlcvs[0][0] - 1\n                            pbar.update(1)\n                        else:\n                            break\n\n                    except Exception as e:\n                        print(type(e).__name__, str(e))\n\n                if all_ohlcvs:\n                    all_ohlcvs = np.array(all_ohlcvs)\n                    data_columns = pd.MultiIndex.from_tuples(\n                        [\n                            (symbol, \"open\"),\n                            (symbol, \"high\"),\n                            (symbol, \"low\"),\n                            (symbol, \"close\"),\n                            (symbol, \"volume\"),\n                        ],\n                        name=[\"symbol\", \"candle_info\"],\n                    )\n                    data_index = pd.Index(\n                        data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                        name=\"open_time\",\n                    )\n                    data = pd.DataFrame(\n                        all_ohlcvs[:, 1:],\n                        columns=data_columns,\n                        index=data_index,\n                    )\n                    if drop_volume:\n                        data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                    final_df = final_df.join(data)\n                pbar.update(1)\n        final_df.sort_index(ascending=True, inplace=True)\n        final_df.sort_index(axis=1, level=0, sort_remaining=False)\n        final_df.dropna(how='all', inplace=True)\n        final_df.drop(final_df.tail(1).index, inplace=True)\n        return final_df\n</code></pre>"},{"location":"api/../quantfreedom/data/#quantfreedom.data.ccxtdata.CCXTData.data_download","title":"data_download  <code>classmethod</code>","text":"<pre><code>data_download(\n    exchange,\n    start,\n    end,\n    symbols,\n    timeframe,\n    drop_volume=True,\n    remove_rate_limit=False,\n    bars_per_loop=200,\n)\n</code></pre> <p>Function name:     data_download </p> <p>Quick Summary:     Download Data using CCXT</p>"},{"location":"api/../quantfreedom/data/#quantfreedom.data.ccxtdata.CCXTData.data_download--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre> <p>Parameters:</p> <ul> <li> cls         \u2013 <p>passing all the information from the created class</p> </li> <li> exchange             (<code>str</code>)         \u2013 <p>'bybit' or 'binance' or whatever exchange works with ccxt http://docs.ccxt.com/#/README?id=exchanges</p> </li> </ul> <p>start : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>end : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>symbol : list or str     This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.     You can send this as a list of symbols or just one symbol.     Here is an example of how to get the symbols list from bybit.     <pre><code>import ccxt\nexh = ccxt.bybit()\nexh.load_markets()\nexh.symbols\n</code></pre></p> <p>timeframe : str     '1m', '5m', '1h' '4h' '1d' '1w'</p> <p>drop_volume: bool = True     Set this to False if you want to keep volume data.</p> <p>remove_rate_limit: bool = False     This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.</p> <p>bars_per_loop: int = 200     How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.</p> <p>Returns:</p> <ul> <li> <code>    Pandas dataframe of prices</code>         \u2013        </li> </ul> Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>@classmethod\ndef data_download(\n    cls,\n    exchange: str,\n    start: str,\n    end: str,\n    symbols: Union[str, list],\n    timeframe: str,\n    drop_volume: bool = True,\n    remove_rate_limit: bool = False,\n    bars_per_loop: int = 200,\n):\n\"\"\"\n    Function name:\n        data_download \n\n    Quick Summary:\n        Download Data using CCXT\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Parameters\n    ----------\n    cls: self\n        passing all the information from the created class\n\n    exchange : str\n        'bybit' or 'binance' or whatever exchange works with ccxt\n        http://docs.ccxt.com/#/README?id=exchanges\n\n    start : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    end : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    symbol : list or str\n        This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n        You can send this as a list of symbols or just one symbol.\n        Here is an example of how to get the symbols list from bybit.\n        ```python\n        import ccxt\n        exh = ccxt.bybit()\n        exh.load_markets()\n        exh.symbols\n        ```\n\n    timeframe : str\n        '1m', '5m', '1h' '4h' '1d' '1w'\n\n    drop_volume: bool = True\n        Set this to False if you want to keep volume data.\n\n    remove_rate_limit: bool = False\n        This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n    bars_per_loop: int = 200\n        How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n    Returns\n    -------\n        Pandas dataframe of prices\n    \"\"\"\n    if remove_rate_limit:\n        exchange = getattr(ccxt, exchange)()\n    else:\n        exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n    print(\"Loading exchange data\")\n    exchange.load_markets()\n    # exchange.verbose = True  # uncomment for debugging purposes if necessary\n    start = exchange.parse8601(start)\n    end = exchange.parse8601(end)\n    timeframe = timeframe.lower()\n    if not isinstance(symbols, list):\n        symbols = [symbols]\n    if not all(isinstance(x, str) for x in symbols):\n        raise ValueError(\"your symbols must be strings\")\n\n    symbols = sorted(symbols)\n    timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n    timeframe_str = sub(r\"\\d\", \"\", timeframe)\n    len_symbols = len(symbols)\n    if timeframe_str == \"m\":\n        time_in = 1000 * 60\n    elif timeframe_str == \"h\":\n        time_in = 1000 * 60 * 60\n    elif timeframe_str == \"d\":\n        time_in = 1000 * 60 * 60 * 24\n    elif timeframe_str == \"w\":\n        time_in = 1000 * 60 * 60 * 24 * 7\n    elif timeframe_str == \"m\":\n        time_in = 1000 * 60 * 60 * 24 * 7 * 12\n    else:\n        raise ValueError(\"something wrong with your timeframe\")\n\n    x = start\n    timelist = [x]\n    while x &lt; end:\n        x += time_in * timeframe_int\n        timelist.append(x)\n\n    final_df = pd.DataFrame(\n        columns=pd.MultiIndex.from_tuples(\n            tuples=[],\n            name=[\"symbol\", \"candle_info\"],\n        ),\n        index=pd.Index(\n            data=pd.to_datetime(timelist, unit=\"ms\"),\n            name=\"open_time\",\n        ),\n    )\n    # Example if you selected your timeframe as 30 minute candles\n\n    # Get the distance between the end date and start date in miliseconds\n    # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n    # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n    # Then divide by limit because that is the amount of rows of data you can return\n    # Then add one because that is the amount of loops we will have to do\n    # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n    # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n    num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n    total_tqdm = (\n        (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n    ) + len_symbols\n    print(\n        f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n        f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n        f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n    )\n    with tqdm(total=total_tqdm) as pbar:\n        # with tqdm(total=96*2) as pbar:\n        for symbol in symbols:\n            all_ohlcvs = []\n            temp_end = end\n            pbar.set_description(f\"Downloading {symbol}\")\n            while True:\n                try:\n                    ohlcvs = exchange.fetch_ohlcv(\n                        symbol=symbol,\n                        timeframe=timeframe,\n                        since=start,\n                        limit=bars_per_loop,\n                        params={\"end\": temp_end},\n                    )\n                    all_ohlcvs += ohlcvs\n                    if len(ohlcvs):\n                        temp_end = ohlcvs[0][0] - 1\n                        pbar.update(1)\n                    else:\n                        break\n\n                except Exception as e:\n                    print(type(e).__name__, str(e))\n\n            if all_ohlcvs:\n                all_ohlcvs = np.array(all_ohlcvs)\n                data_columns = pd.MultiIndex.from_tuples(\n                    [\n                        (symbol, \"open\"),\n                        (symbol, \"high\"),\n                        (symbol, \"low\"),\n                        (symbol, \"close\"),\n                        (symbol, \"volume\"),\n                    ],\n                    name=[\"symbol\", \"candle_info\"],\n                )\n                data_index = pd.Index(\n                    data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                    name=\"open_time\",\n                )\n                data = pd.DataFrame(\n                    all_ohlcvs[:, 1:],\n                    columns=data_columns,\n                    index=data_index,\n                )\n                if drop_volume:\n                    data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                final_df = final_df.join(data)\n            pbar.update(1)\n    final_df.sort_index(ascending=True, inplace=True)\n    final_df.sort_index(axis=1, level=0, sort_remaining=False)\n    final_df.dropna(how='all', inplace=True)\n    final_df.drop(final_df.tail(1).index, inplace=True)\n    return final_df\n</code></pre>"},{"location":"api/../quantfreedom/data/ccxtdata/","title":"Ccxtdata","text":""},{"location":"api/../quantfreedom/data/ccxtdata/#quantfreedom.data.ccxtdata.CCXTData","title":"CCXTData","text":"Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>class CCXTData:\n    @classmethod\n    def data_download(\n        cls,\n        exchange: str,\n        start: str,\n        end: str,\n        symbols: Union[str, list],\n        timeframe: str,\n        drop_volume: bool = True,\n        remove_rate_limit: bool = False,\n        bars_per_loop: int = 200,\n    ):\n\"\"\"\n        Function name:\n            data_download \n\n        Quick Summary:\n            Download Data using CCXT\n\n        Explainer Video\n        ---------------\n            Coming_Soon\n\n        Parameters\n        ----------\n        cls: self\n            passing all the information from the created class\n\n        exchange : str\n            'bybit' or 'binance' or whatever exchange works with ccxt\n            http://docs.ccxt.com/#/README?id=exchanges\n\n        start : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        end : str\n            needs to be in this format '2022-01-01T00:00:00Z'\n\n        symbol : list or str\n            This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n            You can send this as a list of symbols or just one symbol.\n            Here is an example of how to get the symbols list from bybit.\n            ```python\n            import ccxt\n            exh = ccxt.bybit()\n            exh.load_markets()\n            exh.symbols\n            ```\n\n        timeframe : str\n            '1m', '5m', '1h' '4h' '1d' '1w'\n\n        drop_volume: bool = True\n            Set this to False if you want to keep volume data.\n\n        remove_rate_limit: bool = False\n            This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n        bars_per_loop: int = 200\n            How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n        Returns\n        -------\n            Pandas dataframe of prices\n        \"\"\"\n        if remove_rate_limit:\n            exchange = getattr(ccxt, exchange)()\n        else:\n            exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n        print(\"Loading exchange data\")\n        exchange.load_markets()\n        # exchange.verbose = True  # uncomment for debugging purposes if necessary\n        start = exchange.parse8601(start)\n        end = exchange.parse8601(end)\n        timeframe = timeframe.lower()\n        if not isinstance(symbols, list):\n            symbols = [symbols]\n        if not all(isinstance(x, str) for x in symbols):\n            raise ValueError(\"your symbols must be strings\")\n\n        symbols = sorted(symbols)\n        timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n        timeframe_str = sub(r\"\\d\", \"\", timeframe)\n        len_symbols = len(symbols)\n        if timeframe_str == \"m\":\n            time_in = 1000 * 60\n        elif timeframe_str == \"h\":\n            time_in = 1000 * 60 * 60\n        elif timeframe_str == \"d\":\n            time_in = 1000 * 60 * 60 * 24\n        elif timeframe_str == \"w\":\n            time_in = 1000 * 60 * 60 * 24 * 7\n        elif timeframe_str == \"m\":\n            time_in = 1000 * 60 * 60 * 24 * 7 * 12\n        else:\n            raise ValueError(\"something wrong with your timeframe\")\n\n        x = start\n        timelist = [x]\n        while x &lt; end:\n            x += time_in * timeframe_int\n            timelist.append(x)\n\n        final_df = pd.DataFrame(\n            columns=pd.MultiIndex.from_tuples(\n                tuples=[],\n                name=[\"symbol\", \"candle_info\"],\n            ),\n            index=pd.Index(\n                data=pd.to_datetime(timelist, unit=\"ms\"),\n                name=\"open_time\",\n            ),\n        )\n        # Example if you selected your timeframe as 30 minute candles\n\n        # Get the distance between the end date and start date in miliseconds\n        # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n        # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n        # Then divide by limit because that is the amount of rows of data you can return\n        # Then add one because that is the amount of loops we will have to do\n        # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n        # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n        num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n        total_tqdm = (\n            (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n        ) + len_symbols\n        print(\n            f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n            f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n            f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n        )\n        with tqdm(total=total_tqdm) as pbar:\n            # with tqdm(total=96*2) as pbar:\n            for symbol in symbols:\n                all_ohlcvs = []\n                temp_end = end\n                pbar.set_description(f\"Downloading {symbol}\")\n                while True:\n                    try:\n                        ohlcvs = exchange.fetch_ohlcv(\n                            symbol=symbol,\n                            timeframe=timeframe,\n                            since=start,\n                            limit=bars_per_loop,\n                            params={\"end\": temp_end},\n                        )\n                        all_ohlcvs += ohlcvs\n                        if len(ohlcvs):\n                            temp_end = ohlcvs[0][0] - 1\n                            pbar.update(1)\n                        else:\n                            break\n\n                    except Exception as e:\n                        print(type(e).__name__, str(e))\n\n                if all_ohlcvs:\n                    all_ohlcvs = np.array(all_ohlcvs)\n                    data_columns = pd.MultiIndex.from_tuples(\n                        [\n                            (symbol, \"open\"),\n                            (symbol, \"high\"),\n                            (symbol, \"low\"),\n                            (symbol, \"close\"),\n                            (symbol, \"volume\"),\n                        ],\n                        name=[\"symbol\", \"candle_info\"],\n                    )\n                    data_index = pd.Index(\n                        data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                        name=\"open_time\",\n                    )\n                    data = pd.DataFrame(\n                        all_ohlcvs[:, 1:],\n                        columns=data_columns,\n                        index=data_index,\n                    )\n                    if drop_volume:\n                        data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                    final_df = final_df.join(data)\n                pbar.update(1)\n        final_df.sort_index(ascending=True, inplace=True)\n        final_df.sort_index(axis=1, level=0, sort_remaining=False)\n        final_df.dropna(how='all', inplace=True)\n        final_df.drop(final_df.tail(1).index, inplace=True)\n        return final_df\n</code></pre>"},{"location":"api/../quantfreedom/data/ccxtdata/#quantfreedom.data.ccxtdata.CCXTData.data_download","title":"data_download  <code>classmethod</code>","text":"<pre><code>data_download(\n    exchange,\n    start,\n    end,\n    symbols,\n    timeframe,\n    drop_volume=True,\n    remove_rate_limit=False,\n    bars_per_loop=200,\n)\n</code></pre> <p>Function name:     data_download </p> <p>Quick Summary:     Download Data using CCXT</p>"},{"location":"api/../quantfreedom/data/ccxtdata/#quantfreedom.data.ccxtdata.CCXTData.data_download--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre> <p>Parameters:</p> <ul> <li> cls         \u2013 <p>passing all the information from the created class</p> </li> <li> exchange             (<code>str</code>)         \u2013 <p>'bybit' or 'binance' or whatever exchange works with ccxt http://docs.ccxt.com/#/README?id=exchanges</p> </li> </ul> <p>start : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>end : str     needs to be in this format '2022-01-01T00:00:00Z'</p> <p>symbol : list or str     This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.     You can send this as a list of symbols or just one symbol.     Here is an example of how to get the symbols list from bybit.     <pre><code>import ccxt\nexh = ccxt.bybit()\nexh.load_markets()\nexh.symbols\n</code></pre></p> <p>timeframe : str     '1m', '5m', '1h' '4h' '1d' '1w'</p> <p>drop_volume: bool = True     Set this to False if you want to keep volume data.</p> <p>remove_rate_limit: bool = False     This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.</p> <p>bars_per_loop: int = 200     How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.</p> <p>Returns:</p> <ul> <li> <code>    Pandas dataframe of prices</code>         \u2013        </li> </ul> Source code in <code>quantfreedom\\data\\ccxtdata.py</code> <pre><code>@classmethod\ndef data_download(\n    cls,\n    exchange: str,\n    start: str,\n    end: str,\n    symbols: Union[str, list],\n    timeframe: str,\n    drop_volume: bool = True,\n    remove_rate_limit: bool = False,\n    bars_per_loop: int = 200,\n):\n\"\"\"\n    Function name:\n        data_download \n\n    Quick Summary:\n        Download Data using CCXT\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Parameters\n    ----------\n    cls: self\n        passing all the information from the created class\n\n    exchange : str\n        'bybit' or 'binance' or whatever exchange works with ccxt\n        http://docs.ccxt.com/#/README?id=exchanges\n\n    start : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    end : str\n        needs to be in this format '2022-01-01T00:00:00Z'\n\n    symbol : list or str\n        This will depend on the exchange for bybit it would be 'BTCUSDT' you will have to look this up on ccxt if you need to know.\n        You can send this as a list of symbols or just one symbol.\n        Here is an example of how to get the symbols list from bybit.\n        ```python\n        import ccxt\n        exh = ccxt.bybit()\n        exh.load_markets()\n        exh.symbols\n        ```\n\n    timeframe : str\n        '1m', '5m', '1h' '4h' '1d' '1w'\n\n    drop_volume: bool = True\n        Set this to False if you want to keep volume data.\n\n    remove_rate_limit: bool = False\n        This is the default rate limit the exchange asks for. If you remove it then its possible that if you are trying to get tons and tons of data from the exchange they could ban you or time you out.\n\n    bars_per_loop: int = 200\n        How many bars you want to grab at a time. Some exchanges let you grab more info per loop and some don't. I don't think grabbing more would make anything faster but you can try if the exchange allows for more. You would have to do your research and figure out how man bars but i know bybit says you can grab a max of 200 and apparently binance lets you grab up to 1000.\n\n    Returns\n    -------\n        Pandas dataframe of prices\n    \"\"\"\n    if remove_rate_limit:\n        exchange = getattr(ccxt, exchange)()\n    else:\n        exchange = getattr(ccxt, exchange)({\"enableRateLimit\": True})\n    print(\"Loading exchange data\")\n    exchange.load_markets()\n    # exchange.verbose = True  # uncomment for debugging purposes if necessary\n    start = exchange.parse8601(start)\n    end = exchange.parse8601(end)\n    timeframe = timeframe.lower()\n    if not isinstance(symbols, list):\n        symbols = [symbols]\n    if not all(isinstance(x, str) for x in symbols):\n        raise ValueError(\"your symbols must be strings\")\n\n    symbols = sorted(symbols)\n    timeframe_int = int(sub(r\"\\D\", \"\", timeframe))\n    timeframe_str = sub(r\"\\d\", \"\", timeframe)\n    len_symbols = len(symbols)\n    if timeframe_str == \"m\":\n        time_in = 1000 * 60\n    elif timeframe_str == \"h\":\n        time_in = 1000 * 60 * 60\n    elif timeframe_str == \"d\":\n        time_in = 1000 * 60 * 60 * 24\n    elif timeframe_str == \"w\":\n        time_in = 1000 * 60 * 60 * 24 * 7\n    elif timeframe_str == \"m\":\n        time_in = 1000 * 60 * 60 * 24 * 7 * 12\n    else:\n        raise ValueError(\"something wrong with your timeframe\")\n\n    x = start\n    timelist = [x]\n    while x &lt; end:\n        x += time_in * timeframe_int\n        timelist.append(x)\n\n    final_df = pd.DataFrame(\n        columns=pd.MultiIndex.from_tuples(\n            tuples=[],\n            name=[\"symbol\", \"candle_info\"],\n        ),\n        index=pd.Index(\n            data=pd.to_datetime(timelist, unit=\"ms\"),\n            name=\"open_time\",\n        ),\n    )\n    # Example if you selected your timeframe as 30 minute candles\n\n    # Get the distance between the end date and start date in miliseconds\n    # Divide that by the amount of miliseconds in what ever timeframe you set ex: there are 60,000 miliseconds in one minute.\n    # Then you divide that by the number for the timeframe you set like 30 for 30 minutes to get the amount of 30 min bars in that distance of time\n    # Then divide by limit because that is the amount of rows of data you can return\n    # Then add one because that is the amount of loops we will have to do\n    # then multiple by the amount of symbols so if we have to do 2 loops per symbol and we have 2 symbols we have to do a total of 4 loops\n    # Then last we do + len of symbols because we will do an extra pbar update after we create the dataframe\n    num_candles_per_coin = ((end - start) / time_in) / timeframe_int\n    total_tqdm = (\n        (int(num_candles_per_coin / bars_per_loop) + 1) * len_symbols\n    ) + len_symbols\n    print(\n        f\"Total possible rows of data to be download: {int(num_candles_per_coin)}\\n\"\n        f\"Total possible candles to be download: {int(num_candles_per_coin) * len_symbols}\\n\"\n        f\"It could finish earlier than expected because maybe not all coins have data starting from the start date selected.\"\n    )\n    with tqdm(total=total_tqdm) as pbar:\n        # with tqdm(total=96*2) as pbar:\n        for symbol in symbols:\n            all_ohlcvs = []\n            temp_end = end\n            pbar.set_description(f\"Downloading {symbol}\")\n            while True:\n                try:\n                    ohlcvs = exchange.fetch_ohlcv(\n                        symbol=symbol,\n                        timeframe=timeframe,\n                        since=start,\n                        limit=bars_per_loop,\n                        params={\"end\": temp_end},\n                    )\n                    all_ohlcvs += ohlcvs\n                    if len(ohlcvs):\n                        temp_end = ohlcvs[0][0] - 1\n                        pbar.update(1)\n                    else:\n                        break\n\n                except Exception as e:\n                    print(type(e).__name__, str(e))\n\n            if all_ohlcvs:\n                all_ohlcvs = np.array(all_ohlcvs)\n                data_columns = pd.MultiIndex.from_tuples(\n                    [\n                        (symbol, \"open\"),\n                        (symbol, \"high\"),\n                        (symbol, \"low\"),\n                        (symbol, \"close\"),\n                        (symbol, \"volume\"),\n                    ],\n                    name=[\"symbol\", \"candle_info\"],\n                )\n                data_index = pd.Index(\n                    data=pd.to_datetime(all_ohlcvs[:, 0].flatten(), unit=\"ms\"),\n                    name=\"open_time\",\n                )\n                data = pd.DataFrame(\n                    all_ohlcvs[:, 1:],\n                    columns=data_columns,\n                    index=data_index,\n                )\n                if drop_volume:\n                    data.drop(columns=(symbol, \"volume\"), inplace=True, axis=1)\n                final_df = final_df.join(data)\n            pbar.update(1)\n    final_df.sort_index(ascending=True, inplace=True)\n    final_df.sort_index(axis=1, level=0, sort_remaining=False)\n    final_df.dropna(how='all', inplace=True)\n    final_df.drop(final_df.tail(1).index, inplace=True)\n    return final_df\n</code></pre>"},{"location":"api/../quantfreedom/enums/","title":"Index","text":""},{"location":"api/../quantfreedom/enums/enums/","title":"Enums","text":"<p>Enums</p> <p>Warning</p> <p>\u2620\ufe0fTHIS IS A MASSIVE MASSIVE WARNING.\u2620\ufe0f</p> <p>Make sure you follow what the variable types are. If it says float you have to make sure you put a         decimal like 1. or 3., or if it says int that you make sure there are no decimals.</p> <p>If you do not follow exactly what the type says for you to do then numba will start crying and wont run your code.</p> <p>Then you will be sitting there for hours trying to debug what is wrong and then you will find out it is because you put a number as an int instead of a float</p> <p>Danger</p> <p>All inputs requiring you to tell it what percent you want something to be should be put in like 1. for 1% or 50. for 50%.</p> <p>If you put .01 for 1% the math will calculate it as .0001.</p>"},{"location":"api/../quantfreedom/enums/enums/#quantfreedom.enums.enums.RejectedOrderError","title":"RejectedOrderError","text":"<p>         Bases: <code>Exception</code></p> <p>Rejected order error.</p> Source code in <code>quantfreedom\\enums\\enums.py</code> <pre><code>class RejectedOrderError(Exception):\n\"\"\"Rejected order error.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/../quantfreedom/evaluators/","title":"Index","text":""},{"location":"api/../quantfreedom/evaluators/evaluators/","title":"Evaluators","text":""},{"location":"api/../quantfreedom/evaluators/evaluators/#quantfreedom.evaluators.evaluators.combine_evals","title":"combine_evals","text":"<pre><code>combine_evals(\n    first_eval_data,\n    second_eval_data,\n    plot_results=False,\n    first_eval_data_needs_prices=False,\n    second_eval_data_needs_prices=False,\n    prices=None,\n    first_ind_data=None,\n    second_ind_data=None,\n)\n</code></pre> <p>summary</p> <p>Parameters:</p> <ul> <li> first_eval_data             (<code>pdFrame</code>)         \u2013 <p>description</p> </li> <li> second_eval_data             (<code>pdFrame</code>)         \u2013 <p>description</p> </li> <li> plot_results             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> first_eval_data_needs_prices             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> second_eval_data_needs_prices             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> <li> prices             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> first_ind_data             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> second_ind_data             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pdFrame</code>         \u2013 <p>description</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> </ul> Source code in <code>quantfreedom\\evaluators\\evaluators.py</code> <pre><code>def combine_evals(\n    first_eval_data: pdFrame,\n    second_eval_data: pdFrame,\n    plot_results: bool = False,\n    first_eval_data_needs_prices: bool = False,\n    second_eval_data_needs_prices: bool = False,\n    prices: pdFrame = None,\n    first_ind_data: pdFrame = None,\n    second_ind_data: pdFrame = None,\n) -&gt; pdFrame:\n\"\"\"\n    _summary_\n\n    Parameters\n    ----------\n    first_eval_data : pdFrame\n        _description_\n    second_eval_data : pdFrame\n        _description_\n    plot_results : bool, optional\n        _description_, by default False\n    first_eval_data_needs_prices : bool, optional\n        _description_, by default False\n    second_eval_data_needs_prices : bool, optional\n        _description_, by default False\n    prices : pdFrame, optional\n        _description_, by default None\n    first_ind_data : pdFrame, optional\n        _description_, by default None\n    second_ind_data : pdFrame, optional\n        _description_, by default None\n\n    Returns\n    -------\n    pdFrame\n        _description_\n\n    Raises\n    ------\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    \"\"\"\n\n    if plot_results and (first_ind_data is None or second_ind_data is None):\n        raise ValueError(\n            \"Make sure you are sending first and second indicator data if you want to plot\")\n    elif plot_results:\n        if first_eval_data_needs_prices and prices is None:\n            raise ValueError(\"You need to provide prices to plot the candles\")\n        elif not first_eval_data_needs_prices and prices is not None:\n            raise ValueError(\n                \"Make sure you set first_eval_data_needs_prices to true if you want to send price data\")\n    elif not plot_results and (\n        first_eval_data_needs_prices or\n        prices is not None or\n        first_ind_data is not None or\n        second_ind_data is not None\n    ):\n        raise ValueError(\n            \"Make sure you set plot_results to true if you want to send any plotting data.\")\n\n    if len(first_eval_data.columns.levels) &lt; len(second_eval_data.columns.levels):\n        temp = len(first_eval_data.columns.levels)\n    else:\n        temp = len(second_eval_data.columns.levels)\n\n    list_for_product = []\n    pd_col_names = []\n    for x in range(temp):\n        if list(first_eval_data.columns.levels[x]) == list(second_eval_data.columns.levels[x]):\n            list_for_product.append(list(first_eval_data.columns.levels[x]))\n            pd_col_names.append(first_eval_data.columns.names[x])\n    levels = list(product(*list_for_product))\n\n    pd_col_names = pd_col_names + list(first_eval_data.droplevel(pd_col_names, axis=1).columns.names) + \\\n        list(second_eval_data.droplevel(pd_col_names, axis=1).columns.names)\n\n    combine_array = np.empty(\n        (first_eval_data.shape[0], first_eval_data[levels[0]].shape[1] * second_eval_data[levels[0]].shape[1] * len(levels)), dtype=np.bool_\n    )\n\n    try:\n        second_eval_data[levels[0]].columns[0][0]\n        temp_smaller_def_columns = list(second_eval_data[levels[0]].columns)\n    except:\n        temp_smaller_def_columns = []\n        for value in list(second_eval_data[levels[0]].columns):\n            temp_smaller_def_columns.append((value,))\n\n    try:\n        first_eval_data[levels[0]].columns[0][0]\n        temp_big_def_columns = list(first_eval_data[levels[0]].columns)\n    except:\n        temp_big_def_columns = []\n        for value in list(first_eval_data[levels[0]].columns):\n            temp_big_def_columns.append((value,))\n\n    comb_counter = 0\n    pd_multind_tuples = ()\n    for level in levels:\n        temp_big_df = first_eval_data[level]\n        temp_small_df = second_eval_data[level]\n        for big_count, big_values in enumerate(temp_big_df.values.T):\n\n            for small_count, small_values in enumerate(temp_small_df.values.T):\n\n                combine_array[:, comb_counter] = np.logical_and(\n                    big_values == True, small_values == True\n                )\n\n                pd_multind_tuples = pd_multind_tuples + (\n                    level + temp_big_def_columns[big_count] +\n                    temp_smaller_def_columns[small_count],\n                )\n\n                comb_counter += 1\n\n    if plot_results:\n        plot_index = second_eval_data.index\n\n        temp_first_ind_data = first_ind_data.iloc[:, -1]\n        temp_second_ind_data = second_ind_data.iloc[:, -1]\n\n        temp_combine_array = combine_array[:, -1]\n\n        # candle data with subplot\n        if first_eval_data_needs_prices and not second_eval_data_needs_prices:\n            temp_prices = prices[list(prices.columns)[-1][0]]\n            fig = make_subplots(\n                rows=2,\n                cols=1,\n                shared_xaxes=True,\n            )\n            fig.add_traces(\n                data=[\n                    go.Candlestick(\n                        x=plot_index,\n                        open=temp_prices.open,\n                        high=temp_prices.high,\n                        low=temp_prices.low,\n                        close=temp_prices.close,\n                        name=\"Candles\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_first_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='#60BFE1'),\n                        name=\"First Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_first_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n                rows=1,\n                cols=1,\n            )\n            fig.add_traces(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_second_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=2, color='#60BFE1'),\n                        name=\"Second Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_second_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n                rows=2,\n                cols=1,\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=700, title=\"Last Column of the Results\")\n            fig.show()\n\n        elif first_eval_data_needs_prices and second_eval_data_needs_prices:\n            temp_prices = prices[list(prices.columns)[-1][0]]\n            fig = go.Figure(\n                data=[\n                    go.Candlestick(\n                        x=plot_index,\n                        open=temp_prices.open,\n                        high=temp_prices.high,\n                        low=temp_prices.low,\n                        close=temp_prices.close,\n                        name=\"Candles\",\n                    ),\n\n                    # First Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_first_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='#60BFE1'),\n                        name=\"First Ind\",\n                    ),\n\n                    # Second Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_second_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='#84E5AC'),\n                        name=\"Second Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_second_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n        elif not first_eval_data_needs_prices and not second_eval_data_needs_prices:\n            fig = go.Figure(\n                data=[\n                    # First Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_first_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=2, color='green'),\n                        name=\"First Ind\",\n                    ),\n\n                    # Second Plot\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_second_ind_data,\n                        mode=\"lines\",\n                        line=dict(width=3, color='red'),\n                        name=\"Second Ind\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            temp_combine_array,\n                            temp_second_ind_data,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Combo Signals\",\n                    ),\n                ],\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n    return pd.DataFrame(\n        combine_array,\n        index=second_eval_data.index,\n        columns=pd.MultiIndex.from_tuples(\n            tuples=list(pd_multind_tuples),\n            names=pd_col_names,\n        ),\n    )\n</code></pre>"},{"location":"api/../quantfreedom/evaluators/evaluators/#quantfreedom.evaluators.evaluators.eval_is_below","title":"eval_is_below","text":"<pre><code>eval_is_below(\n    want_to_evaluate,\n    user_args=None,\n    indicator_data=None,\n    prices=None,\n    cand_ohlc=None,\n    plot_results=False,\n)\n</code></pre> <p>summary</p> <p>Parameters:</p> <ul> <li> want_to_evaluate             (<code>pdFrame</code>)         \u2013 <p>description</p> </li> <li> user_args             (<code>Union[list[int, float], int, float, Array1d], optional</code>)         \u2013 <p>description, by default None</p> </li> <li> indicator_data             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> prices             (<code>pdFrame, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> cand_ohlc             (<code>str, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> plot_results             (<code>bool, optional</code>)         \u2013 <p>description, by default False</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pdFrame</code>         \u2013 <p>description</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> <li> <code>ValueError</code>           \u2013         <p>description</p> </li> </ul> Source code in <code>quantfreedom\\evaluators\\evaluators.py</code> <pre><code>def eval_is_below(\n    want_to_evaluate: pdFrame,\n    user_args: Union[list[int, float], int, float, Array1d] = None,\n    indicator_data: pdFrame = None,\n    prices: pdFrame = None,\n    cand_ohlc: str = None,\n    plot_results: bool = False,\n) -&gt; pdFrame:\n\"\"\"\n    _summary_\n\n    Parameters\n    ----------\n    want_to_evaluate : pdFrame\n        _description_\n    user_args : Union[list[int, float], int, float, Array1d], optional\n        _description_, by default None\n    indicator_data : pdFrame, optional\n        _description_, by default None\n    prices : pdFrame, optional\n        _description_, by default None\n    cand_ohlc : str, optional\n        _description_, by default None\n    plot_results : bool, optional\n        _description_, by default False\n\n    Returns\n    -------\n    pdFrame\n        _description_\n\n    Raises\n    ------\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    ValueError\n        _description_\n    \"\"\"\n    if not isinstance(want_to_evaluate, pdFrame):\n        raise ValueError(\"Data must be a dataframe with multindex\")\n\n    want_to_evaluate_values = want_to_evaluate.values\n    want_to_evaluate_name = want_to_evaluate.columns.names[1].split(\"_\")[0]\n    pd_col_names = list(want_to_evaluate.columns.names) + [\n        want_to_evaluate_name + \"_is_below\"\n    ]\n    pd_multind_tuples = ()\n\n    if isinstance(user_args, (list, Array1d)):\n        if not all(isinstance(x, (int, float, np.int_, np.float_)) for x in user_args):\n            raise ValueError(\"user_args must be a list of ints or floats\")\n        user_args = np.asarray(user_args)\n\n        eval_array = np.empty(\n            (want_to_evaluate.shape[0], want_to_evaluate.shape[1] * user_args.size), dtype=np.bool_\n        )\n\n        eval_array_counter = 0\n        temp_eval_values = want_to_evaluate.values.T\n        for count, value in enumerate(want_to_evaluate.values.T):\n            for eval_col in range(user_args.size):\n                eval_array[:, eval_array_counter] = np.where(\n                    value &lt; user_args[eval_col], True, False\n                )\n                eval_array_counter += 1\n\n                pd_multind_tuples = pd_multind_tuples + (\n                    want_to_evaluate.columns[count] + (user_args[eval_col],),\n                )\n\n        if plot_results:\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=4),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n    elif isinstance(prices, pdFrame):\n        if cand_ohlc == None or cand_ohlc.lower() not in (\n            \"open\",\n            \"high\",\n            \"low\",\n            \"close\",\n        ):\n            raise ValueError(\n                \"cand_ohlc must be open, high, low or close when sending price data\"\n            )\n\n        eval_array = np.empty_like(want_to_evaluate, dtype=np.bool_)\n        symbols = list(prices.columns.levels[0])\n        eval_array_counter = 0\n\n        for symbol in symbols:\n            temp_prices_values = prices[symbol][cand_ohlc].values\n            if not all(isinstance(x, (np.int_, np.float_)) for x in temp_prices_values):\n                raise ValueError(\"price data must be ints or floats\")\n\n            temp_eval_values = want_to_evaluate[symbol].values.T\n\n            for values in temp_eval_values:\n                eval_array[:, eval_array_counter] = np.where(\n                    values &lt; temp_prices_values, True, False\n                )\n\n                pd_multind_tuples = pd_multind_tuples + (\n                    want_to_evaluate.columns[eval_array_counter] +\n                    (cand_ohlc,),\n                )\n                eval_array_counter += 1\n\n        if plot_results:\n            temp_prices = prices[prices.columns.levels[0][-1]]\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Candlestick(\n                        x=plot_index,\n                        open=temp_prices.open,\n                        high=temp_prices.high,\n                        low=temp_prices.low,\n                        close=temp_prices.close,\n                        name=\"Candles\",\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=4, color='lightblue'),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=3, color='yellow'),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_xaxes(rangeslider_visible=False)\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n        return pd.DataFrame(\n            eval_array,\n            index=want_to_evaluate.index,\n            columns=pd.MultiIndex.from_tuples(\n                tuples=list(pd_multind_tuples),\n                names=pd_col_names,\n            ),\n        ).swaplevel(1, -1, axis=1)\n\n    elif isinstance(indicator_data, pdFrame):\n        want_to_evaluate_name = want_to_evaluate.columns.names[-1].split(\"_\")[\n            1]\n        indicator_data_name = indicator_data.columns.names[-1].split(\"_\")[0]\n\n        pd_col_names = list(want_to_evaluate.columns.names) + [\n            want_to_evaluate_name + \"_is_below\"\n        ]\n\n        want_to_evaluate_settings_tuple_list = want_to_evaluate.columns.to_list()\n\n        eval_array = np.empty_like(want_to_evaluate,  dtype=np.bool_,)\n        pd_multind_tuples = ()\n\n        indicator_data_levels = list(indicator_data.columns)\n        eval_array_counter = 0\n\n        for level in indicator_data_levels:\n            temp_indicator_values = indicator_data[level].values\n            temp_evaluate_values = want_to_evaluate[level].values.T\n\n            for values in temp_evaluate_values:\n                eval_array[:, eval_array_counter] = np.where(\n                    values &lt; temp_indicator_values,\n                    True,\n                    False,\n                )\n                pd_multind_tuples = pd_multind_tuples + \\\n                    (want_to_evaluate_settings_tuple_list[eval_array_counter] + (\n                        indicator_data_name,),)\n                eval_array_counter += 1\n\n        if plot_results:\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            temp_ind_values = indicator_data.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_ind_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=4),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n\n    elif isinstance(user_args, (int, float)):\n        eval_array = np.where(want_to_evaluate_values &lt; user_args, True, False)\n\n        for col in range(want_to_evaluate.shape[1]):\n            pd_multind_tuples = pd_multind_tuples + (\n                want_to_evaluate.columns[col] + (user_args,),\n            )\n\n        if plot_results:\n            temp_eval_values = want_to_evaluate.iloc[:, -1].values\n            plot_index = want_to_evaluate.index\n\n            fig = go.Figure(\n                data=[\n                    go.Scatter(\n                        x=plot_index,\n                        y=temp_eval_values,\n                        mode=\"lines\",\n                        line=dict(width=2),\n                        name=want_to_evaluate_name,\n                    ),\n                    go.Scatter(\n                        x=plot_index,\n                        y=np.where(\n                            eval_array[:, -1],\n                            temp_eval_values,\n                            np.nan,\n                        ),\n                        mode=\"markers\",\n                        marker=dict(size=4),\n                        name=\"Signals\",\n                    ),\n                ]\n            )\n            fig.update_layout(height=500, title=\"Last Column of the Results\")\n            fig.show()\n    else:\n        raise ValueError(\n            \"something is wrong with what you sent please make sure the type of variable you are sending matches with the type required\"\n        )\n    return pd.DataFrame(\n        eval_array,\n        index=want_to_evaluate.index,\n        columns=pd.MultiIndex.from_tuples(\n            tuples=list(pd_multind_tuples),\n            names=pd_col_names,\n        ),\n    )\n</code></pre>"},{"location":"api/../quantfreedom/indicators/","title":"Index","text":""},{"location":"api/../quantfreedom/indicators/talib_ind/","title":"Talib ind","text":""},{"location":"api/../quantfreedom/nb/","title":"Index","text":""},{"location":"api/../quantfreedom/nb/buy_funcs/","title":"Buy funcs","text":""},{"location":"api/../quantfreedom/nb/buy_funcs/#quantfreedom.nb.buy_funcs.long_decrease_nb","title":"long_decrease_nb","text":"<pre><code>long_decrease_nb(\n    fee_pct,\n    order_result,\n    account_state,\n)\n</code></pre> <p>This is where the long position gets decreased or closed out.</p> Source code in <code>quantfreedom\\nb\\buy_funcs.py</code> <pre><code>@njit(cache=True)\ndef long_decrease_nb(\n    fee_pct: float,\n    order_result: OrderResult,\n    account_state: AccountState,\n):\n\"\"\"\n    This is where the long position gets decreased or closed out.\n    \"\"\"\n\n    if order_result.size_value &gt;= order_result.position:\n        size_value = order_result.position\n    else:\n        size_value = order_result.size_value\n\n    pct_chg_trade = (\n        order_result.price - order_result.average_entry\n    ) / order_result.average_entry  # math checked\n\n    # Set new order_result.position size_value and cash borrowed and cash used\n    position_new = order_result.position - size_value\n    position_pct_chg = (\n        order_result.position - position_new\n    ) / order_result.position  # math checked\n\n    # profit and loss calulation\n    coin_size = size_value / order_result.average_entry  # math checked\n    pnl = coin_size * (order_result.price - order_result.average_entry)  # math checked\n    fee_open = coin_size * order_result.average_entry * fee_pct  # math checked\n    fee_close = coin_size * order_result.price * fee_pct  # math checked\n    fees_paid = fee_open + fee_close  # math checked\n    realized_pnl = pnl - fees_paid  # math checked\n\n    # Setting new account_state.equity\n    equity_new = account_state.equity + realized_pnl\n\n    cash_borrowed_new = account_state.cash_borrowed - (\n        account_state.cash_borrowed * position_pct_chg\n    )\n\n    cash_used_new = account_state.cash_used - (\n        account_state.cash_used * position_pct_chg\n    )\n\n    available_balance_new = (\n        realized_pnl\n        + account_state.available_balance\n        + (account_state.cash_used * position_pct_chg)\n    )\n\n    return AccountState(\n        available_balance=available_balance_new,\n        cash_borrowed=cash_borrowed_new,\n        cash_used=cash_used_new,\n        equity=equity_new,\n    ), OrderResult(\n        average_entry=order_result.average_entry,\n        fees_paid=fees_paid,\n        leverage=order_result.leverage,\n        liq_price=order_result.liq_price,\n        moved_sl_to_be=order_result.moved_sl_to_be,\n        order_status=OrderStatus.Filled,\n        order_status_info=OrderStatusInfo.HopefullyNoProblems,\n        order_type=order_result.order_type,\n        pct_chg_trade=pct_chg_trade,\n        position=position_new,\n        price=order_result.price,\n        realized_pnl=realized_pnl,\n        size_value=size_value,\n        sl_pcts=order_result.sl_pcts,\n        sl_prices=order_result.sl_prices,\n        tp_pcts=order_result.tp_pcts,\n        tp_prices=order_result.tp_prices,\n        tsl_pcts_init=order_result.tsl_pcts_init,\n        tsl_prices=order_result.tsl_prices,\n    )\n</code></pre>"},{"location":"api/../quantfreedom/nb/execute_funcs/","title":"Execute funcs","text":"<p>Testing the tester</p>"},{"location":"api/../quantfreedom/nb/helper_funcs/","title":"Helper funcs","text":""},{"location":"api/../quantfreedom/nb/helper_funcs/#quantfreedom.nb.helper_funcs.to_1d_array_nb","title":"to_1d_array_nb","text":"<pre><code>to_1d_array_nb(\n    var,\n)\n</code></pre> <p>Resize array to one dimension.</p> Source code in <code>quantfreedom\\nb\\helper_funcs.py</code> <pre><code>@njit(cache=True)\ndef to_1d_array_nb(var: PossibleArray) -&gt; Array1d:\n\"\"\"Resize array to one dimension.\"\"\"\n    if var.ndim == 0:\n        return np.expand_dims(var, axis=0)\n    if var.ndim == 1:\n        return var\n    if var.ndim == 2 and var.shape[1] == 1:\n        return var[:, 0]\n    raise ValueError(\"to 1d array problem\")\n</code></pre>"},{"location":"api/../quantfreedom/nb/sell_funcs/","title":"Sell funcs","text":""},{"location":"api/../quantfreedom/nb/sell_funcs/#quantfreedom.nb.sell_funcs.short_decrease_nb","title":"short_decrease_nb","text":"<pre><code>short_decrease_nb(\n    fee_pct,\n    order_result,\n    account_state,\n)\n</code></pre> <p>This is where the long position gets decreased or closed out.</p> Source code in <code>quantfreedom\\nb\\sell_funcs.py</code> <pre><code>@njit(cache=True)\ndef short_decrease_nb(\n    fee_pct: float,\n    order_result: OrderResult,\n    account_state: AccountState,\n):\n\"\"\"\n    This is where the long position gets decreased or closed out.\n    \"\"\"\n\n    if order_result.size_value &gt;= order_result.position:\n        size_value = order_result.position\n    else:\n        size_value = order_result.size_value\n\n    pct_chg_trade = (\n        order_result.average_entry - order_result.price\n    ) / order_result.average_entry  # math checked\n\n    # Set new order_result.position size_value and cash borrowed and cash used\n    position_new = order_result.position - size_value\n    position_pct_chg = (\n        order_result.position - position_new\n    ) / order_result.position  # math checked\n\n    # profit and loss calulation\n    coin_size = size_value / order_result.average_entry  # math checked\n    pnl = coin_size * (order_result.average_entry - order_result.price)  # math checked\n    fee_open = coin_size * order_result.average_entry * fee_pct  # math checked\n    fee_close = coin_size * order_result.price * fee_pct  # math checked\n    fees_paid = fee_open + fee_close  # math checked\n    realized_pnl = pnl - fees_paid  # math checked\n\n    # Setting new account_state.equity\n    equity_new = account_state.equity + realized_pnl\n\n    cash_borrowed_new = account_state.cash_borrowed - (\n        account_state.cash_borrowed * position_pct_chg\n    )\n\n    cash_used_new = account_state.cash_used - (\n        account_state.cash_used * position_pct_chg\n    )\n\n    available_balance_new = (\n        realized_pnl\n        + account_state.available_balance\n        + (account_state.cash_used * position_pct_chg)\n    )\n\n    return AccountState(\n        available_balance=available_balance_new,\n        cash_borrowed=cash_borrowed_new,\n        cash_used=cash_used_new,\n        equity=equity_new,\n    ), OrderResult(\n        average_entry=order_result.average_entry,\n        fees_paid=fees_paid,\n        leverage=order_result.leverage,\n        liq_price=order_result.liq_price,\n        moved_sl_to_be=order_result.moved_sl_to_be,\n        order_status=OrderStatus.Filled,\n        order_status_info=OrderStatusInfo.HopefullyNoProblems,\n        order_type=order_result.order_type,\n        pct_chg_trade=pct_chg_trade,\n        position=position_new,\n        price=order_result.price,\n        realized_pnl=realized_pnl,\n        size_value=size_value,\n        sl_pcts=order_result.sl_pcts,\n        sl_prices=order_result.sl_prices,\n        tp_pcts=order_result.tp_pcts,\n        tp_prices=order_result.tp_prices,\n        tsl_pcts_init=order_result.tsl_pcts_init,\n        tsl_prices=order_result.tsl_prices,\n    )\n</code></pre>"},{"location":"api/../quantfreedom/nb/simulate/","title":"Simulate","text":""},{"location":"api/../quantfreedom/nb/temp/","title":"Temp","text":""},{"location":"api/../quantfreedom/plotting/","title":"Index","text":""},{"location":"api/../quantfreedom/plotting/plot_helper_functions/","title":"Plot helper functions","text":""},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list","title":"append_to_trace_data_list","text":"<pre><code>append_to_trace_data_list(\n    trace_data_list,\n    dict_key,\n    dict_value,\n    index_prices,\n    temp_ind_vals,\n)\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list--function-name","title":"Function Name","text":"<pre><code>append_to_trace_data_list\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list--quick-summary","title":"Quick Summary","text":"<pre><code>appending value or entry scatter plots to the trace data list\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.append_to_trace_data_list--required-parameters","title":"Required Parameters","text":"<p>Variable Name: Variable Type</p> <p>trace_data_list: list     trace data list dict_key: str     either values or entries dict_value: pdFrame     dataframe of either an indicator or entries index_prices: pdIndex     index temp_ind_vals: pdFrame     needed so we can use this if the dict key is entries so we can generate temp_ind_entries</p> Source code in <code>quantfreedom\\plotting\\plot_helper_functions.py</code> <pre><code>def append_to_trace_data_list(\n    trace_data_list: list,\n    dict_key: str,\n    dict_value: pdFrame,\n    index_prices: pdIndex,\n    temp_ind_vals: pdFrame,\n):\n\"\"\"\n    Function Name\n    -------------\n        append_to_trace_data_list\n\n    Quick Summary\n    -------------\n        appending value or entry scatter plots to the trace data list\n\n    Required Parameters\n    -------------------\n    Variable Name: Variable Type\n\n    trace_data_list: list\n        trace data list\n    dict_key: str\n        either values or entries\n    dict_value: pdFrame\n        dataframe of either an indicator or entries\n    index_prices: pdIndex\n        index\n    temp_ind_vals: pdFrame\n        needed so we can use this if the dict key is entries so we can generate temp_ind_entries\n    \"\"\"\n    if \"values\" in dict_key:\n        temp_ind_vals[0] = dict_value.values.flatten()\n        ind_name = list(dict_value.columns.names)[1].split(\"_\")[0]\n        ind_value = str(list(dict_value.columns)[0][0])\n        trace_data_list.append(\n            go.Scatter(\n                x=index_prices,\n                y=temp_ind_vals[0],\n                mode=\"lines\",\n                name=ind_name + \" \" + ind_value,\n            )\n        )\n    elif \"entries\" in dict_key:\n        temp_ind_entries = np.where(\n            dict_value.values.flatten(), temp_ind_vals[0], np.nan\n        ).flatten()\n        trace_data_list.append(\n            go.Scatter(\n                x=index_prices,\n                y=temp_ind_entries,\n                mode=\"markers\",\n                name=\"Signals\",\n            )\n        )\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data","title":"get_candle_trace_data","text":"<pre><code>get_candle_trace_data(\n    index_prices,\n    prices,\n    order_records,\n    indicator_dict,\n)\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data--function-name","title":"Function Name","text":"<pre><code>get_candle_trace_data\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data--quick-summary","title":"Quick Summary","text":"<pre><code>Here we take all the info needed to create a candlestick chart and also place indicators on top of the candle stick chart\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plot_helper_functions/#quantfreedom.plotting.plot_helper_functions.get_candle_trace_data--required-parameters","title":"Required Parameters","text":"<p>Variable Name: Variable Type</p> <p>index_prices: pdIndex     index prices: pdFrame     price dataframe order_records: RecordArray     order records indicator_dict: dict     dictionary of candle stick and indicator data</p> <p>Returns:</p> <ul> <li> <code>list</code>         \u2013 <p>list of Candle stick chart and indicators data for plotly</p> </li> </ul> Source code in <code>quantfreedom\\plotting\\plot_helper_functions.py</code> <pre><code>def get_candle_trace_data(\n    index_prices: pdIndex,\n    prices: pdFrame,\n    order_records: RecordArray,\n    indicator_dict: dict,\n)-&gt; list:\n\"\"\"\n    Function Name\n    -------------\n        get_candle_trace_data\n\n    Quick Summary\n    -------------\n        Here we take all the info needed to create a candlestick chart and also place indicators on top of the candle stick chart\n\n    Required Parameters\n    -------------------\n    Variable Name: Variable Type\n\n    index_prices: pdIndex\n        index\n    prices: pdFrame\n        price dataframe\n    order_records: RecordArray\n        order records\n    indicator_dict: dict\n        dictionary of candle stick and indicator data\n\n    Returns\n    -------\n    list\n        list of Candle stick chart and indicators data for plotly\n    \"\"\"\n    array_size = prices.shape[0]\n\n    order_price_array = np.full(array_size, np.nan)\n    avg_entry_array = np.full(array_size, np.nan)\n    stop_loss_array = np.full(array_size, np.nan)\n    trailing_sl_array = np.full(array_size, np.nan)\n    take_profit_array = np.full(array_size, np.nan)\n\n    or_counter = 0\n    array_counter = 0\n\n    avg_entry_current = np.array([0.0])\n    stop_loss_current = np.array([0.0])\n    trailing_sl_current = np.array([0.0])\n    take_profit_current = np.array([0.0])\n\n    for i in range(array_size):\n        if or_counter &lt; order_records.size and order_records[\"bar\"][or_counter] == i:\n            fill_candle_trace_trades(\n                order_records=order_records[or_counter],\n                order_price_array=order_price_array,\n                avg_entry_array=avg_entry_array,\n                stop_loss_array=stop_loss_array,\n                trailing_sl_array=trailing_sl_array,\n                take_profit_array=take_profit_array,\n                avg_entry_current=avg_entry_current,\n                stop_loss_current=stop_loss_current,\n                trailing_sl_current=trailing_sl_current,\n                take_profit_current=take_profit_current,\n                array_counter=array_counter,\n            )\n            or_counter += 1\n\n            if (\n                or_counter &lt; order_records.size\n                and order_records[\"bar\"][or_counter] == i\n            ):\n                fill_candle_trace_trades(\n                    order_records=order_records[or_counter],\n                    order_price_array=order_price_array,\n                    avg_entry_array=avg_entry_array,\n                    stop_loss_array=stop_loss_array,\n                    trailing_sl_array=trailing_sl_array,\n                    take_profit_array=take_profit_array,\n                    avg_entry_current=avg_entry_current,\n                    stop_loss_current=stop_loss_current,\n                    trailing_sl_current=trailing_sl_current,\n                    take_profit_current=take_profit_current,\n                    array_counter=array_counter,\n                )\n            or_counter += 1\n        array_counter += 1\n    trace_data_list = cerate_candle_trace_trades_list(\n        index_prices=index_prices,\n        prices=prices,\n        order_price_array=order_price_array,\n        avg_entry=avg_entry_array,\n        stop_loss=stop_loss_array,\n        trailing_sl=trailing_sl_array,\n        take_profit=take_profit_array,\n    )\n    if list(indicator_dict.keys())[0] == \"candle_chart\":\n        temp_ind_vals = np.array([0], dtype=object)\n        for candle_ind_key, candle_ind_value in indicator_dict[\"candle_chart\"].items():\n            append_to_trace_data_list(\n                trace_data_list,\n                index_prices=index_prices,\n                dict_key=candle_ind_key,\n                dict_value=candle_ind_value,\n                temp_ind_vals=temp_ind_vals,\n            )\n    return trace_data_list\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plotting_main/","title":"Plotting main","text":""},{"location":"api/../quantfreedom/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard","title":"strat_dashboard","text":"<pre><code>strat_dashboard(\n    indicator_dict,\n    prices,\n    order_records,\n)\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--function-name","title":"Function Name","text":"<pre><code>strat_dashboard\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--quick-summary","title":"Quick Summary","text":"<pre><code>Creates a dashboard with your trades, indicators, cumliative PnL and the order records of all the trades.\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre>"},{"location":"api/../quantfreedom/plotting/plotting_main/#quantfreedom.plotting.plotting_main.strat_dashboard--required-parameters","title":"Required Parameters","text":"<p>Variable Name: Variable Type</p> <p>indicator_dict: dict     You need to create a dictionary of all your indicators.</p> <pre><code>If you have any indicators that need to go on the candle stick chart then make a key named candle_chart and inside of that you put your indicator values with keys called value with a number after it like in the example, then you provide the entries\n\nIf you have indicators that need their own chart then create a key called indicator with a number after it and then provide the indicator values and the entries in new keys.\n\nExample:\n    indicator_dict = {\n            \"candle_chart\": {\n                \"values1\": ema_300_ind[[('BTCUSDT', 300)]],\n                \"values2\": ema_600_ind[[('BTCUSDT', 600)]],\n                \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                },\n            \"indicator1\": {\n                \"values1\": rsi_ind[[('BTCUSDT', 30)]],\n                \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                },\n            \"indicator2\": {\n                \"values1\": atr_ind[[('BTCUSDT', 50)]],\n                \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                },\n            }\n</code></pre> <p>prices: pdFrame     Your prices info as one symbol like prices['BTCUSDT']</p> <p>order_records: RecordArray     Order Records</p> <p>Returns:</p> <ul> <li> <code>JupyterDash</code>         \u2013 <p>Returns a jupyter dashboard that will open up in a new window when you click on the local host url</p> </li> </ul> Source code in <code>quantfreedom\\plotting\\plotting_main.py</code> <pre><code>def strat_dashboard(\n    indicator_dict: dict,\n    prices: pdFrame,\n    order_records: RecordArray,\n) -&gt; JupyterDash:\n\"\"\"\n    Function Name\n    -------------\n        strat_dashboard\n\n    Quick Summary\n    -------------\n        Creates a dashboard with your trades, indicators, cumliative PnL and the order records of all the trades.\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Required Parameters\n    -------------------\n    Variable Name: Variable Type\n\n    indicator_dict: dict\n        You need to create a dictionary of all your indicators.\n\n        If you have any indicators that need to go on the candle stick chart then make a key named candle_chart and inside of that you put your indicator values with keys called value with a number after it like in the example, then you provide the entries\n\n        If you have indicators that need their own chart then create a key called indicator with a number after it and then provide the indicator values and the entries in new keys.\n\n        Example:\n            indicator_dict = {\n                    \"candle_chart\": {\n                        \"values1\": ema_300_ind[[('BTCUSDT', 300)]],\n                        \"values2\": ema_600_ind[[('BTCUSDT', 600)]],\n                        \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                        },\n                    \"indicator1\": {\n                        \"values1\": rsi_ind[[('BTCUSDT', 30)]],\n                        \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                        },\n                    \"indicator2\": {\n                        \"values1\": atr_ind[[('BTCUSDT', 50)]],\n                        \"entries\": entries[[(\"BTCUSDT\", 30, 50, 300, 600)]],\n                        },\n                    }\n    prices: pdFrame\n        Your prices info as one symbol like prices['BTCUSDT']\n\n    order_records: RecordArray\n        Order Records\n\n    Returns\n    -------\n    JupyterDash\n        Returns a jupyter dashboard that will open up in a new window when you click on the local host url\n    \"\"\"\n\n    amount_of_subplots = 0\n\n    for keys in indicator_dict.keys():\n        if \"indicator\" in keys:\n            amount_of_subplots += 1\n\n    layout_height = 500 + (250 * amount_of_subplots)\n    candle_chart_height_pct = [500 / layout_height]\n\n    if amount_of_subplots &gt; 0:\n        subchart_heights_pct = np.array(\n            [((layout_height - 500) / layout_height) / amount_of_subplots]\n            * amount_of_subplots\n        ).tolist()\n        row_heights = candle_chart_height_pct + subchart_heights_pct\n        fig = make_subplots(\n            rows=amount_of_subplots + 1,\n            cols=1,\n            shared_xaxes=True,\n            vertical_spacing=0.02,\n            row_heights=row_heights,\n        )\n    else:\n        fig = make_subplots()\n\n    index_prices = prices.index.to_list()\n\n    # candle chart trace\n    fig.add_traces(\n        data=get_candle_trace_data(\n            index_prices=index_prices,\n            prices=prices,\n            order_records=order_records,\n            indicator_dict=indicator_dict,\n        ),\n        rows=1,\n        cols=1,\n    )\n    try:\n        del indicator_dict[\"candle_chart\"]\n    except:\n        pass\n\n    row_count = 2\n    for indicator_dict_value in indicator_dict.values():\n        trace_data_list = []\n        temp_ind_vals = np.array([0], dtype=object)\n        for ind_key, ind_value in indicator_dict_value.items():\n            append_to_trace_data_list(\n                trace_data_list=trace_data_list,\n                index_prices=index_prices,\n                dict_key=ind_key,\n                dict_value=ind_value,\n                temp_ind_vals=temp_ind_vals,\n            )\n        fig.add_traces(\n            data=trace_data_list,\n            rows=row_count,\n            cols=1,\n        )\n        row_count += 1\n    fig.update_xaxes(row=1, col=1, rangeslider_visible=False)\n    fig.update_yaxes(row=1, col=1, tickprefix=\"$\")\n    fig.update_layout(\n        height=layout_height,\n        paper_bgcolor=bg_color,\n        plot_bgcolor=bg_color,\n    )\n    candle_trades_and_ind = (\n        html.H1(\n            \"All Trades For This Strategy\",\n            style={\n                \"textAlign\": \"center\",\n                \"font-weight\": \"bold\",\n                \"font-size\": \"5em\",\n                \"padding-top\": \"20px\",\n            },\n        ),\n        dcc.Graph(\n            id=\"candles-trades\",\n            figure=fig,\n        ),\n    )\n\n    y_pnl = np.append(\n        0,\n        order_records[\"real_pnl\"][~np.isnan(order_records[\"real_pnl\"])].cumsum(),\n    )\n\n    pnl_graph = go.Figure(\n        data=[\n            go.Scatter(\n                x=np.arange(0, y_pnl.size),\n                y=y_pnl,\n                mode=\"lines+markers\",\n                marker=dict(size=6),\n                line=dict(color=\"#247eb2\"),\n            ),\n        ]\n    ).update_layout(\n        paper_bgcolor=bg_color,\n        plot_bgcolor=bg_color,\n    )\n    pnl_graph.update_yaxes(tickprefix=\"$\"),\n\n    pnl_graph = (\n        html.H1(\n            \"Cumulative PnL Over Time\",\n            style={\n                \"textAlign\": \"center\",\n                \"font-weight\": \"bold\",\n            },\n        ),\n        dcc.Graph(\n            id=\"pnl-graph\",\n            figure=pnl_graph,\n        ),\n    )\n\n    d_table = pd.DataFrame(order_records)\n    for i in range(len(OrderType._fields)):\n        d_table.replace({\"order_type\": {i: OrderType._fields[i]}}, inplace=True)\n\n    for col in d_table:\n        if d_table[col].dtype == \"float64\":\n            d_table[col] = d_table[col].map(\"{:,.2f}\".format)\n    d_table = d_table.to_dict(\"records\")\n\n    d_table = (\n        html.H1(\n            \"Table of All Orders\",\n            style={\n                \"textAlign\": \"center\",\n                \"font-weight\": \"bold\",\n            },\n        ),\n        dash_table.DataTable(\n            data=d_table,\n            id=\"d-table\",\n            page_size=50,\n            # page_action='none',\n            style_table={\"height\": \"400px\", \"overflowY\": \"auto\"},\n            fixed_rows={\"headers\": True},\n            style_header={\"backgroundColor\": \"rgb(30, 30, 30)\", \"color\": \"white\"},\n            style_data={\"backgroundColor\": \"rgb(50, 50, 50)\", \"color\": \"white\"},\n            style_cell_conditional=[\n                {\"if\": {\"column_id\": \"settings_id\"}, \"width\": \"110px\"},\n                {\"if\": {\"column_id\": \"order_id\"}, \"width\": \"90px\"},\n            ],\n        ),\n    )\n\n    app.layout = html.Div(\n        [\n            html.Div(\n                candle_trades_and_ind,\n            ),\n            html.Div(\n                pnl_graph,\n            ),\n            html.Div(\n                d_table,\n            ),\n        ]\n    )\n\n    return app.run_server(debug=True, port=3003)\n</code></pre>"},{"location":"api/../quantfreedom/plotting/replay/","title":"Replay","text":""},{"location":"api/../quantfreedom/plotting/temp/","title":"Temp","text":""},{"location":"api/../quantfreedom/utils/","title":"Index","text":""},{"location":"api/../quantfreedom/utils/#quantfreedom.utils.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache()\n</code></pre> <p>clears the python cache and numba cache</p> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def clear_cache():\n\"\"\"\n    clears the python cache and numba cache\n    \"\"\"\n    for p in Path(dir_path).parent.parent.rglob(\"numba_cache\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"__pycache__\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"*.py[co]\"):\n        p.unlink()\n</code></pre>"},{"location":"api/../quantfreedom/utils/#quantfreedom.utils.pretty","title":"pretty","text":"<pre><code>pretty(\n    object,\n)\n</code></pre> <p>Prints named tuples in a pretty way like StopOrder(     var1=54,     var2=1000,     var3=2.45, )</p> <p>Parameters:</p> <ul> <li> object             (<code>namedtuple</code>)         \u2013 <p>must only be a named tuple</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def pretty(\n    object: tuple,\n):\n\"\"\"\n    Prints named tuples in a pretty way like\n    StopOrder(\n        var1=54,\n        var2=1000,\n        var3=2.45,\n    )\n\n    Parameters\n    ----------\n    object : namedtuple\n        must only be a named tuple\n    \"\"\"\n    try:\n        object._fields[0]\n        items = []\n        indent = str(\"    \")\n        for x in range(len(object)):\n            items.append(indent + object._fields[x] + \" = \" + str(object[x]) + \",\\n\")\n        print(type(object).__name__ + \"(\" + \"\\n\" + \"\".join(items) + \")\")\n    except:\n        print(object)\n</code></pre>"},{"location":"api/../quantfreedom/utils/helpers/","title":"Helpers","text":""},{"location":"api/../quantfreedom/utils/helpers/#quantfreedom.utils.helpers.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache()\n</code></pre> <p>clears the python cache and numba cache</p> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def clear_cache():\n\"\"\"\n    clears the python cache and numba cache\n    \"\"\"\n    for p in Path(dir_path).parent.parent.rglob(\"numba_cache\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"__pycache__\"):\n        delete_dir(p)\n    for p in Path(__file__).parent.parent.rglob(\"*.py[co]\"):\n        p.unlink()\n</code></pre>"},{"location":"api/../quantfreedom/utils/helpers/#quantfreedom.utils.helpers.delete_dir","title":"delete_dir","text":"<pre><code>delete_dir(\n    p,\n)\n</code></pre> <p>Delete info in directory</p> <p>Parameters:</p> <ul> <li> p             (<code>path</code>)         \u2013 <p>path to directory</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def delete_dir(\n    p,\n):\n\"\"\"\n    Delete info in directory\n\n    Parameters\n    ----------\n    p : path\n        path to directory\n    \"\"\"\n    for sub in p.iterdir():\n        if sub.is_dir():\n            delete_dir(sub)\n        else:\n            sub.unlink()\n    p.rmdir()\n</code></pre>"},{"location":"api/../quantfreedom/utils/helpers/#quantfreedom.utils.helpers.generate_candles","title":"generate_candles","text":"<pre><code>generate_candles(\n    number_of_candles=100,\n    seed=None,\n)\n</code></pre> <p>Generate a dataframe filled with random candles</p>"},{"location":"api/../quantfreedom/utils/helpers/#quantfreedom.utils.helpers.generate_candles--explainer-video","title":"Explainer Video","text":"<pre><code>Coming_Soon\n</code></pre> <p>Parameters:</p> <ul> <li> number_of_candles             (<code>int</code>)         \u2013 <p>number of candles you want to create</p> </li> <li> seed             (<code>int</code>)         \u2013 <p>random seed number</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pdFrame</code>         \u2013 <p>Dataframe of open high low close</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def generate_candles(\n    number_of_candles: int = 100,\n    seed: int = None,\n) -&gt; pdFrame:\n\"\"\"\n    Generate a dataframe filled with random candles\n\n    Explainer Video\n    ---------------\n        Coming_Soon\n\n    Parameters\n    ----------\n    number_of_candles: int = 100\n        number of candles you want to create\n    seed: int = None\n        random seed number\n\n    Returns\n    -------\n    pdFrame\n        Dataframe of open high low close\n    \"\"\"\n    np.random.seed(seed)\n\n    periods = number_of_candles * 48\n\n    prices = np.around(5000 + np.random.normal(scale=1.5, size=periods).cumsum(), 2)\n\n    data = pd.DataFrame(\n        prices,\n        index=pd.Index(\n            pd.date_range(\"01/01/2000\", periods=periods, freq=\"30min\"),\n            name=\"open_time\",\n        ),\n        columns=[\"price\"],\n    )\n    data = data.price.resample(\"D\").ohlc()\n\n    data.columns = pd.MultiIndex.from_tuples(\n        tuples=[\n            (\"QuantFreedom\", \"open\"),\n            (\"QuantFreedom\", \"high\"),\n            (\"QuantFreedom\", \"low\"),\n            (\"QuantFreedom\", \"close\"),\n        ],\n        name=[\"symbol\", \"candle_info\"],\n    )\n    fig = go.Figure(\n        data=go.Candlestick(\n            x=data.index,\n            open=data.iloc[:, 0],\n            high=data.iloc[:, 1],\n            low=data.iloc[:, 2],\n            close=data.iloc[:, 3],\n        )\n    )\n    fig.update_layout(xaxis_rangeslider_visible=False)\n    fig.show()\n\n    return data\n</code></pre>"},{"location":"api/../quantfreedom/utils/helpers/#quantfreedom.utils.helpers.pretty","title":"pretty","text":"<pre><code>pretty(\n    object,\n)\n</code></pre> <p>Prints named tuples in a pretty way like StopOrder(     var1=54,     var2=1000,     var3=2.45, )</p> <p>Parameters:</p> <ul> <li> object             (<code>namedtuple</code>)         \u2013 <p>must only be a named tuple</p> </li> </ul> Source code in <code>quantfreedom\\utils\\helpers.py</code> <pre><code>def pretty(\n    object: tuple,\n):\n\"\"\"\n    Prints named tuples in a pretty way like\n    StopOrder(\n        var1=54,\n        var2=1000,\n        var3=2.45,\n    )\n\n    Parameters\n    ----------\n    object : namedtuple\n        must only be a named tuple\n    \"\"\"\n    try:\n        object._fields[0]\n        items = []\n        indent = str(\"    \")\n        for x in range(len(object)):\n            items.append(indent + object._fields[x] + \" = \" + str(object[x]) + \",\\n\")\n        print(type(object).__name__ + \"(\" + \"\\n\" + \"\".join(items) + \")\")\n    except:\n        print(object)\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>You will find tutorials here on various subjects ... please select from the menu on the left.</p> <p>In most if not all of my links you will see three sections. One will be the offical documentaion link. Second will be the link to a youtube video i made explaining the subject. Third will be a couple of links to written tutorials.</p> <p>The reason I am doing it this way is because there is no need to reinvent the wheel. There are plenty of people who haven written great blog posts on the basics of how to use the function. For me it is more important to make the youtube video because in there i will be going over specific things that i use the function for. In my opinion it is easier to learn from a video about the specifics and the written is better for just a quick refreasher on remembering a paramater or argument the function takes. So that is why i provide both as a solution. </p>"},{"location":"tutorials/#how-to-learn-how-to-code","title":"How to learn how to code","text":"<p>make youtube video explaining the test file strategy</p>"},{"location":"tutorials/#numpy-tutorials","title":"Numpy Tutorials","text":"<p>Here i will be going over numpy tutorials based on the numpy functions i am mainly using in my project or my daily coding. You should get real familiar with the numpy documentation and how to search there. https://numpy.org/doc/stable/index.html</p>"},{"location":"tutorials/git/","title":"Git","text":"<p>create empty branch git switch --orphan  git commit --allow-empty -m \"Initial commit on orphan branch\" git push -u origin  <p>configure your user.name and user.email in git In your shell, add your user name:</p> <p>git config --global user.name \"your_username\"</p> <p>Add your email address:</p> <p>git config --global user.email \"your_email_address@example.com\"</p> <p>To check the configuration, run:</p> <p>git config --global --list</p>"},{"location":"tutorials/python/","title":"Python","text":"<p>tuple     Test type of elements python tuple/list https://stackoverflow.com/questions/8964191/test-type-of-elements-python-tuple-list     add to a tuple    hey = ()    hey + (9,) + (5,)</p> <pre><code>turn a tuple into a list turn a list into a tuple\n</code></pre> <p>dictionary     How to check if a dictionary is empty? https://stackoverflow.com/questions/23177439/how-to-check-if-a-dictionary-is-empty</p> <pre><code>turn a dictionary into a list\nhttps://stackoverflow.com/questions/1679384/converting-dictionary-to-list\nfor key, value in dict.iteritems():\n    temp = [key,value]\n    dictlist.append(temp)\n</code></pre> <p>list     append to beginning of list         https://stackoverflow.com/questions/17911091/append-integer-to-beginning-of-list-in-python</p> <pre><code>turn a list into a dictionary https://builtin.com/software-engineering-perspectives/convert-list-to-dictionary-python\n\nappend to list without chaning the original list\nhttps://stackoverflow.com/questions/35608790/how-to-add-new-value-to-a-list-without-using-append-and-then-store-the-value\n['yo'] + param_keys + ['hey']\n\nget specific part of a string python\nhttps://stackoverflow.com/questions/27387415/how-would-i-get-everything-before-a-in-a-string-python\nparam_keys[0].split('_')[0] returns rsi\n</code></pre> <p>How to open a URL in python https://stackoverflow.com/questions/4302027/how-to-open-a-url-in-python</p> <p>itertools cart product         final_user_args = np.array(list(product(*users_args_list))).T</p> <p>if statement one line 'Yes' if fruit == 'Apple' else 'No' https://stackoverflow.com/questions/2802726/putting-a-simple-if-then-else-statement-on-one-line</p> <p>How to test multiple variables for equality against a single value? and test one variable against multiple values https://stackoverflow.com/questions/15112125/how-to-test-multiple-variables-for-equality-against-a-single-value if tester.lower() in ('open', 'high', 'low', 'close'): if tester.lower() not in ('open', 'high', 'low', 'close'):</p> <p>capitalize upper lowercase str or list .upper .lower .capitialize</p> <p>list comprehension for loop  param_keys = [ind_name + '_' + x for x in param_keys] </p> <p>How to \"test\" NoneType in python? if variable is None:</p> <p>how to check whether list contains only None in python print('yes') if all(x is None for x in test) else print('No')</p> <p>How do I check if a list is empty? https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty if not a:     print(\"List is empty\")</p>"},{"location":"tutorials/vscode/","title":"Vscode","text":"<p>how to turn off auto complete for txt files https://stackoverflow.com/questions/71049196/how-can-i-turn-off-auto-complete-for-txt-files-in-vs-code</p> <p>if you forked my project to get the latest updates you want to go to the source then remotes then open the upstream then make sure you are in the branch you want to update and then right click the upstream dev or main branch and then merge into current branch then once you do that you can sync your changes from your local branch to your orgin branch aka github</p>"},{"location":"tutorials/numpy/broadcasting/","title":"Broadcasting","text":"<p>I will be going over all things broadcasting in this section</p>"},{"location":"tutorials/numpy/broadcasting/#npbroadcast_to","title":"np.broadcast_to","text":""},{"location":"tutorials/numpy/broadcasting/#offical-numpy-doc-link","title":"Offical numpy doc link","text":"<p>https://numpy.org/doc/stable/reference/generated/numpy.broadcast_to.html</p>"},{"location":"tutorials/numpy/broadcasting/#my-youtube-tutorial-video","title":"My Youtube Tutorial Video","text":"<p>https://youtu.be/2rZnShOh9as</p>"},{"location":"tutorials/numpy/broadcasting/#written-examples","title":"Written Examples","text":"<p>https://note.nkmk.me/en/python-numpy-broadcasting/ https://www.codespeedy.com/how-does-numpy-broadcast_to-work-with-examples-in-python/ https://www.geeksforgeeks.org/numpy-broadcast_to-function-python/ https://www.w3resource.com/numpy/manipulation/broadcast-to.php https://www.educative.io/answers/what-is-the-numpybroadcastto-function-in-numpy</p>"},{"location":"tutorials/numpy/dtypes/","title":"Data Types","text":""},{"location":"tutorials/numpy/formatting/","title":"Formatting","text":"<p>Formatting floats in a numpy array - Pretty-print a NumPy array without scientific notation and with given precision -  https://stackoverflow.com/questions/21008858/formatting-floats-in-a-numpy-array np.set_printoptions(formatter={'float_kind':\"{:.2f}\".format})</p> <p>How do I print the full NumPy array, without truncation? https://stackoverflow.com/questions/1987694/how-do-i-print-the-full-numpy-array-without-truncation?rq=1</p>"},{"location":"tutorials/numpy/logical/","title":"Logical","text":"<p>Here we will be going over different functions that test if something is true or false</p>"},{"location":"tutorials/numpy/logical/#npwhere","title":"np.where","text":""},{"location":"tutorials/numpy/logical/#offical-doc-link","title":"Offical Doc Link","text":"<p>https://numpy.org/doc/stable/reference/generated/numpy.where.html</p>"},{"location":"tutorials/numpy/logical/#my-youtube-tutorial-video","title":"My Youtube Tutorial Video","text":"<p>https://youtu.be/-oMjyoQhvCY</p>"},{"location":"tutorials/numpy/logical/#written-examples-links","title":"Written Examples Links","text":"<p>https://sparkbyexamples.com/numpy/numpy-where-function/ https://www.digitalocean.com/community/tutorials/python-numpy-where https://www.sharpsightlabs.com/blog/numpy-where/ https://www.geeksforgeeks.org/numpy-where-in-python</p>"},{"location":"tutorials/numpy/random/","title":"Random","text":"<p>numpy random ints from a low to a high in steps https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html#numpy.random.randint</p>"},{"location":"tutorials/pandas_dataframe/dataframe/","title":"Dataframe","text":"<p>Time to talk about the basics of just creating a pandas dataframe</p>"},{"location":"tutorials/pandas_dataframe/dataframe/#pandasdataframe","title":"pandas.DataFrame","text":""},{"location":"tutorials/pandas_dataframe/dataframe/#offical-doc-link","title":"Offical Doc Link","text":"<p>https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html</p>"},{"location":"tutorials/pandas_dataframe/dataframe/#my-youtube-tutorial-video","title":"My Youtube Tutorial Video","text":"<p>https://youtu.be/KaUn5KFkXdM</p>"},{"location":"tutorials/pandas_dataframe/dataframe/#written-examples-links","title":"Written Examples Links","text":"<p>https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/ https://www.w3schools.com/python/pandas/pandas_dataframes.asp https://towardsdatascience.com/15-ways-to-create-a-pandas-dataframe-754ecc082c17 https://pynative.com/pandas-dataframe-from-python-dict/ https://www.javatpoint.com/how-to-create-a-dataframes-in-python</p>"},{"location":"tutorials/pandas_functions/indexing/","title":"Indexing","text":"<p>We will be learning a lot about indexing using different pandas functions.</p> <p>https://pandas.pydata.org/docs/user_guide/advanced.html https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html</p>"},{"location":"tutorials/pandas_functions/indexing/#pandasdataframexs","title":"pandas.DataFrame.xs","text":""},{"location":"tutorials/pandas_functions/indexing/#offical-doc-link","title":"Offical Doc Link","text":"<p>https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html</p>"},{"location":"tutorials/pandas_functions/indexing/#my-youtube-tutorial-video","title":"My Youtube Tutorial Video","text":"<p>https://youtu.be/kD7btJbZ9q4</p>"},{"location":"tutorials/pandas_functions/indexing/#written-examples-links","title":"Written Examples Links","text":"<p>https://www.w3resource.com/pandas/dataframe/dataframe-xs.php https://www.w3schools.com/python/pandas/ref_df_xs.asp https://www.geeksforgeeks.org/python-pandas-series-xs/ https://www.geeksforgeeks.org/how-to-find-the-cross-section-of-pandas-data-frame/</p> <p>combos_finished.iloc(axis=1)[1] will return column 1 as a series and combos_finished.iloc(axis=1)[[1,4]] will return columns 1 and 4 as dataframe</p>"},{"location":"tutorials/pandas_functions/multiindex/","title":"MultiIndex","text":"<p>We will be learning more about multiIndexing using pandas ... this is very very very very important to understand as a quant. Make sure you check out the offical pandas website and read through the entire documentation on this because it is really important you know how it works.</p> <p>https://pandas.pydata.org/docs/user_guide/advanced.html https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html</p>"},{"location":"tutorials/pandas_functions/multiindex/#pandasmultiindexfrom_tuples","title":"pandas.MultiIndex.from_tuples","text":""},{"location":"tutorials/pandas_functions/multiindex/#offical-doc-link","title":"Offical Doc Link","text":"<p>https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_tuples.html</p>"},{"location":"tutorials/pandas_functions/multiindex/#my-youtube-tutorial-video","title":"My Youtube Tutorial Video","text":"<p>https://youtu.be/xXbXnNiCBt8</p>"},{"location":"tutorials/pandas_functions/multiindex/#written-examples-links","title":"Written Examples Links","text":"<p>https://sparkbyexamples.com/pandas/pandas-multiindex-dataframe-examples/ https://www.geeksforgeeks.org/pandas-multi-index-and-groupbys/ https://jakevdp.github.io/PythonDataScienceHandbook/03.05-hierarchical-indexing.html https://vitalflux.com/pandas-creating-multiindex-dataframe-from-product-or-tuples/ https://github.com/ZaxR/pandas_multiindex_tutorial/blob/master/Pandas%20MultiIndex%20Tutorial.ipynb</p>"},{"location":"tutorials/pandas_functions/plotting/","title":"Plotting","text":"<p>Functions on how to plot</p>"}]}